## zpool add top-level vdev; attach, detach, offline, online, replace vdev;  
                                                                                                                                                                   
### 作者                                                                                                                                                               
digoal                                                                                                                                                                 
                                                                                                                                                             
### 日期                                                                                                                                                                                
2014-05-27                                                                                                                                                       
                                                                                                                                                              
### 标签                                                                                                                                                             
PostgreSQL , Linux , ZFS                                                                                                                                                           
                                                                                                                                                                                               
----                                                                                                                                                                       
                                                                                                                                                                                                           
## 背景           
zpool允许我们动态的添加vdev, 这个我们已经在上一篇BLOG中介绍过.  
  
http://blog.163.com/digoal@126/blog/static/163877040201442731413803/  
  
```  
如添加spare  
[root@db-172-16-3-150 ssd1]# zpool add zpp spare /ssd1/zfs.6  
[root@db-172-16-3-150 ssd1]# zpool status zpp  
  pool: zpp  
 state: ONLINE  
  scan: none requested  
config:  
  
        NAME             STATE     READ WRITE CKSUM  
        zpp              ONLINE       0     0     0  
          mirror-0       ONLINE       0     0     0  
            /ssd1/zfs.1  ONLINE       0     0     0  
            /ssd1/zfs.2  ONLINE       0     0     0  
          raidz1-1       ONLINE       0     0     0  
            /ssd1/zfs.3  ONLINE       0     0     0  
            /ssd1/zfs.4  ONLINE       0     0     0  
            /ssd1/zfs.5  ONLINE       0     0     0  
        spares  
          /ssd1/zfs.6    AVAIL  
这里继续介绍一下mirror设备或raidz设备中的一些vdev 的操作.  
例如mirror设备允许attach和detach  
[root@db-172-16-3-150 ssd1]# zpool attach zpp /ssd1/zfs.2 /ssd1/zfs.1  
[root@db-172-16-3-150 ssd1]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.2   ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
  
[root@db-172-16-3-150 ssd1]# zpool detach zpp /ssd1/zfs.2   
[root@db-172-16-3-150 ssd1]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
  
raidz的设备不允许detach和attach  
[root@db-172-16-3-150 ssd1]# zpool detach zpp /ssd1/zfs.5  
cannot detach /ssd1/zfs.5: only applicable to mirror and replacing vdevs  
[root@db-172-16-3-150 man8]# zpool attach zpp /ssd1/zfs.5 /ssd1/zfs.2  
cannot attach /ssd1/zfs.2 to /ssd1/zfs.5: can only attach to mirrors and top-level disks  
  
单设备也允许attach, 变成mirror设备.  
[root@db-172-16-3-150 test]# zpool status zpp  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          /ssd1/zfs.1     ONLINE       0     0     0  
[root@db-172-16-3-150 test]# zpool attach zpp /ssd1/zfs.1 /ssd1/zfs.11  
绑定后变成了mirror设备.  
[root@db-172-16-3-150 test]# zpool status zpp  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
  
offline则可以针对有冗余的设备的离线.  
对raidz和mirror都可以这么做, 但是必须确保至少数据还是可用的, 例如raidz1可以offline1个设备  
[root@db-172-16-3-150 man8]# zpool offline zpp /ssd1/zfs.5  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: DEGRADED  
status: One or more devices has been taken offline by the administrator.  
        Sufficient replicas exist for the pool to continue functioning in a  
        degraded state.  
action: Online the device using 'zpool online' or replace the device with  
        'zpool replace'.  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               DEGRADED     0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        DEGRADED     0     0     0  
            /ssd1/zfs.5   OFFLINE      0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
[root@db-172-16-3-150 man8]# zpool offline zpp /ssd1/zfs.6  
cannot offline /ssd1/zfs.6: no valid replicas  
[root@db-172-16-3-150 man8]# zpool offline zpp /ssd1/zfs.10  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: DEGRADED  
status: One or more devices has been taken offline by the administrator.  
        Sufficient replicas exist for the pool to continue functioning in a  
        degraded state.  
action: Online the device using 'zpool online' or replace the device with  
        'zpool replace'.  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               DEGRADED     0     0     0  
          mirror-0        DEGRADED     0     0     0  
            /ssd1/zfs.10  OFFLINE      0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        DEGRADED     0     0     0  
            /ssd1/zfs.5   OFFLINE      0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
  
启用  
[root@db-172-16-3-150 man8]# zpool online zpp /ssd1/zfs.10  
[root@db-172-16-3-150 man8]# zpool online zpp /ssd1/zfs.5  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 2K in 0h0m with 0 errors on Tue May 27 15:58:23 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        ONLINE       0     0     0  
            /ssd1/zfs.5   ONLINE       0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
  
replace 一般用于坏掉的设备的替换.  
[root@db-172-16-3-150 man8]# zpool detach zpp /ssd1/zfs.11  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 2K in 0h0m with 0 errors on Tue May 27 15:58:23 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        ONLINE       0     0     0  
            /ssd1/zfs.5   ONLINE       0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          /ssd1/zfs.12    ONLINE       0     0     0  
[root@db-172-16-3-150 ssd1]# zpool replace zpp /ssd1/zfs.1 /ssd1/zfs.12  
[root@db-172-16-3-150 ssd1]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 1.26M in 0h0m with 0 errors on Tue May 27 15:37:52 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.2   ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        ONLINE       0     0     0  
            /ssd1/zfs.5   ONLINE       0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
```  
      
  
<a rel="nofollow" href="http://info.flagcounter.com/h9V1"  ><img src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"  alt="Flag Counter"  border="0"  ></a>  
  
  
  
  
  
  
## [digoal's 大量PostgreSQL文章入口](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
