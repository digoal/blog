## zpool add top-level vdev; attach, detach, offline, online, replace vdev;  
                                                                                                                                                                   
### 作者                                                                                                                                                               
digoal                                                                                                                                                                 
                                                                                                                                                             
### 日期                                                                                                                                                                                
2014-05-27                                                                                                                                                       
                                                                                                                                                              
### 标签                                                                                                                                                             
PostgreSQL , Linux , ZFS                                                                                                                                                           
                                                                                                                                                                                               
----                                                                                                                                                                       
                                                                                                                                                                                                           
## 背景           
zpool允许我们动态的添加vdev, 这个我们已经在上一篇BLOG中介绍过.  
  
http://blog.163.com/digoal@126/blog/static/163877040201442731413803/  
  
```  
如添加spare  
[root@db-172-16-3-150 ssd1]# zpool add zpp spare /ssd1/zfs.6  
[root@db-172-16-3-150 ssd1]# zpool status zpp  
  pool: zpp  
 state: ONLINE  
  scan: none requested  
config:  
  
        NAME             STATE     READ WRITE CKSUM  
        zpp              ONLINE       0     0     0  
          mirror-0       ONLINE       0     0     0  
            /ssd1/zfs.1  ONLINE       0     0     0  
            /ssd1/zfs.2  ONLINE       0     0     0  
          raidz1-1       ONLINE       0     0     0  
            /ssd1/zfs.3  ONLINE       0     0     0  
            /ssd1/zfs.4  ONLINE       0     0     0  
            /ssd1/zfs.5  ONLINE       0     0     0  
        spares  
          /ssd1/zfs.6    AVAIL  
这里继续介绍一下mirror设备或raidz设备中的一些vdev 的操作.  
例如mirror设备允许attach和detach  
[root@db-172-16-3-150 ssd1]# zpool attach zpp /ssd1/zfs.2 /ssd1/zfs.1  
[root@db-172-16-3-150 ssd1]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.2   ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
  
[root@db-172-16-3-150 ssd1]# zpool detach zpp /ssd1/zfs.2   
[root@db-172-16-3-150 ssd1]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
  
raidz的设备不允许detach和attach  
[root@db-172-16-3-150 ssd1]# zpool detach zpp /ssd1/zfs.5  
cannot detach /ssd1/zfs.5: only applicable to mirror and replacing vdevs  
[root@db-172-16-3-150 man8]# zpool attach zpp /ssd1/zfs.5 /ssd1/zfs.2  
cannot attach /ssd1/zfs.2 to /ssd1/zfs.5: can only attach to mirrors and top-level disks  
  
单设备也允许attach, 变成mirror设备.  
[root@db-172-16-3-150 test]# zpool status zpp  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          /ssd1/zfs.1     ONLINE       0     0     0  
[root@db-172-16-3-150 test]# zpool attach zpp /ssd1/zfs.1 /ssd1/zfs.11  
绑定后变成了mirror设备.  
[root@db-172-16-3-150 test]# zpool status zpp  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
  
offline则可以针对有冗余的设备的离线.  
对raidz和mirror都可以这么做, 但是必须确保至少数据还是可用的, 例如raidz1可以offline1个设备  
[root@db-172-16-3-150 man8]# zpool offline zpp /ssd1/zfs.5  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: DEGRADED  
status: One or more devices has been taken offline by the administrator.  
        Sufficient replicas exist for the pool to continue functioning in a  
        degraded state.  
action: Online the device using 'zpool online' or replace the device with  
        'zpool replace'.  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               DEGRADED     0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        DEGRADED     0     0     0  
            /ssd1/zfs.5   OFFLINE      0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
[root@db-172-16-3-150 man8]# zpool offline zpp /ssd1/zfs.6  
cannot offline /ssd1/zfs.6: no valid replicas  
[root@db-172-16-3-150 man8]# zpool offline zpp /ssd1/zfs.10  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: DEGRADED  
status: One or more devices has been taken offline by the administrator.  
        Sufficient replicas exist for the pool to continue functioning in a  
        degraded state.  
action: Online the device using 'zpool online' or replace the device with  
        'zpool replace'.  
  scan: resilvered 11.4M in 0h0m with 0 errors on Tue May 27 15:39:08 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               DEGRADED     0     0     0  
          mirror-0        DEGRADED     0     0     0  
            /ssd1/zfs.10  OFFLINE      0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        DEGRADED     0     0     0  
            /ssd1/zfs.5   OFFLINE      0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
  
启用  
[root@db-172-16-3-150 man8]# zpool online zpp /ssd1/zfs.10  
[root@db-172-16-3-150 man8]# zpool online zpp /ssd1/zfs.5  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 2K in 0h0m with 0 errors on Tue May 27 15:58:23 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        ONLINE       0     0     0  
            /ssd1/zfs.5   ONLINE       0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
  
replace 一般用于坏掉的设备的替换.  
[root@db-172-16-3-150 man8]# zpool detach zpp /ssd1/zfs.11  
[root@db-172-16-3-150 man8]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 2K in 0h0m with 0 errors on Tue May 27 15:58:23 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
            /ssd1/zfs.1   ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        ONLINE       0     0     0  
            /ssd1/zfs.5   ONLINE       0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          /ssd1/zfs.12    ONLINE       0     0     0  
[root@db-172-16-3-150 ssd1]# zpool replace zpp /ssd1/zfs.1 /ssd1/zfs.12  
[root@db-172-16-3-150 ssd1]# zpool status -v zpp  
  pool: zpp  
 state: ONLINE  
  scan: resilvered 1.26M in 0h0m with 0 errors on Tue May 27 15:37:52 2014  
config:  
  
        NAME              STATE     READ WRITE CKSUM  
        zpp               ONLINE       0     0     0  
          mirror-0        ONLINE       0     0     0  
            /ssd1/zfs.2   ONLINE       0     0     0  
            /ssd1/zfs.10  ONLINE       0     0     0  
          mirror-1        ONLINE       0     0     0  
            /ssd1/zfs.3   ONLINE       0     0     0  
            /ssd1/zfs.4   ONLINE       0     0     0  
          raidz1-2        ONLINE       0     0     0  
            /ssd1/zfs.5   ONLINE       0     0     0  
            /ssd1/zfs.6   ONLINE       0     0     0  
            /ssd1/zfs.7   ONLINE       0     0     0  
          mirror-3        ONLINE       0     0     0  
            /ssd1/zfs.8   ONLINE       0     0     0  
            /ssd1/zfs.9   ONLINE       0     0     0  
          mirror-4        ONLINE       0     0     0  
            /ssd1/zfs.12  ONLINE       0     0     0  
            /ssd1/zfs.11  ONLINE       0     0     0  
```  
      
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
