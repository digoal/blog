## dmsetup remove dm device solve : zpool error:one or more vdevs refer to the same device  
                                                                                                                                                                                                         
### 作者                                                                                                                                                                                                     
digoal                                                                                                                                                                                                       
                                                                                                                                                                                                   
### 日期                                                                                                                                                                                                                      
2015-01-29                                                                                                                                                                                             
                                                                                                                                                                                                    
### 标签                                                                                                                                                                                                   
PostgreSQL , Linux , ZFS                                                                                                                                                                                                 
                                                                                                                                                                                                                                     
----                                                                                                                                                                                                             
                                                                                                                                                                                                                                                 
## 背景                                    
这是一个OCZ的SSD, 一般用一半以内的容量是性能比较好, 所以480G的SSD, 我分了220G给ZFS缓存.  
  
但是注意对其的问题.  
  
```  
# fdisk -c -u /dev/sda  
```  
  
开始位置2048  
  
新增块数```2048*1024*220-1=461373439```  
  
因为原来配置的块未对其, 所以准备重新分一下 :   
  
查看cache设备 :   
  
```  
# zpool status  
  pool: zp1  
 state: ONLINE  
  scan: none requested  
config:  
  
        NAME                                            STATE     READ WRITE CKSUM  
        zp1                                             ONLINE       0     0     0  
          mirror-0                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2c8a06200099      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2c92069983cb      ONLINE       0     0     0  
          mirror-1                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2c9a0712503c      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2ca2078b4231      ONLINE       0     0     0  
          mirror-2                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2ca907f2b840      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2cb0085a22e6      ONLINE       0     0     0  
          mirror-3                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2cba08f37c32      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2d340486b1c4      ONLINE       0     0     0  
          mirror-4                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2d3b04e93404      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2d42054f21b8      ONLINE       0     0     0  
          mirror-5                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2d4905bed3f3      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2d4f061c3f88      ONLINE       0     0     0  
        logs  
          wwn-0x6b083fe0d17216001c1b2c7f056bd76c-part3  ONLINE       0     0     0  
        cache  
          wwn-0x5e83a977e08cba3e-part1                  ONLINE       0     0     0  
```  
  
删除cache设备  
  
```  
# zpool remove zp1 wwn-0x5e83a977e08cba3e-part1  
```  
  
重新对ssd分区 :   
  
```  
# fdisk -c -u /dev/sda  
Device contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabel  
Building a new DOS disklabel with disk identifier 0xb641c765.  
Changes will remain in memory only, until you decide to write them.  
After that, of course, the previous content won't be recoverable.  
  
Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)  
  
Command (m for help): d  
Selected partition 1  
  
Command (m for help): n  
Command action  
   e   extended  
   p   primary partition (1-4)  
p  
Partition number (1-4): 1  
First sector (2048-937766396, default 2048):   
Using default value 2048  
Last sector, +sectors or +size{K,M,G} (2048-937766396, default 937766396): +461373439  
```  
  
重新分完, 添加回去报错  
  
```  
# zpool add zp1 cache /dev/disk/by-id/wwn-0x5e83a977e08cba3e-part1  
cannot open '/dev/disk/by-id/wwn-0x5e83a977e08cba3e-part1': Device or resource busy  
cannot add to 'zp1': one or more vdevs refer to the same device  
```  
  
dd 这个设备亦无变化, 一开始我以为是头信息的问题 :   
  
```  
# dd if=/dev/zero of=/dev/disk/by-id/wwn-0x5e83a977e08cba3e-part1 bs=1k count=1024  
  
# zpool add zp1 cache /dev/disk/by-id/wwn-0x5e83a977e08cba3e-part1  
cannot open '/dev/disk/by-id/wwn-0x5e83a977e08cba3e-part1': Device or resource busy  
cannot add to 'zp1': one or more vdevs refer to the same device  
```  
  
真实原因是这个设备被device mapper占用了.  
  
```  
# dmsetup  ls  
sda1    (253:0)  
```  
  
删除这个dm设备 :   
  
```  
# dmsetup remove /dev/disk/by-id/dm-name-sda1  
  
ata-OCZ-REVODRIVE3_X2_OCZ-9XJBU029CT3M3U56           scsi-SATA_OCZ-REVODRIVE3_OCZ-9XJBU029CT3M3U56  
ata-OCZ-REVODRIVE3_X2_OCZ-9XJBU029CT3M3U56-part1     scsi-SATA_OCZ-REVODRIVE3_OCZ-9XJBU029CT3M3U56-part1  
dm-name-sda1                                         wwn-0x5e83a977e08cba3e  
dm-uuid-part1-sda  
```  
  
现在添加cache成功了, 省去了重启的烦恼.  
  
```  
# zpool add zp1 cache /dev/disk/by-id/wwn-0x5e83a977e08cba3e-part1  
  
# zpool status  
  pool: zp1  
 state: ONLINE  
  scan: none requested  
config:  
  
        NAME                                            STATE     READ WRITE CKSUM  
        zp1                                             ONLINE       0     0     0  
          mirror-0                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2c8a06200099      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2c92069983cb      ONLINE       0     0     0  
          mirror-1                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2c9a0712503c      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2ca2078b4231      ONLINE       0     0     0  
          mirror-2                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2ca907f2b840      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2cb0085a22e6      ONLINE       0     0     0  
          mirror-3                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2cba08f37c32      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2d340486b1c4      ONLINE       0     0     0  
          mirror-4                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2d3b04e93404      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2d42054f21b8      ONLINE       0     0     0  
          mirror-5                                      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2d4905bed3f3      ONLINE       0     0     0  
            wwn-0x6b083fe0d17216001c1b2d4f061c3f88      ONLINE       0     0     0  
        logs  
          wwn-0x6b083fe0d17216001c1b2c7f056bd76c-part3  ONLINE       0     0     0  
        cache  
          wwn-0x5e83a977e08cba3e-part1                  ONLINE       0     0     0  
```  
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
