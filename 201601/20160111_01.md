## PostgreSQL hugepage 支持与配置    
                                                
### 作者                                                                                             
digoal                                           
                                                  
### 日期                                             
2016-01-11                                          
                                              
### 标签                                           
PostgreSQL , hugepage , linux , shared buffer                     
                                                
----                                          
                                                   
## 背景                                         
PostgreSQL启动大页支持很简单，只需要配置几个东西。    
  
1、评估PG启动需要多少共享内存，先使用非大页启动。  
  
```  
huge_pages = off   
```  
  
启动数据库，从postmaster.pid中获取数据库启动需要多少内存。  
  
例如  
  
```  
获得PID  
  
$ head -1 $PGDATA/postmaster.pid  
4170  
  
计算数据库启动用了多少内存，指定进程ID  
  
$ pmap 4170 | awk '/rw-s/ && /zero/ {print $2}'  
6490428K  
```  
  
2、计算需要多少HUGE PAGE  
  
```  
huge page页大小  
  
$ grep ^Hugepagesize /proc/meminfo  
Hugepagesize:       2048 kB  
  
  
计算需要多少HUGE PAGE  
  
  
6490428 / 2048 gives approximately 3169.154,   
so in this example we need at least 3170 huge pages,   
which we can set with:  
```  
  
3、根据计算好的HUGE PAGE数分配HUGE PAGE  
  
```  
$ sysctl -w vm.nr_hugepages=3170  
```  
  
A larger setting would be appropriate if other programs on the machine also need huge pages.   
  
Don't forget to add this setting to /etc/sysctl.conf so that it will be reapplied after reboots.  
  
```  
vi /etc/sysctl.conf    
vm.nr_hugepages = 3170    
```  
    
4、配置postgresql.conf  ， 让数据库使用huge page。    
    
```    
huge_pages = on     # 或者try    
shared_buffers = 8GB  # 使用8G内存    
```    
    
5、操作系统(可选，关闭透明大页)    
    
配置grub.conf，加入如下，重启系统    
    
```    
numa=off    
transparent_hugepage=never    
```    
    
或    
    
在/etc/rc.local中加入下面的几行，然后重启操作系统：    
    
```    
if test -f /sys/kernel/mm/transparent_hugepage/enabled; then    
   echo never > /sys/kernel/mm/transparent_hugepage/enabled    
fi    
if test -f /sys/kernel/mm/transparent_hugepage/defrag; then    
   echo never > /sys/kernel/mm/transparent_hugepage/defrag    
fi    
```    
  
6、启动数据库  
  
```  
pg_ctl start  
```  
  
7、查看是否已使用大页。  
  
```  
获得PID  
  
$ head -1 $PGDATA/postmaster.pid  
4170  
  
计算数据库启动用了多少内存，指定进程ID  
  
$ pmap 4170 | awk '/rw-s/ && /zero/ {print $2}'  
  
没有返回，说明使用了huge page。  
```  
  
## PG如何使用HUGE PAGE  
src/backend/port/sysv_shmem.c  
  
```  
/*  
 * Identify the huge page size to use.  
 *  
 * Some Linux kernel versions have a bug causing mmap() to fail on requests  
 * that are not a multiple of the hugepage size.  Versions without that bug  
 * instead silently round the request up to the next hugepage multiple ---  
 * and then munmap() fails when we give it a size different from that.  
 * So we have to round our request up to a multiple of the actual hugepage  
 * size to avoid trouble.  
 *  
 * Doing the round-up ourselves also lets us make use of the extra memory,  
 * rather than just wasting it.  Currently, we just increase the available  
 * space recorded in the shmem header, which will make the extra usable for  
 * purposes such as additional locktable entries.  Someday, for very large  
 * hugepage sizes, we might want to think about more invasive strategies,  
 * such as increasing shared_buffers to absorb the extra space.  
 *  
 * Returns the (real or assumed) page size into *hugepagesize,  
 * and the hugepage-related mmap flags to use into *mmap_flags.  
 *  
 * Currently *mmap_flags is always just MAP_HUGETLB.  Someday, on systems  
 * that support it, we might OR in additional bits to specify a particular  
 * non-default huge page size.  
 */  
static void  
GetHugePageSize(Size *hugepagesize, int *mmap_flags)  
{  
        /*  
         * If we fail to find out the system's default huge page size, assume it  
         * is 2MB.  This will work fine when the actual size is less.  If it's  
         * more, we might get mmap() or munmap() failures due to unaligned  
         * requests; but at this writing, there are no reports of any non-Linux  
         * systems being picky about that.  
         */  
        *hugepagesize = 2 * 1024 * 1024;  
        *mmap_flags = MAP_HUGETLB;  
  
        /*  
         * System-dependent code to find out the default huge page size.  
         *  
         * On Linux, read /proc/meminfo looking for a line like "Hugepagesize:  
         * nnnn kB".  Ignore any failures, falling back to the preset default.  
         */  
#ifdef __linux__  
        {  
                FILE       *fp = AllocateFile("/proc/meminfo", "r");  
                char            buf[128];  
                unsigned int sz;  
                char            ch;  
  
                if (fp)  
                {  
                        while (fgets(buf, sizeof(buf), fp))  
                        {  
                                if (sscanf(buf, "Hugepagesize: %u %c", &sz, &ch) == 2)  
                                {  
                                        if (ch == 'k')  
                                        {  
                                                *hugepagesize = sz * (Size) 1024;  
                                                break;  
                                        }  
                                        /* We could accept other units besides kB, if needed */  
                                }  
                        }  
                        FreeFile(fp);  
                }  
        }  
#endif                                                  /* __linux__ */  
}  
  
#endif                                                  /* MAP_HUGETLB */  
```  
  
```  
/*  
 * Creates an anonymous mmap()ed shared memory segment.  
 *  
 * Pass the requested size in *size.  This function will modify *size to the  
 * actual size of the allocation, if it ends up allocating a segment that is  
 * larger than requested.  
 */  
static void *  
CreateAnonymousSegment(Size *size)  
{  
        Size            allocsize = *size;  
        void       *ptr = MAP_FAILED;  
        int                     mmap_errno = 0;  
  
#ifndef MAP_HUGETLB  
        /* PGSharedMemoryCreate should have dealt with this case */  
        Assert(huge_pages != HUGE_PAGES_ON);  
#else  
        if (huge_pages == HUGE_PAGES_ON || huge_pages == HUGE_PAGES_TRY)  
        {  
                /*  
                 * Round up the request size to a suitable large value.  
                 */  
                Size            hugepagesize;  
                int                     mmap_flags;  
  
                GetHugePageSize(&hugepagesize, &mmap_flags);  
  
                if (allocsize % hugepagesize != 0)  
                        allocsize += hugepagesize - (allocsize % hugepagesize);  
  
                ptr = mmap(NULL, allocsize, PROT_READ | PROT_WRITE,  
                                   PG_MMAP_FLAGS | mmap_flags, -1, 0);  
                mmap_errno = errno;  
                if (huge_pages == HUGE_PAGES_TRY && ptr == MAP_FAILED)  
                        elog(DEBUG1, "mmap(%zu) with MAP_HUGETLB failed, huge pages disabled: %m",  
                                 allocsize);  
        }  
#endif  
  
        if (ptr == MAP_FAILED && huge_pages != HUGE_PAGES_ON)  
        {  
                /*  
                 * Use the original size, not the rounded-up value, when falling back  
                 * to non-huge pages.  
                 */  
                allocsize = *size;  
                ptr = mmap(NULL, allocsize, PROT_READ | PROT_WRITE,  
                                   PG_MMAP_FLAGS, -1, 0);  
                mmap_errno = errno;  
        }  
  
        if (ptr == MAP_FAILED)  
        {  
                errno = mmap_errno;  
                ereport(FATAL,  
                                (errmsg("could not map anonymous shared memory: %m"),  
                                 (mmap_errno == ENOMEM) ?  
                                 errhint("This error usually means that PostgreSQL's request "  
                                                 "for a shared memory segment exceeded available memory, "  
                                                 "swap space, or huge pages. To reduce the request size "  
                                                 "(currently %zu bytes), reduce PostgreSQL's shared "  
                                                 "memory usage, perhaps by reducing shared_buffers or "  
                                                 "max_connections.",  
                                                 *size) : 0));  
        }  
  
        *size = allocsize;  
        return ptr;  
}  
```  
   
```  
/*  
 * PGSharedMemoryCreate  
 *  
 * Create a shared memory segment of the given size and initialize its  
 * standard header.  Also, register an on_shmem_exit callback to release  
 * the storage.  
 *  
 * Dead Postgres segments are recycled if found, but we do not fail upon  
 * collision with non-Postgres shmem segments.  The idea here is to detect and  
 * re-use keys that may have been assigned by a crashed postmaster or backend.  
 *  
 * makePrivate means to always create a new segment, rather than attach to  
 * or recycle any existing segment.  
 *  
 * The port number is passed for possible use as a key (for SysV, we use  
 * it to generate the starting shmem key).  In a standalone backend,  
 * zero will be passed.  
 */  
PGShmemHeader *  
PGSharedMemoryCreate(Size size, bool makePrivate, int port,  
                                         PGShmemHeader **shim)  
{  
        IpcMemoryKey NextShmemSegID;  
        void       *memAddress;  
        PGShmemHeader *hdr;  
        IpcMemoryId shmid;  
        struct stat statbuf;  
        Size            sysvsize;  
  
        /* Complain if hugepages demanded but we can't possibly support them */  
#if !defined(USE_ANONYMOUS_SHMEM) || !defined(MAP_HUGETLB)  
        if (huge_pages == HUGE_PAGES_ON)  
                ereport(ERROR,  
                                (errcode(ERRCODE_FEATURE_NOT_SUPPORTED),  
                                 errmsg("huge pages not supported on this platform")));  
#endif  
  
        /* Room for a header? */  
        Assert(size > MAXALIGN(sizeof(PGShmemHeader)));  
  
#ifdef USE_ANONYMOUS_SHMEM  
        AnonymousShmem = CreateAnonymousSegment(&size);  
        AnonymousShmemSize = size;  
  
        /* Register on-exit routine to unmap the anonymous segment */  
        on_shmem_exit(AnonymousShmemDetach, (Datum) 0);  
  
        /* Now we need only allocate a minimal-sized SysV shmem block. */  
        sysvsize = sizeof(PGShmemHeader);  
#else  
        sysvsize = size;  
#endif  
  
        /* Make sure PGSharedMemoryAttach doesn't fail without need */  
        UsedShmemSegAddr = NULL;  
  
        /* Loop till we find a free IPC key */  
        NextShmemSegID = port * 1000;  
  
        for (NextShmemSegID++;; NextShmemSegID++)  
        {  
                /* Try to create new segment */  
                memAddress = InternalIpcMemoryCreate(NextShmemSegID, sysvsize);  
                if (memAddress)  
                        break;                          /* successful create and attach */  
  
                /* Check shared memory and possibly remove and recreate */  
  
                if (makePrivate)                /* a standalone backend shouldn't do this */  
                        continue;  
  
                if ((memAddress = PGSharedMemoryAttach(NextShmemSegID, &shmid)) == NULL)  
                        continue;                       /* can't attach, not one of mine */  
  
                /*  
                 * If I am not the creator and it belongs to an extant process,  
                 * continue.  
                 */  
                hdr = (PGShmemHeader *) memAddress;  
                if (hdr->creatorPID != getpid())  
                {  
                        if (kill(hdr->creatorPID, 0) == 0 || errno != ESRCH)  
                        {  
                                shmdt(memAddress);  
                                continue;               /* segment belongs to a live process */  
                        }  
                }  
  
                /*  
                 * The segment appears to be from a dead Postgres process, or from a  
                 * previous cycle of life in this same process.  Zap it, if possible,  
                 * and any associated dynamic shared memory segments, as well. This  
                 * probably shouldn't fail, but if it does, assume the segment belongs  
                 * to someone else after all, and continue quietly.  
                 */  
                if (hdr->dsm_control != 0)  
                        dsm_cleanup_using_control_segment(hdr->dsm_control);  
                shmdt(memAddress);  
                if (shmctl(shmid, IPC_RMID, NULL) < 0)  
                        continue;  
  
                /*  
                 * Now try again to create the segment.  
                 */  
                memAddress = InternalIpcMemoryCreate(NextShmemSegID, sysvsize);  
                if (memAddress)  
                        break;                          /* successful create and attach */  
  
                /*  
                 * Can only get here if some other process managed to create the same  
                 * shmem key before we did.  Let him have that one, loop around to try  
                 * next key.  
                 */  
        }  
  
        /*  
         * OK, we created a new segment.  Mark it as created by this process. The  
         * order of assignments here is critical so that another Postgres process  
         * can't see the header as valid but belonging to an invalid PID!  
         */  
        hdr = (PGShmemHeader *) memAddress;  
        hdr->creatorPID = getpid();  
        hdr->magic = PGShmemMagic;  
        hdr->dsm_control = 0;  
  
        /* Fill in the data directory ID info, too */  
        if (stat(DataDir, &statbuf) < 0)  
                ereport(FATAL,  
                                (errcode_for_file_access(),  
                                 errmsg("could not stat data directory \"%s\": %m",  
                                                DataDir)));  
        hdr->device = statbuf.st_dev;  
        hdr->inode = statbuf.st_ino;  
  
        /*  
         * Initialize space allocation status for segment.  
         */  
        hdr->totalsize = size;  
        hdr->freeoffset = MAXALIGN(sizeof(PGShmemHeader));  
        *shim = hdr;  
  
        /* Save info for possible future use */  
        UsedShmemSegAddr = memAddress;  
        UsedShmemSegID = (unsigned long) NextShmemSegID;  
  
        /*  
         * If AnonymousShmem is NULL here, then we're not using anonymous shared  
         * memory, and should return a pointer to the System V shared memory  
         * block. Otherwise, the System V shared memory block is only a shim, and  
         * we must return a pointer to the real block.  
         */  
#ifdef USE_ANONYMOUS_SHMEM  
        if (AnonymousShmem == NULL)  
                return hdr;  
        memcpy(AnonymousShmem, hdr, sizeof(PGShmemHeader));  
        return (PGShmemHeader *) AnonymousShmem;  
#else  
        return hdr;  
#endif  
}  
```  
  
## 排错  
启动数据库，如果发现报这个错误，    
    
```    
huge TLB pages not supported on this platform    
```    
    
说明系统编译时，检测到OS不支持大页，那么怎么解决呢？    
    
```    
src/backend/port/sysv_shmem.c    
src/backend/port/pg_shmem.c    
/*    
 * Creates an anonymous mmap()ed shared memory segment.    
 *    
 * Pass the requested size in *size.  This function will modify *size to the    
 * actual size of the allocation, if it ends up allocating a segment that is    
 * larger than requested.    
 */    
#ifndef EXEC_BACKEND    
static void *    
CreateAnonymousSegment(Size *size)    
{    
        Size            allocsize = *size;    
        void       *ptr = MAP_FAILED;    
        int                     mmap_errno = 0;    
    
#ifndef MAP_HUGETLB    
        if (huge_pages == HUGE_PAGES_ON)    
                ereport(ERROR,    
                                (errcode(ERRCODE_FEATURE_NOT_SUPPORTED),    
                                 errmsg("huge TLB pages not supported on this platform")));    
#else    
......    
```    
    
    
实际上MAP_HUGETLB是在系统的/usr/include/sys/mman.h 中定义的，如果没有定义，PG就不支持大页。    
    
```    
#include <bits/mman.h>    
```    
    
在文件 /usr/include/bits/mman.h 中加入以下行，重新编译PostgreSQL即可。    
    
```    
# define MAP_HUGETLB    0x40000         /* Create huge page mapping.  */    
```    
    
重新编译PostgreSQL后，重启数据库。    
    
## 参考    
1\. http://www.postgresql.org/message-id/flat/54B9C41D.10109@jcvi.org#54B9C41D.10109@jcvi.org    
    
2\. http://terryebase.com/?p=161    
    
3\. https://www.postgresql.org/docs/current/kernel-resources.html#LINUX-HUGE-PAGES    
            
    
    
    
    
    
    
    
    
    
      
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
