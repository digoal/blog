## PostgreSQL 最佳实践 - 块级增量备份(ZFS篇)双机HA与块级备份部署  
##### [TAG 24](../class/24.md)
                                                                                                                  
### 作者                                                                                                                      
digoal                                                                                                                      
                                                                                                                  
### 日期                                                                                                                      
2016-08-23                                                                                                                 
                                                                                                                  
### 标签                                                                                                                      
PostgreSQL , 增量备份 , 块级 , COW , 写时复制 , zfs , clone , snapshot , 快照 , ha                                         
                                                                                                                  
----                                                                                                                      
                           
## 背景  
基于流复制的HA, 采样如下方案.    
  
https://github.com/digoal/PostgreSQL_HA_with_primary_standby_2vip    
    
本文介绍一下, 在没有其他主机的情况下, 如何实施块级别的增量备份.    
    
(假设主机为了性能, 未直接使用ZFS作为文件系统)    
    
主要用到的是chroot, zfs. 当前, 现在btrfs 也支持snapshot, 所以随便你的选择了.     
    
实现方法也比较多, 我们可以用容器, 例如docker, 也可用虚拟机.    
    
本文采用KVM虚拟机, 在虚拟机中使用ZFS文件系统, 在虚拟机中创建以宿主机数据库为primary的第三个standby.    
    
然后在zfs上做快照.    
    
## 宿主机的归档如何传递给虚拟机  
我这里虚拟机和宿主机用的不同网段, 虚拟机出外网使用NAT转发通讯.    
  
```  
# iptables -L -v -n -t nat    
Chain PREROUTING (policy ACCEPT 22449 packets, 1310K bytes)    
 pkts bytes target     prot opt in     out     source               destination             
    
Chain POSTROUTING (policy ACCEPT 25464 packets, 1325K bytes)    
 pkts bytes target     prot opt in     out     source               destination             
  116  6960 MASQUERADE  tcp  --  *      *       192.168.122.0/24    !192.168.122.0/24    masq ports: 1024-65535     
  337 23214 MASQUERADE  udp  --  *      *       192.168.122.0/24    !192.168.122.0/24    masq ports: 1024-65535     
    0     0 MASQUERADE  all  --  *      *       192.168.122.0/24    !192.168.122.0/24        
    
Chain OUTPUT (policy ACCEPT 25464 packets, 1325K bytes)    
 pkts bytes target     prot opt in     out     source               destination     
```  
    
这种通讯方式, 要直接挂载远端的NFS是有问题的, 所以需要用其他方式来获取远端归档.    
    
我这里选择的方法是scp, 将虚拟机的postgres 用户下的key拷贝到2台宿主机, 使用scp来拷贝归档.    
    
假设宿主机的物理IP分别为172.16.18.25,172.16.18.26.     
  
```  
restore_command = 'ping -c 1 -W 1 172.16.18.25 && scp root@172.16.18.25:/data04/pgdata/arch/*/%f %p; ping -c 1 -W 1 172.16.18.26 && scp root@172.16.18.26:/data04/pgdata/arch/*/%f %p'    
primary_conninfo = 'host=192.168.122.1 port=1921 user=replica keepalives_idle=60'    
```  
    
## 为什么不直接使用primary VIP呢?   
假设primary VIP是172.16.18.27.    
    
因为VIP会漂移, 一旦漂移, 虚拟机的~/.ssh/known_hosts里面的条目就会失效, 需要重新编写, 比较麻烦.    
    
## 配置宿主机    
    
自动启动虚拟机    
  
```  
# cat /etc/rc.local    
# kvm    
/usr/bin/virsh start centos6_6_x64    
```  
    
配置虚拟机自动启动数据库    
  
```  
# cat /etc/rc.local    
su - postgres -c "pg_ctl start"    
```  
    
配置虚拟机自动快照    
  
```  
# crontab -l    
8 * * * * /usr/sbin/ntpdate asia.pool.ntp.org && /sbin/hwclock --systohc    
1 4 * * * /root/script/zfs_snap.sh    
    
# cat /root/script/zfs_snap.sh     
#!/bin/bash    
    
DATE="`date +%Y%m%d`"    
# 注意, 第一个快照的位置是$PGDATA 即控制文件所在的zfs    
/sbin/zfs snapshot zp1/data02@$DATE    
/sbin/zfs snapshot zp1/data01@$DATE    
/sbin/zfs snapshot zp1/data03@$DATE    
/sbin/zfs snapshot zp1/data04@$DATE    
```  
    
现在快照有了, 加上宿主机上的归档也在, 完全可以实现基于时间点的恢复 .     
    
最后, 强烈建议pg_xlog不要放在zfs文件系统中. 宁愿放在虚拟机的系统盘里面也不要放在ZFS里面.        
                                                                                          
                                                                    
                                                                
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
