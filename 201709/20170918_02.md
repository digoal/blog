## 空间、时间、对象圈人 + 人物透视
                     
### 作者    
digoal    
    
### 日期     
2017-09-18     
      
### 标签    
PostgreSQL , PostGIS , geohash , brin , gist索引 , Greenplum , HybridDB for PostgreSQL    
                
----                
                 
## 背景          
通常一个人的常驻地可能会包括：家、儿女家、双方父母家、情人、异性伴侣家、公司、商圈若干等。

通过对这些数据的运营，可以实现很多业务需求。例如：

1、寻人

[《海量用户实时定位和圈人 - 团圆社会公益系统(位置寻人\圈人)》](../201709/20170915_01.md)  

2、线下广告投放人群圈选，选址，商圈人群画像。

[《数据寻龙点穴（空间聚集分析） - 阿里云RDS PostgreSQL最佳实践》](../201708/20170820_02.md)  

[《(新零售)商户网格化(基于位置GIS)运营 - 阿里云RDS PostgreSQL、HybridDB for PostgreSQL最佳实践》](../201708/20170802_02.md)  

3、基于位置的用户画像透视、基于用户群体的位置透视、以上需求再叠加时间区间条件进行透视。比如

以地图为底，在图上展示每个BOX、GRID（例如每方圆100米，用width_bucket或自定义UDF可以得到这些box id）的平均收入、平均消费。通过颜色深浅来表示收入和消费的数值。

再细一点，可以再分消费领域（饮食、衣服、电子产品、书籍、。。。。），这样是不是一眼就能看出该去哪里开什么类型的店了呢？当然电商发达的今天，一定要考虑线上和线下结合的。

这类空间圈人 + 人物透视的场景中，Greenplum无疑是一个很好的选择(简单粗暴、功能性能都满足)，PostgreSQL 10也可以，到底选择PostgreSQL还是Greenplum呢？

## Greenplum和PostgreSQL两个产品的特色和选择指导
  
1、PostgreSQL 10 适合以10TB ~ 100TB，OLTP为主，OLAP为辅的场景。与Oracle覆盖的场景非常类似。  
  
兼容SQL:2011，百万+级tpmC。  
  
支持多核并行计算。  
  
支持可读写的OSS对象存储外部表。  
  
支持常用类型、扩展数据类型：JSON(B)、Hstore(KV), PostGIS空间数据库、pgrouting(路由,图式搜索)、数组、ltree树类型、HLL估值类型, smlar, imgsmlr等。  
  
支持SQL流计算插件  
  
支持时序插件  
  
支持btree, hash, gin, gist, sp-gist, bloom, brin等索引。  
  
支持plpgsql, sql服务端编程。  
  
支持分析型语法（多维计算、窗口查询）、递归查询(树形查询、图式搜索、等场景)。支持文本全文检索、模糊查询、相似查询、正则查询。支持数组相似查询，图像相似查询。  
  
1\.1 适合业务场景：  
  
```  
 TB+级OLTP(在线事务处理)+OLAP(实时分析)。  

 模糊查询、相似搜索、正则搜索  

 全文检索  

 物联网  

 流式数据处理  

 社交  

 图式搜索  

 独立事件分析  

 冷热分离  

 异步消息  

 多值类型、图像特征值 相似搜索  

 实时数据清洗  

 GIS应用  

 任意字段实时搜索  

 ... ...
```  
  
1\.2 主打：功能、稳定性、性能、高可用、可靠性、Oracle兼容性、HTAP。  
  
2、HybridDB for PostgreSQL(Greenplum开源版GPDB改进而来) 适合PB级实时OLAP，非常典型的海量数仓。  
  
兼容SQL:2008，兼容TPC-H，TPC-DS。有数十年的商业化历练经验。  
  
支持可读写的OSS对象存储外部表。  
  
支持常用类型、扩展数据类型：JSON、PostGIS空间数据库、数组、HLL估值类型。  
  
支持bitmap, hash, btree索引。  
  
支持pljava服务端编程。  
  
支持分析型语法（多维计算、窗口查询、MADlib机器学习）、支持全文检索语法。  
  
支持列存储、行存储、压缩、混合存储。  
  
支持4阶段聚合，支持节点间自动重分布。  
  
支持水平扩容。  
  
2\.1 适合业务场景：  
  
PB+级实时分析。（传统统计；时间、空间、属性多维属性透视、圈人；任意表、任意维度JOIN；）  
  
2\.2 主打：分析型SQL兼容性、功能、稳定性、性能、高可用、扩展性。  

## 空间圈人+人物透视 DEMO

### 结构设计
1、表结构设计1，宽表（当标签种类在1600以内时）

```
create table tbl_pos (
  uid int8,   -- 用户ID
  att1 int8,  -- 用户标签1
  att2 int8,  -- 用户标签2
  att3 int8,  -- 用户标签3
  ....
  pos1 geometry,  -- 用户家庭位置
  pos2 geometry,  -- 用户公司位置
  pos3 geometry,  -- 用户xx位置
  pos4 geometry,  -- 用户xxx位置
  ...
);
```

或者

```
create table tbl_tag (
  uid int8,   -- 用户ID
  att1 int8,  -- 用户标签1
  att2 int8,  -- 用户标签2
  att3 int8,  -- 用户标签3
  ....
);

create table tbl_pos (
  uid int8,
  pos_att int2,   -- 位置属性，（家、公司、。。。）
  pos geometry,   -- 位置
);
```

2、表结构设计2，JSONB作为标签字段，当表签种类大于1600时。

```
create table tbl_pos (
  uid int8,   -- 用户ID
  att jsonb,  -- 用户标签，用JSONB表示
  ....
  pos1 geometry,  -- 用户家庭位置
  pos2 geometry,  -- 用户公司位置
  pos3 geometry,  -- 用户xx位置
  pos4 geometry,  -- 用户xxx位置
  ...
);
```

3、表结构设计3，数组存标签设计（与结构2的覆盖范围一样），这个设计曾经用在个方案里面：

[《恭迎万亿级营销(圈人)潇洒的迈入毫秒时代 - 万亿user_tags级实时推荐系统数据库设计》](../201612/20161225_01.md)  

```
create table tbl_tag (
  uid int8,
  tag text[],
  ...
  pos1 geometry,  -- 用户家庭位置
  pos2 geometry,  -- 用户公司位置
  pos3 geometry,  -- 用户xx位置
  pos4 geometry,  -- 用户xxx位置
  ...
);
```

4、表结构设计4，标签倒排设计（当标签种类超过1600，并且标签为YES OR NO的类别时，变更标签需要使用合并和UDF的方式，仅仅适合于PostgreSQL），这个设计层级用在这个方案里面：

[《基于 阿里云 RDS PostgreSQL 打造实时用户画像推荐系统》](../201610/20161021_01.md)  

```
create table tbl_pos (
  uid int8,
  pos1 geometry,  -- 用户家庭位置
  pos2 geometry,  -- 用户公司位置
  pos3 geometry,  -- 用户xx位置
  pos4 geometry,  -- 用户xxx位置
  ...
);

create table tbl_tag (
  tag int,
  userbits varbit
);
```

以上设计各有优劣以及覆盖的场景，看场景进行选择。

接下来就对比PG 10和GPDB，采用第一种设计进行对比，用例中有200种数值类型的标签种类，有10个常用地址。

### PostgreSQL 10
#### 准备数据
1、建标签表、位置表，写入10亿标签数据，100亿位置数据。

```
create extension postgis;

create or replace function ct1 () returns void as $$
declare
  sql text := '';
begin
  sql := 'create unlogged table tbl_tag(uid int8,';
  for i in 1..200 loop
    sql := sql||'c'||i||' int2 default random()*32767,';
  end loop;
  sql := rtrim(sql, ',');
  sql := sql||')';
  execute sql;
end;
$$ language plpgsql strict;


create unlogged table tbl_pos(
  uid int8, 
  pos_att int2,
  pos geometry default st_setsrid(st_makepoint(73+random()*62, 3+random()*50), 4326)
);

select ct1();

nohup psql -c "insert into tbl_tag select generate_series(1,1000000000)" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),1" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),2" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),3" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),4" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),5" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),6" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),7" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),8" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),9" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),10" >/dev/null 2>&1 &
```

2、根据位置整理位置表，（因为用户的位置数据是通过行为算出来的，并且通常变化非常小，所以可以视为半静态数据，适合整理）。

```
create unlogged table tbl_pos1 (like tbl_pos);
insert into tbl_pos1 select * from tbl_pos order by pos_att, st_geohash(pos, 10);  -- 10位已经精确到米级, 足够使用
```

3、创建位置表的geohash brin块级索引。

```
create index idx_tbl_pos1_pos on tbl_pos1 using brin( st_geohash(pos, 10) );  
```

4、创建标签数据btree索引。

```
for ((i=1;i<=200;i++)) 
do
  nohup psql -c "create index idx_tbl_tag_$i on tbl_tag (c$i);" >/dev/null 2>&1 &
done
```

5、空间使用情况

#### 空间、属性圈人 + 透视 性能测试

### Greenplum

#### 准备数据

```
create or replace function ct1 () returns void as $$
declare
  sql text := '';
begin
  sql := 'create table tbl_tag(uid int8,';
  for i in 1..200 loop
    sql := sql||'c'||i||' int2 default random()*32767,';
  end loop;
  sql := rtrim(sql, ',');
  sql := sql||') with (APPENDONLY=true, ORIENTATION=column, COMPRESSTYPE=zlib, CHECKSUM=false)';
  execute sql;
end;
$$ language plpgsql strict;

select ct1();

create table tbl_pos(
  uid int8, 
  pos_att int2,
  pos geometry default st_setsrid(st_makepoint(73+random()*62, 3+random()*50), 4326)
)
with (APPENDONLY=true, ORIENTATION=row, COMPRESSTYPE=zlib, CHECKSUM=false)
partition by list (pos_att)
(
  partition p1 values (1),
  partition p2 values (2),
  partition p3 values (3),
  partition p4 values (4),
  partition p5 values (5),
  partition p6 values (6),
  partition p7 values (7),
  partition p8 values (8),
  partition p9 values (9),
  partition p10 values (10)
)
;

nohup psql -c "insert into tbl_tag select generate_series(1,1000000000)" >/dev/null 2>&1 &

nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),1" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),2" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),3" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),4" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),5" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),6" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),7" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),8" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),9" >/dev/null 2>&1 &
nohup psql -c "insert into tbl_pos select generate_series(1,1000000000),10" >/dev/null 2>&1 &
```

nohup psql -c "copy (select uid,pos_att,st_geohash(pos, 10) from tbl_pos1) to stdout"|psql -c "copy tbl_pos from stdin" >/dev/null 2>&1 &

#### 空间、属性圈人 + 透视 性能测试




## 小结

对比表格：

空间

性能

并行?




冗余，消除JOIN？对Greenplum来说没有必要。

对于PG来说，需要等列存引擎、parallel hash补丁，同等资源下，性能会做到和Greenplum差不多（甚至更好）

3. 士元：文档

9亿

POC


brin 空间索引


商圈圈人


任意列合并查询

parallel hash join

https://commitfest.postgresql.org/14/871/

range merge join

https://commitfest.postgresql.org/14/1106/

parallel append scan

https://commitfest.postgresql.org/14/987/



Greenplum和PostgreSQL两个产品的选择还是请参考前面所述。
