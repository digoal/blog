## PostgreSQL 大版本升级方法之一 - 不落地并行导出导入    
                                                             
### 作者                                                             
digoal                                                             
                                                             
### 日期                                                             
2018-09-11                                                           
                                                             
### 标签                                                             
PostgreSQL , 大版本升级 , rds_dbsync , pg_dump , pg_restore         
                                                             
----                                                             
                                                             
## 背景     
尽量快的大版本升级的方法。     
    
## 一、9.4以下版本，使用pg_dump并行导出，pg_restore并行导入，迁移    
(导出使用源版本pg_dump，导入使用目标版本pg_restore。如果是ppas请使用enterprisedb对应版本。)      
    
1、(源库)全局元数据(用户、表空间)导出    
    
需要superuser权限（如果你没有这个权限，跳过此步，但是务必在执行下一步时，人为在目标实例中创建所有与对象权限相关的用户）。     
    
```    
pg_dumpall -g -h IP地址 -p 端口 -U 用户 -W -l 数据库名    
```    
    
2、(目标库)全局元数据导入    
    
```    
导入以上元数据，在目标库执行即可（通常包括创建用户，修改用户密码，创建表空间等。）    
```    
    
执行第2步的目的是保证导入时，执行grant, alter set owner等操作时，目标用户已存在，否则缺失用户会导致pg_restore报错。    
    
3、(目标库)建库    
    
```    
postgres=# create database newdb;    
CREATE DATABASE    
```    
    
4、(目标库)插件    
    
```    
安装postgresql软件时，打包源库已使用的的插件。    
    
略    
```    
    
5、(源库)导出    
    
```    
mkdir /data01/pg/backup    
pg_dump -j 32 -f /data01/pg/backup -F d -h IP地址 -p 端口 -U 用户 -W newdb     
```    
    
6、(目标实例)关闭autovacuum，加速导入(可选)    
    
```    
使用超级用户执行SQL    
    
alter system set autovacuum=off;    
select pg_reload_conf();    
```    
    
7、(目标库)导入    
    
```    
pg_restore -d newdb -F d -j 32 -h IP地址 -p 端口 -U 用户 /data01/pg/backup    
```    
    
8、(目标实例)开启autovacuum(如果执行了6)    
    
```    
使用超级用户执行SQL    
    
alter system set autovacuum=on;    
select pg_reload_conf();    
```    
    
9、(目标实例)收集统计信息(如果执行了6)    
    
```    
使用超级用户执行SQL，收集统计信息    
\c newdb 超级用户    
analyze;    
```    
    
使用以上方法，60GB的数据库迁移，耗时约10分钟。      
    
### 多机玩法  
https://momjian.us/main/blogs/pgblog/2018.html#September_12_2018     
    
```  
Where this gets interesting is with multiple hosts. You can:  
  
$ # dump a remote database to your local machine  
$ pg_dump -h remotedb.mydomain.com -f /home/postgres/dump.sql test  
   
$ # dump a local database and write to a remote machine  
$ pg_dump -h remotedb.mydomain.com test | ssh postgres@remotedb.mydomain.com 'cat > dump.sql'  
   
$ # dump a remote database and write to the same remote machine  
$ pg_dump -h remotedb.mydomain.com test | ssh postgres@remotedb.mydomain.com 'cat > dump.sql'  
   
$ # or a different remote machine  
$ pg_dump -h remotedb1.mydomain.com test | ssh postgres@remotedb2.mydomain.com 'cat > dump.sql'  
   
  
  
  
  
You also have similar restore options. I will use psql below but pg_restore works the same:  
  
$ # dump a remote database and restore to your local machine  
$ pg_dump -h remotedb.mydomain.com test1 | psql test2  
   
$ # dump a local database and restore to a remote machine  
$ pg_dump -h remotedb.mydomain.com test | ssh postgres@remotedb.mydomain.com 'psql test'  
   
$ # dump a remote database and restore to the same remote machine  
$ pg_dump -h remotedb.mydomain.com test1 | ssh postgres@remotedb.mydomain.com 'psql test2'  
   
$ # or a different remote machine  
$ pg_dump -h remotedb1.mydomain.com test | ssh postgres@remotedb2.mydomain.com 'psql test'  
```  
    
### [大多数情况建议使用本方法]不落地迁移方法pg_dump 输出到standard output, psql管道执行  
old pg -> ecs(linux\win) -> new pg  
  
保证足够的带宽，因为不落地，迁移速度还是很快的。有网友反馈100GB的数据不到10分钟就迁移完成了。        
   
1、先迁移全局数据（最主要的是用户、表空间，否则在倒入时可能因为目标环境没有用户或表空间而报错）。  
  
```
全局数据可以使用pg_dumpall -g来导出， 
导出的sql内容根据情况提取， 
不一定要在目标端全部执行， 
但是目标端建议把所有的create user相关的都执行一下(目标端已存在端user不需要重复创建)。  
```
  
2、pg_dump | psql  
  
使用源库版本的pg_dump和psql版本。   
  
Linux例子：    
  
```  
编辑密码文件

vi ~/.pgpass  
主机1:端口:数据库:用户:密码  
主机2:端口:数据库:用户:密码  

修改密码文件权限为400

chmod 400 ~/.pgpass  
```
  
如果使用的是RDS目标端， 不要导出表空间语句， 因RDS不支持创建表空间。  pg_dump加上--no-tablespaces即可。   
    
  
```
方法1： 单个事务倒入，有任何错误都会导致全部回滚  
nohup pg_dump -F p -h 主机1 -p 端口 -U 用户 -d 数据库 | psql -h 主机2 -p 端口 -U 用户 -1 数据库 >./imp.log1 2>&1 &  
OR(目标端是rds)
nohup pg_dump -F p -h 主机1 -p 端口 -U 用户 -d 数据库 --no-tablespaces | psql -h 主机2 -p 端口 -U 用户 -1 数据库 >./imp.log1 2>&1 &  
  
方法2： 有错误不会导致全部回滚  
nohup pg_dump -F p -h 主机1 -p 端口 -U 用户 -d 数据库 | psql -h 主机2 -p 端口 -U 用户 数据库 >./imp.log2 2>&1 &  
OR(目标端是rds)
nohup pg_dump -F p -h 主机1 -p 端口 -U 用户 -d 数据库 --no-tablespaces | psql -h 主机2 -p 端口 -U 用户 数据库 >./imp.log2 2>&1 &  
```  
  
如果希望打印总耗时, 使用以下command:  

```
方法1： 单个事务倒入，有任何错误都会导致全部回滚  
nohup pg_dump -F p -h 主机1 -p 端口 -U 用户 -d 数据库 | time psql -h 主机2 -p 端口 -U 用户 -1 数据库 >./imp.log1 2>&1 &  
OR(目标端是rds)
nohup pg_dump -F p -h 主机1 -p 端口 -U 用户 -d 数据库 --no-tablespaces | time psql -h 主机2 -p 端口 -U 用户 -1 数据库 >./imp.log1 2>&1 &  
  
方法2： 有错误不会导致全部回滚  
nohup pg_dump -F p -h 主机1 -p 端口 -U 用户 -d 数据库 | time psql -h 主机2 -p 端口 -U 用户 数据库 >./imp.log2 2>&1 &  
OR(目标端是rds)
nohup pg_dump -F p -h 主机1 -p 端口 -U 用户 -d 数据库 --no-tablespaces | time psql -h 主机2 -p 端口 -U 用户 数据库 >./imp.log2 2>&1 &  
```
  
某些error类的报警通常可以忽略（例如目标端没有某些用户， 赋权或回收权限错误等）。  实际情况实际分析。  
    
## 二、9.4及以上版本，使用rds_dbsync不落地并行迁移    
[《MySQL 不落地迁移、导入 PostgreSQL - 推荐 rds_dbsync》](../201808/20180815_01.md)    
    
## 三、9.4及以上版本，使用pg_logical，增量迁移    
    
## 四、10及以上版本，使用逻辑订阅，增量迁移    
    
## 五、任何版本，都可以使用pg_upgrade升级  
详见     
    
[《PostgreSQL 快速大版本升级多种方案 - 含重点介绍fast & safe upgrade to PostgreSQL 9.4 use pg_upgrade & zfs》](../201412/20141219_01.md)    
    
[《PostgreSQL pg_upgrade 9.3 improve and example》](../201305/20130520_01.md)    
    
    
    
    
    
    
    
    
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
