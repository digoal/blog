## PostgreSQL 12 AM 之 - blackhole 黑洞存储引擎  
                                                                                                                                                      
### 作者                                                                                                                                                      
digoal                                                                                                                                                      
                                                                                                                                                      
### 日期                                                                                                                                                      
2019-06-07                                                                                                                                                      
                                                                                                                                                      
### 标签                                                                                                                                                      
PostgreSQL , am , 存储引擎 , 黑洞 , blackhole   
                                                                     
----                                                                                                                                                
                                                                                                                                                  
## 背景   
PostgreSQL 12开放AM接口，用户可以自己写数据存储引擎，索引引擎。  
  
[《PostgreSQL 基于access method api的列存zedstore》](../201905/20190531_03.md)    
  
[《PostgreSQL 12 preview - 意义重大改进：增加一层access manager API - 支持 TABLE、INDEX AM(access method) - 为storage  pluggable 开路》](../201903/20190331_03.md)    
  
blackhole 是一个示例数据存储引擎，黑洞，数据写入这个数据存储引擎会被直接忽略。    
  
https://github.com/michaelpq/pg_plugins/tree/master/blackhole_am  
  
## 例子  
1、部署pg 12  
  
```  
wget https://ftp.postgresql.org/pub/snapshot/dev/postgresql-snapshot.tar.bz2  
  
tar -jxvf postgresql-snapshot.tar.bz2  
  
cd postgresql-12beta1/  
  
./configure --prefix=/home/pg12/pgsql12  
  
make world -j 128  
  
make install-world  
```  
  
```  
vi ~/.bash_profile  
export PS1="$USER@`/bin/hostname -s`-> "      
export PGPORT=12000  
export PGDATA=/data01/pg12/pg_root$PGPORT      
export LANG=en_US.utf8      
export PGHOME=/home/pg12/pgsql12  
export LD_LIBRARY_PATH=$PGHOME/lib:/lib64:/usr/lib64:/usr/local/lib64:/lib:/usr/lib:/usr/local/lib:$LD_LIBRARY_PATH      
export DATE=`date +"%Y%m%d%H%M"`    
export PATH=$PGHOME/bin:$PATH:.      
export MANPATH=$PGHOME/share/man:$MANPATH      
export PGHOST=$PGDATA      
export PGUSER=postgres      
export PGDATABASE=postgres      
alias rm='rm -i'      
alias ll='ls -lh'      
unalias vi  
```  
  
  
```  
. ~/.bash_profile  
```  
  
2、部署blackhole_am存储引擎  
  
```  
git clone https://github.com/michaelpq/pg_plugins  
cd pg_plugins  
cd blackhole_am/  
make  
make install  
```  
  
3、初始化12数据  
  
  
```  
initdb -D $PGDATA -U postgres -E UTF8 --lc-collate=C --lc-ctype=en_US.utf8   
```  
  
4、配置12数据库  
  
```  
vi $PGDATA/postgresql.conf  
```  
  
```  
listen_addresses = '0.0.0.0'            # what IP address(es) to listen on;  
port = 12000                            # (change requires restart)  
max_connections = 1000                  # (change requires restart)  
superuser_reserved_connections = 3      # (change requires restart)  
unix_socket_directories = '.,/tmp'      # comma-separated list of directories  
unix_socket_permissions = 0700          # begin with 0 to use octal notation  
tcp_keepalives_idle = 45                # TCP_KEEPIDLE, in seconds;  
tcp_keepalives_interval = 10            # TCP_KEEPINTVL, in seconds;  
tcp_keepalives_count = 10               # TCP_KEEPCNT;  
shared_buffers = 32GB                   # min 128kB  
max_prepared_transactions = 2000                # zero disables the feature  
work_mem = 8MB                          # min 64kB  
maintenance_work_mem = 2GB              # min 1MB  
dynamic_shared_memory_type = posix      # the default is the first option  
max_files_per_process = 10000           # min 25  
vacuum_cost_delay = 0                   # 0-100 milliseconds (0 disables)  
bgwriter_delay = 10ms                   # 10-10000ms between rounds  
bgwriter_lru_maxpages = 1000            # max buffers written/round, 0 disables  
bgwriter_lru_multiplier = 10.0          # 0-10.0 multiplier on buffers scanned/round  
effective_io_concurrency = 0            # 1-1000; 0 disables prefetching  
max_worker_processes = 128              # (change requires restart)  
max_parallel_maintenance_workers = 8    # taken from max_parallel_workers  
max_parallel_workers_per_gather = 0     # taken from max_parallel_workers  
parallel_leader_participation = off  
max_parallel_workers = 64               # maximum number of max_worker_processes that  
wal_level = replica  # minimal, replica, or logical  
synchronous_commit = off                # synchronization level;  
full_page_writes = on                   # recover from partial page writes  
wal_compression = on                    # enable compression of full-page writes  
wal_init_zero = on                      # zero-fill new WAL files  
wal_recycle = on                        # recycle WAL files  
wal_buffers = 32MB                      # min 32kB, -1 sets based on shared_buffers  
wal_writer_delay = 10ms         # 1-10000 milliseconds  
checkpoint_timeout = 35min              # range 30s-1d  
max_wal_size = 64GB  
min_wal_size = 16GB  
checkpoint_completion_target = 0.2      # checkpoint target duration, 0.0 - 1.0  
archive_mode = off              # enables archiving; off, on, or always  
max_wal_senders = 10            # max number of walsender processes  
enable_partitionwise_join = on  
enable_partitionwise_aggregate = on  
random_page_cost = 1.1                  # same scale as above  
effective_cache_size = 400GB  
jit = off                               # allow JIT compilation  
log_destination = 'csvlog'              # Valid values are combinations of  
logging_collector = on          # Enable capturing of stderr and csvlog  
log_filename = 'postgresql-%H.log'      # log file name pattern,  
log_truncate_on_rotation = on           # If on, an existing log file with the  
log_rotation_age = 1h                   # Automatic rotation of logfiles will  
log_rotation_size = 100MB               # Automatic rotation of logfiles will  
log_min_duration_statement = 1s # logs statements and their durations  
log_checkpoints = on  
log_connections = on  
log_disconnections = on  
log_error_verbosity = verbose  # terse, default, or verbose messages  
log_lock_waits = on                     # log lock waits >= deadlock_timeout  
log_statement = 'ddl'                   # none, ddl, mod, all  
log_timezone = 'PRC'  
track_io_timing = on  
track_functions = pl                    # none, pl, all  
log_autovacuum_min_duration = 0 # -1 disables, 0 logs all actions and  
autovacuum_vacuum_scale_factor = 0.02   # fraction of table size before vacuum  
autovacuum_analyze_scale_factor = 0.01  # fraction of table size before analyze  
autovacuum_freeze_max_age = 1200000000  # maximum XID age before forced vacuum  
autovacuum_multixact_freeze_max_age = 1400000000        # maximum multixact age  
autovacuum_vacuum_cost_delay = 0ms      # default vacuum cost delay for  
vacuum_freeze_table_age = 250000000  
vacuum_multixact_freeze_table_age = 250000000  
datestyle = 'iso, mdy'  
timezone = 'PRC'  
lc_messages = 'en_US.utf8'                      # locale for system error message  
lc_monetary = 'en_US.utf8'                      # locale for monetary formatting  
lc_numeric = 'en_US.utf8'                       # locale for number formatting  
lc_time = 'en_US.utf8'                          # locale for time formatting  
default_text_search_config = 'pg_catalog.english'  
```  
  
5、启动  
  
```  
pg_ctl start  
```  
  
6、安装blackhole_am存储引擎插件  
  
```  
postgres=# create extension blackhole_am ;  
CREATE EXTENSION  
```  
  
可以查到，目前支持了blackhole_am table 存储引擎  
  
```  
postgres=# \dA+  
                                List of access methods  
     Name     | Type  |       Handler        |              Description                 
--------------+-------+----------------------+----------------------------------------  
 blackhole_am | Table | blackhole_am_handler | template table AM eating all data  
 brin         | Index | brinhandler          | block range index (BRIN) access method  
 btree        | Index | bthandler            | b-tree index access method  
 gin          | Index | ginhandler           | GIN index access method  
 gist         | Index | gisthandler          | GiST index access method  
 hash         | Index | hashhandler          | hash index access method  
 heap         | Table | heap_tableam_handler | heap table access method  
 spgist       | Index | spghandler           | SP-GiST index access method  
(8 rows)  
```  
  
7、一些测试  
  
写入黑洞引擎测试  
  
```  
postgres=# \timing  
Timing is on.  
  
postgres=# create table test(id int) using blackhole_am;  
CREATE TABLE  
Time: 1.157 ms  
postgres=# insert into test select generate_series(1,10000000);  
INSERT 0 10000000  
Time: 990.184 ms  
postgres=# insert into test select generate_series(1,100000000);  
INSERT 0 100000000  
Time: 9885.936 ms (00:09.886)  
postgres=# insert into test select generate_series(1,100000000);  
INSERT 0 100000000  
Time: 9889.912 ms (00:09.890)  
```  
  
写入HEAP引擎测试  
  
```  
postgres=# create unlogged table test1 (id int);  
CREATE TABLE  
Time: 1.587 ms  
postgres=# insert into test1 select generate_series(1,100000000);  
INSERT 0 100000000  
Time: 42083.534 ms (00:42.084)  
```  
  
可以看到黑洞引擎的数据直接被抛弃，而HEAP引擎的数据存储下来。  
  
```  
postgres=# \dt+ test*  
                     List of relations  
 Schema | Name  | Type  |  Owner   |  Size   | Description   
--------+-------+-------+----------+---------+-------------  
 public | test  | table | postgres | 0 bytes |   
 public | test1 | table | postgres | 3458 MB |   
(2 rows)  
```  
  
```returning *```语法支持。  
  
```  
postgres=# insert into test values (1) returning *;  
 id   
----  
  1  
(1 row)  
  
INSERT 0 1  
Time: 0.335 ms  
postgres=# select * from test;  
 id   
----  
(0 rows)  
  
Time: 0.381 ms  
postgres=# update test set id=1;  
UPDATE 0  
Time: 0.426 ms  
postgres=# update test set id=1 returning *;  
 id   
----  
(0 rows)  
  
UPDATE 0  
Time: 0.236 ms  
```  
  
copy 支持  
  
```  
postgres=# copy (select generate_series(1,10000)) to '/tmp/test';  
COPY 10000  
Time: 2.055 ms  
  
postgres=# copy test from '/tmp/test';  
COPY 10000  
Time: 3.411 ms  
postgres=# select count(*) from test;  
 count   
-------  
     0  
(1 row)  
  
Time: 0.512 ms  
```  
  
### 黑洞性能测试  
```  
vi test.sql  
  
insert into test select generate_series(1,1000);  
```  
  
```  
pg12@pg11-test-> pgbench -M prepared -n -r -P 1 -f ./test.sql -c 64 -j 64 -T 120  
  
transaction type: ./test.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 64  
number of threads: 64  
duration: 120 s  
number of transactions actually processed: 26692255  
latency average = 0.287 ms  
latency stddev = 0.014 ms  
tps = 222423.280053 (including connections establishing)  
tps = 222445.784854 (excluding connections establishing)  
statement latencies in milliseconds:  
         0.241  insert into test select generate_series(1,1000);  
```  
  
每秒约写入2.22亿行。  
  
非批量如下：   
  
```
transaction type: ./test.sql
scaling factor: 1
query mode: prepared
number of clients: 64
number of threads: 64
duration: 120 s
number of transactions actually processed: 144621367
latency average = 0.053 ms
latency stddev = 0.006 ms
tps = 1205028.340511 (including connections establishing)
tps = 1205182.864303 (excluding connections establishing)
statement latencies in milliseconds:
         0.045  insert into test values (1);
```
    
  
### RULE与触发器测试  
1、RULE on 黑洞表测试  
  
```  
postgres=# truncate test1;  
  
postgres=# create rule r1 as on insert to test do also insert into test1 values (new.*);  
CREATE RULE  
postgres=# insert into test values (1);  
INSERT 0 1  
postgres=# select count(*) from test;  
 count   
-------  
     0  
(1 row)  
postgres=# select count(*) from test1;  
 count   
-------  
     1  
(1 row)  
```  
  
2、trigger on 黑洞表测试  
  
```  
postgres=# drop rule r1 ON test ;  
DROP RULE  
```  
  
```  
postgres=# create or replace function tg() returns trigger as $$  
declare  
begin  
  insert into test1 values (new.*);   
  return new;  
end;  
$$ language plpgsql strict;  
CREATE FUNCTION  
```  
  
```  
postgres=# create trigger tg1 before insert on test for each row execute function tg();  
CREATE TRIGGER  
```  
  
  
```  
postgres=# insert into test values (2);  
INSERT 0 1  
postgres=# select * from test;  
 id   
----  
(0 rows)  
  
postgres=# select * from test1;  
 id   
----  
  1  
  2  
(2 rows)  
```  
  
因为仅结构存在，after trigger返回NULL。  
  
```  
postgres=# drop trigger tg1 ON test ;  
DROP TRIGGER  
postgres=# create trigger tg1 after insert on test for each row execute function tg();  
CREATE TRIGGER  
  
  
postgres=# insert into test values (3);  
INSERT 0 1  
postgres=# select * from test1;  
 id   
----  
  1  
  2  
     
(3 rows)  
```  
  
## 黑洞引擎应用  
例如  
  
演练，真实数据引流  
  
遇到攻击时，吸引流量，每秒可吸引2.22亿行写入流量（批量，非批量约120万行/s写入流量） .    
  
测试  
  
...  
  
PG 12开放am后，未来会看到更多的PG存储引擎的加入，例如列存。  
  
## 参考  
https://github.com/michaelpq/pg_plugins/tree/master/blackhole_am  
  
[《PostgreSQL 基于access method api的列存zedstore》](../201905/20190531_03.md)    
  
[《PostgreSQL 12 preview - 意义重大改进：增加一层access manager API - 支持 TABLE、INDEX AM(access method) - 为storage  pluggable 开路》](../201903/20190331_03.md)    
  
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
