## PostgreSQL merge join 扫描方法实例细说，以及SQL写法注意 或 内核优化建议 - query rewrite  
                                                                           
### 作者                                                                           
digoal                                                                           
                                                                           
### 日期                                                                           
2019-07-13                                                                        
                                                                           
### 标签                                                                           
PostgreSQL , mergejoin , 扫描方法 , 写法注意 , query rewrite , 内核优化      
                                                                           
----                                                                           
                                                                           
## 背景    
PostgreSQL 支持三种JOIN方法，它们分别是nestloop, hash, merge join.   
  
https://www.postgresql.org/docs/12/planner-optimizer.html  
  
nested loop join:   
  
```
The right relation is scanned once for every row found in the left relation.   
This strategy is easy to implement but can be very time consuming.   
(However, if the right relation can be scanned with an index scan, this can be a good strategy.   
It is possible to use values from the current row of the left relation as keys for the index scan of the right.)  
```
  
merge join:   
  
```
Each relation is sorted on the join attributes before the join starts.   
Then the two relations are scanned in parallel, and matching rows are combined to form join rows.   
This kind of join is more attractive because each relation has to be scanned only once.   
The required sorting might be achieved either by an explicit sort step,   
or by scanning the relation in the proper order using an index on the join key.  
```
  
hash join:   
  
```
the right relation is first scanned and loaded into a hash table,   
using its join attributes as hash keys.   
Next the left relation is scanned and the appropriate values of every row   
found are used as hash keys to locate the matching rows in the table.  
```
  
关于merge join，按JOIN KEY顺序扫描，两个JOIN对象都只扫描一次。  
  
但是当其中一个表有过滤条件时，会怎么样呢？扫描范围如何？  
  
## 例子  
创建两个测试表，JOIN字段创建索引。每个表1000万条记录。  
  
```  
create table tbl1 (id int, info text);  
create table tbl2 (id int, info text);  
  
insert into tbl1 select generate_series(1,10000000),'test';  
insert into tbl2 select * from tbl1;  
  
create index idx_tbl1_1 on tbl1(id);  
create index idx_tbl2_1 on tbl2(id);  
```  
  
JOIN查询，JOIN字段包含索引。  
  
其中一个表的JOIN字段包含WHERE过滤条件。另一个表的JOIN字段不包含过滤条件。  
  
```  
select count(*) from tbl1 join tbl2 on (tbl1.id=tbl2.id and tbl1.id between 2000000 and 2090000);  
  
select count(*) from tbl1 join tbl2 on (tbl1.id=tbl2.id) where tbl1.id between 2000000 and 2090000;  
```  
  
执行计划如下，  
  
tbl1带过滤条件，在索引扫描时直接过滤。90001条。没有额外扫描的记录。  
  
tbl2未带WHERE条件，从索引头部（索引顺序对齐，例如都是asc或都是desc的头部开始扫）开始扫描，直到超出匹配范围。（第一条匹配的记录是id=2000000，所以从索引头部扫描到这条匹配的记录，扫描了2000000行。），到超出匹配时，实际上已经额外扫描了2000000行。  
  
```  
postgres=# explain (analyze,verbose,timing,costs,buffers) select count(*) from tbl1 join tbl2 on (tbl1.id=tbl2.id and tbl1.id between 2000000 and 2090000);  
  
  
									   
									 QUERY PLAN                                                                            
-------------------------------------------------------------------------------------------------------------------------------------------------------------  
 Aggregate  (cost=208513.83..208513.84 rows=1 width=8) (actual time=354.075..354.075 rows=1 loops=1)  
   Output: count(*)  
   Buffers: shared hit=5716 read=248  
   I/O Timings: read=1.811  
   ->  Merge Join  (cost=0.95..208293.85 rows=87990 width=0) (actual time=306.532..348.407 rows=90001 loops=1)  
         Merge Cond: (tbl1.id = tbl2.id)  
         Buffers: shared hit=5716 read=248  
         I/O Timings: read=1.811  
         ->  Index Only Scan using idx_tbl1_1 on public.tbl1  (cost=0.43..2026.43 rows=87990 width=4) (actual time=0.068..11.605 rows=90001 loops=1) 带where条件，直接索引过滤  
               Output: tbl1.id  
               Index Cond: ((tbl1.id >= 2000000) AND (tbl1.id <= 2090000))  带where条件，直接索引过滤  
               Heap Fetches: 0  
               Buffers: shared hit=2 read=248  
               I/O Timings: read=1.811  
         ->  Index Only Scan using idx_tbl2_1 on public.tbl2  (cost=0.43..180167.26 rows=10000175 width=4) (actual time=0.018..190.092 rows=2090001 loops=1) 不带where条件，从索引头扫到尾  
               Output: tbl2.id  
               Heap Fetches: 0  
               Buffers: shared hit=5714  不带where条件，从索引头扫到尾  
 Planning Time: 0.349 ms  
 Execution Time: 354.254 ms  
(20 rows)  
  
postgres=# explain (analyze,verbose,timing,costs,buffers) select count(*) from tbl1 join tbl2 on (tbl1.id=tbl2.id) where tbl1.id between 2000000 and 2090000;  
                                                                         QUERY PLAN                                                                            
-------------------------------------------------------------------------------------------------------------------------------------------------------------  
 Aggregate  (cost=208513.83..208513.84 rows=1 width=8) (actual time=347.461..347.461 rows=1 loops=1)  
   Output: count(*)  
   Buffers: shared hit=5964  
   ->  Merge Join  (cost=0.95..208293.85 rows=87990 width=0) (actual time=302.083..341.707 rows=90001 loops=1)  
         Merge Cond: (tbl1.id = tbl2.id)  
         Buffers: shared hit=5964  
         ->  Index Only Scan using idx_tbl1_1 on public.tbl1  (cost=0.43..2026.43 rows=87990 width=4) (actual time=0.053..9.650 rows=90001 loops=1)  带where条件，直接索引过滤  
               Output: tbl1.id  
               Index Cond: ((tbl1.id >= 2000000) AND (tbl1.id <= 2090000))  带where条件，直接索引过滤  
               Heap Fetches: 0  
               Buffers: shared hit=250  
         ->  Index Only Scan using idx_tbl2_1 on public.tbl2  (cost=0.43..180167.26 rows=10000175 width=4) (actual time=0.012..185.742 rows=2090001 loops=1)  不带where条件，从索引头扫到尾  
               Output: tbl2.id  
               Heap Fetches: 0  
               Buffers: shared hit=5714  不带where条件，从索引头扫到尾  
 Planning Time: 0.326 ms  
 Execution Time: 347.499 ms  
(17 rows)  
```  
  
调整条件，符合条件的记录依旧是90001条，但是起始ID调大或调小，由于mergejoin的扫描方法中不带过滤条件的表是从头扫到尾部，所以ID越大，浪费的扫描记录越多。  
  
如下：  
  
QUERY 1： tbl2总共扫描了9090001行。  
  
QUERY 2： tbl2总共扫描了1090001行。  
  
```  
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from tbl1 join tbl2 on (tbl1.id=tbl2.id and tbl1.id between 9000000 and 9090000);  
                                                                    QUERY PLAN                                                                       
---------------------------------------------------------------------------------------------------------------------------------------------------  
 Merge Join  (cost=0.96..262580.78 rows=82034 width=18) (actual time=2023.362..2079.127 rows=90001 loops=1)  
   Output: tbl1.id, tbl1.info, tbl2.id, tbl2.info  
   Merge Cond: (tbl1.id = tbl2.id)  
   Buffers: shared hit=74712  
   ->  Index Scan using idx_tbl1_1 on public.tbl1  (cost=0.43..2332.71 rows=82034 width=9) (actual time=0.021..14.901 rows=90001 loops=1)  带where条件，直接索引过滤  
         Output: tbl1.id, tbl1.info  
         Index Cond: ((tbl1.id >= 9000000) AND (tbl1.id <= 9090000))  带where条件，直接索引过滤  
         Buffers: shared hit=737  
   ->  Index Scan using idx_tbl2_1 on public.tbl2  (cost=0.43..234222.36 rows=10000175 width=9) (actual time=0.007..1378.680 rows=9090001 loops=1) 不带where条件，从索引头扫到尾  
         Output: tbl2.id, tbl2.info  
         Buffers: shared hit=73975 不带where条件，从索引头扫到尾  
 Planning Time: 0.403 ms  
 Execution Time: 2083.441 ms  
(13 rows)  
  
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from tbl1 join tbl2 on (tbl1.id=tbl2.id and tbl1.id between 1000000 and 1090000);  
                                                                    QUERY PLAN                                                                      
--------------------------------------------------------------------------------------------------------------------------------------------------  
 Merge Join  (cost=0.96..263354.20 rows=100935 width=18) (actual time=225.665..281.209 rows=90001 loops=1)  
   Output: tbl1.id, tbl1.info, tbl2.id, tbl2.info  
   Merge Cond: (tbl1.id = tbl2.id)  
   Buffers: shared hit=9609  
   ->  Index Scan using idx_tbl1_1 on public.tbl1  (cost=0.43..2869.93 rows=100935 width=9) (actual time=0.020..14.829 rows=90001 loops=1) 带where条件，直接索引过滤  
         Output: tbl1.id, tbl1.info  
         Index Cond: ((tbl1.id >= 1000000) AND (tbl1.id <= 1090000))  带where条件，直接索引过滤  
         Buffers: shared hit=736  
   ->  Index Scan using idx_tbl2_1 on public.tbl2  (cost=0.43..234222.36 rows=10000175 width=9) (actual time=0.007..165.857 rows=1090001 loops=1) 不带where条件，从索引头扫到尾  
         Output: tbl2.id, tbl2.info  
         Buffers: shared hit=8873 不带where条件，从索引头扫到尾  
 Planning Time: 0.320 ms  
 Execution Time: 285.484 ms  
(13 rows)  
```  
  
优化方法:  
  
1、调整SQL，把tbl2的条件 也带上。  
  
那么就直接在索引中过滤了，效率急剧提升。  
  
```  
postgres=# explain (analyze,verbose,timing,costs,buffers) select count(*) from tbl1 join tbl2 on (tbl1.id=tbl2.id) where tbl1.id between 2000000 and 2090000 and tbl2.id between 2000000 and 2090000;  
                                                                     QUERY PLAN                                                                        
-----------------------------------------------------------------------------------------------------------------------------------------------------  
 Aggregate  (cost=4557.24..4557.25 rows=1 width=8) (actual time=47.634..47.634 rows=1 loops=1)  
   Output: count(*)  
   Buffers: shared hit=499 read=1  
   I/O Timings: read=0.009  
   ->  Merge Join  (cost=0.95..4555.26 rows=793 width=0) (actual time=0.063..41.903 rows=90001 loops=1)  
         Merge Cond: (tbl1.id = tbl2.id)  
         Buffers: shared hit=499 read=1  
         I/O Timings: read=0.009  
         ->  Index Only Scan using idx_tbl1_1 on public.tbl1  (cost=0.43..2026.43 rows=87990 width=4) (actual time=0.019..10.119 rows=90001 loops=1) 带where条件，直接索引过滤  
               Output: tbl1.id  
               Index Cond: ((tbl1.id >= 2000000) AND (tbl1.id <= 2090000)) 带where条件，直接索引过滤  
               Heap Fetches: 0  
               Buffers: shared hit=250  
         ->  Index Only Scan using idx_tbl2_1 on public.tbl2  (cost=0.43..2075.75 rows=90126 width=4) (actual time=0.041..10.355 rows=90001 loops=1) 带where条件，直接索引过滤  
               Output: tbl2.id   
               Index Cond: ((tbl2.id >= 2000000) AND (tbl2.id <= 2090000)) 带where条件，直接索引过滤  
               Heap Fetches: 0  
               Buffers: shared hit=249 read=1  
               I/O Timings: read=0.009  
 Planning Time: 0.367 ms  
 Execution Time: 47.671 ms  
(21 rows)  
  
  
explain (analyze,verbose,timing,costs,buffers) select * from tbl1 join tbl2 on (tbl1.id=tbl2.id and tbl1.id between 9000000 and 9090000 and tbl2.id between 9000000 and 9090000);  
                                                                QUERY PLAN                                                                  
------------------------------------------------------------------------------------------------------------------------------------------  
 Merge Join  (cost=0.96..5511.08 rows=786 width=18) (actual time=0.031..57.417 rows=90001 loops=1)  
   Output: tbl1.id, tbl1.info, tbl2.id, tbl2.info  
   Merge Cond: (tbl1.id = tbl2.id)  
   Buffers: shared hit=1474  
   ->  Index Scan using idx_tbl1_1 on public.tbl1  (cost=0.43..2332.71 rows=82034 width=9) (actual time=0.014..14.820 rows=90001 loops=1) 带where条件，直接索引过滤  
         Output: tbl1.id, tbl1.info  
         Index Cond: ((tbl1.id >= 9000000) AND (tbl1.id <= 9090000)) 带where条件，直接索引过滤  
         Buffers: shared hit=737  
   ->  Index Scan using idx_tbl2_1 on public.tbl2  (cost=0.43..2725.93 rows=95855 width=9) (actual time=0.013..14.881 rows=90001 loops=1) 带where条件，直接索引过滤  
         Output: tbl2.id, tbl2.info  
         Index Cond: ((tbl2.id >= 9000000) AND (tbl2.id <= 9090000)) 带where条件，直接索引过滤  
         Buffers: shared hit=737  
 Planning Time: 0.293 ms  
 Execution Time: 61.697 ms  
(14 rows)  
```  
  
2、修改内核，支持query rewrite. 自动补上关联字段的WHERE条件。  
  
[《PostgreSQL 优化器逻辑推理能力 源码解析》](../201602/20160225_01.md)    
  
[《PostgreSQL 函数稳定性与constraint_excluded分区表逻辑推理过滤的CASE》](../201605/20160531_01.md)    
  
  
## 小结  
merge join ，左右两个join对象，扫描的范围如下：  
  
1、有过滤条件的，有索引的表，走索引精准过滤。  
  
2、没有过滤条件的，有索引的，从索引头部开始扫描，直到超出边界停止扫描。所以可能有放大。  
  
优化方法1、改写SQL  
  
优化方法2、修改内核，支持query rewrite.   
  
## 参考  
[《PostgreSQL 优化器逻辑推理能力 源码解析》](../201602/20160225_01.md)    
  
[《PostgreSQL 函数稳定性与constraint_excluded分区表逻辑推理过滤的CASE》](../201605/20160531_01.md)    
  
    
https://www.postgresql.org/docs/12/planner-optimizer.html  
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
