## PostgreSQL 13 preview - Disk Quota 功能 - add smgr block hooks  
                                                                                                                     
### 作者                                                                            
digoal                                                                                                                     
                                                                                                                     
### 日期                                                                                                                     
2020-01-01                                                                                                                  
                                                                                                                     
### 标签                                                                                                                     
PostgreSQL , disk quota , hook   
                                                                                                                     
----                                                                                                                     
                                                                                                                     
## 背景           
pg 13 将增加磁盘限制，支持：db级别，schema，用户级别，表级别。  
  
一个用户最多可用多少空间，一个db最多可用多少空间，一个表最多可用多少空间。  
  
感谢pivotal贡献的patch，首先需要在smgr管理模块中添加一些hook，当扩展block时可用进入用户定义的hook，判定是否达到quota阈值。  
  
disk quota演进：  
  
1、PostgreSQL extension for quotas:  
  
https://github.com/hlinnaka/pg_quota  
  
2、Diskquota is an extension that provides disk usage enforcement for database objects in Postgresql. Currently it supports to set quota limit on schema and role in a given database and limit the amount of disk space that a schema or a role can use.  
  
This project is inspired by Heikki's pg_quota project (link: https://github.com/hlinnaka/pg_quota) and enhance it to support different kinds of DDL and DML which may change the disk usage of database objects.  
  
Diskquota is a soft limit of disk uages. It has some delay to detect the schemas or roles whose quota limit is exceeded. Here 'soft limit' supports two kinds of encforcement: Query loading data into out-of-quota schema/role will be forbidden before query is running. Query loading data into schema/role with rooms will be cancelled when the quota limit is reached dynamically during the query is running.  
  
https://github.com/greenplum-db/diskquota  
  
3、pg 增加hook，插件化支持  
  
https://www.postgresql.org/message-id/flat/CAB0yre=RP_ho6Bq4cV23ELKxRcfhV2Yqrb1zHp0RfUPEWCnBRw@mail.gmail.com  
  
## 设计原型  
```  
Hi all,  
  
We implement disk quota feature on Postgresql as an extension(link:  
https://github.com/greenplum-db/diskquota),  
If you are interested, try and use it to limit the amount of disk space that  
a schema or a role can use in Postgresql.  
Any feedback or question are appreciated.  
  
Overview  
  
Diskquota is an extension that provides disk usage enforcement for database  
objects in Postgresql. Currently it supports to set quota limit on schema  
and role in a given database and limit the amount of disk space that a  
schema or a role can use.  
  
This project is inspired by Heikki's pg_quota project (link:  
https://github.com/hlinnaka/pg_quota) and enhance it to support different  
kinds of DDL and DML which may change the disk usage of database objects.  
  
Diskquota is a soft limit of disk uages. It has some delay to detect the  
schemas or roles whose quota limit is exceeded. Here 'soft limit' supports  
two kinds of encforcement: Query loading data into out-of-quota schema/role  
will be forbidden before query is running. Query loading data into  
schema/role with rooms will be cancelled when the quota limit is reached  
dynamically during the query is running.  
<https://github.com/greenplum-db/diskquota/blob/master/README.md#design>  
Design  
  
Diskquota extension is based on background worker framework in Postgresql.  
There are two kinds of background workers: diskquota launcher and diskquota  
worker.  
  
There is only one laucher process per database cluster(i.e. one laucher per  
postmaster). Launcher process is reponsible for manage worker processes:  
Calling RegisterDynamicBackgroundWorker() to create new workers and keep  
their handle. Calling TerminateBackgroundWorker() to terminate workers  
which are disabled when DBA modify diskquota.monitor_databases  
  
There are many worker processes, one for each database which is listed in  
diskquota.monitor_databases. Currently, we support to monitor at most 10  
databases at the same time. Worker processes are responsible for monitoring  
the disk usage of schemas and roles for the target database, and do quota  
enfocement. It will periodically (can be set via diskquota.naptime)  
recalcualte the table size of active tables, and update their corresponding  
schema or owner's disk usage. Then compare with quota limit for those  
schemas or roles. If exceeds the limit, put the corresponding schemas or  
roles into the blacklist in shared memory. Schemas or roles in blacklist  
are used to do query enforcement to cancel queries which plan to load data  
into these schemas or roles.  
<https://github.com/greenplum-db/diskquota/blob/master/README.md#active-table>Active  
table  
  
Active tables are the tables whose table size may change in the last quota  
check interval. We use hooks in smgecreate(), smgrextend() and  
smgrtruncate() to detect active tables and store them(currently  
relfilenode) in the shared memory. Diskquota worker process will  
periodically consuming active table in shared memories, convert relfilenode  
to relaton oid, and calcualte table size by calling  
pg_total_relation_size(), which will sum the size of table(including: base,  
vm, fsm, toast and index).  
<https://github.com/greenplum-db/diskquota/blob/master/README.md#enforcement>  
Enforcement  
  
Enforcement is implemented as hooks. There are two kinds of enforcement  
hooks: enforcement before query is running and enforcement during query is  
running. The 'before query' one is implemented at ExecutorCheckPerms_hook  
in function ExecCheckRTPerms() The 'during query' one is implemented at  
BufferExtendCheckPerms_hook in function ReadBufferExtended(). Note that the  
implementation of BufferExtendCheckPerms_hook will firstly check whether  
function request a new block, if not skip directyly.  
<https://github.com/greenplum-db/diskquota/blob/master/README.md#quota-setting-store>Quota  
setting store  
  
Quota limit of a schema or a role is stored in table 'quota_config' in  
'diskquota' schema in monitored database. So each database stores and  
manages its own disk quota configuration. Note that although role is a db  
object in cluster level, we limit the diskquota of a role to be database  
specific. That is to say, a role may has different quota limit on different  
databases and their disk usage is isolated between databases.  
<https://github.com/greenplum-db/diskquota/blob/master/README.md#install>  
Install  
  
   1. Add hook functions to Postgres by applying patch. It's required since  
   disk quota need to add some new hook functions in postgres core. This step  
   would be skipped after patch is merged into postgres in future.  
  
# install patch into postgres_src and rebuild postgres.  
cd postgres_src;  
git apply $diskquota_src/patch/pg_hooks.patch;  
make;  
make install;  
  
   1. Compile and install disk quota.  
  
cd $diskquota_src;  
make;  
make install;  
  
   1. Config postgresql.conf  
  
# enable diskquota in preload library.  
shared_preload_libraries = 'diskquota'  
# set monitored databases  
diskquota.monitor_databases = 'postgres'  
# set naptime (second) to refresh the disk quota stats periodically  
diskquota.naptime = 2  
# restart database to load preload library.  
pg_ctl restart  
  
   1. Create diskquota extension in monitored database.  
  
create extension diskquota;  
  
   1. Reload database configuraion  
  
# reset monitored database list in postgresql.conf  
diskquota.monitor_databases = 'postgres, postgres2'  
# reload configuration  
pg_ctl reload  
  
<https://github.com/greenplum-db/diskquota/blob/master/README.md#usage>Usage  
  
   1. Set/update/delete schema quota limit using diskquota.set_schema_quota  
  
create schema s1;  
select diskquota.set_schema_quota('s1', '1 MB');  
set search_path to s1;  
  
create table a(i int);  
# insert small data succeeded  
insert into a select generate_series(1,100);  
# insert large data failed  
insert into a select generate_series(1,10000000);  
# insert small data failed  
insert into a select generate_series(1,100);  
  
# delete quota configuration  
select diskquota.set_schema_quota('s1', '-1');  
# insert small data succeed  
select pg_sleep(5);  
insert into a select generate_series(1,100);  
reset search_path;  
  
   1. Set/update/delete role quota limit using diskquota.set_role_quota  
  
create role u1 nologin;  
create table b (i int);  
alter table b owner to u1;  
select diskquota.set_role_quota('u1', '1 MB');  
  
# insert small data succeeded  
insert into b select generate_series(1,100);  
# insert large data failed  
insert into b select generate_series(1,10000000);  
# insert small data failed  
insert into b select generate_series(1,100);  
  
# delete quota configuration  
select diskquota.set_role_quota('u1', '-1');  
# insert small data succeed  
select pg_sleep(5);  
insert into a select generate_series(1,100);  
reset search_path;  
  
   1. Show schema quota limit and current usage  
  
select * from diskquota.show_schema_quota_view;  
  
<https://github.com/greenplum-db/diskquota/blob/master/README.md#test>Test  
  
Run regression tests.  
  
cd contrib/diskquota;  
make installcheck  
  
<https://github.com/greenplum-db/diskquota/blob/master/README.md#benchmark--performence-test>Benchmark  
& Performence Test  
<https://github.com/greenplum-db/diskquota/blob/master/README.md#cost-of-diskquota-worker>Cost  
of diskquota worker  
  
During each refresh interval, the disk quota worker need to refresh the  
disk quota model.  
  
It take less than 100ms under 100K user tables with no avtive tables.  
  
It take less than 200ms under 100K user tables with 1K active tables.  
<https://github.com/greenplum-db/diskquota/blob/master/README.md#impact-on-oltp-queries>Impact  
on OLTP queries  
  
We test OLTP queries to measure the impact of enabling diskquota feature.  
The range is from 2k tables to 10k tables. Each connection will insert 100  
rows into each table. And the parallel connections range is from 5 to 25.  
Number of active tables will be around 1k.  
  
Without diskquota enabled (seconds)  
2k 4k 6k 8k 10k  
5 4.002 11.356 18.460 28.591 41.123  
10 4.832 11.988 21.113 32.829 45.832  
15 6.238 16.896 28.722 45.375 64.642  
20 8.036 21.711 38.499 61.763 87.875  
25 9.909 27.175 47.996 75.688 106.648  
  
With diskquota enabled (seconds)  
2k 4k 6k 8k 10k  
5 4.135 10.641 18.776 28.804 41.740  
10 4.773 12.407 22.351 34.243 47.568  
15 6.355 17.305 30.941 46.967 66.216  
20 9.451 22.231 40.645 61.758 88.309  
25 10.096 26.844 48.910 76.537 108.025  
  
The performance difference between with/without diskquota enabled are less  
then 2-3% in most case. Therefore, there is no significant performance  
downgrade when diskquota is enabled.  
<https://github.com/greenplum-db/diskquota/blob/master/README.md#notes>Notes  
  
   1. Drop database with diskquota enabled.  
  
If DBA enable monitoring diskquota on a database, there will be a  
connection to this database from diskquota worker process. DBA need to  
first remove this database from diskquota.monitor_databases in  
postgres.conf, and reload configuration by call pg_ctl reload. Then  
database could be dropped successfully.  
  
   1. Temp table.  
  
Diskquota supports to limit the disk usage of temp table as well. But  
schema and role are different. For role, i.e. the owner of the temp table,  
diakquota will treat it the same as normal tables and sum its table size to  
its owner's quota. While for schema, temp table is located under namespace  
'pg_temp_backend_id', so temp table size will not sum to the current  
schema's qouta.  
  
--   
Thanks  
  
Hubert Zhang, Haozhou Wang, Hao Wu, Jack WU  
```  
  
早起设计使用worker间歇性监控role/schema级别的空间使用，将已经超出阈值的role/schema加入blacklist，当新的insert/create/copy在blacklist里面的role/schema时，报错。  
  
所以比较粗糙，无法精准控制，而且也无法及时控制，所以pg 13支持会基于hook来做，smgr里面与block扩展相关的操作触发阈值可用直接在hook中拦截。  
  
```  
Hi Michael, Robert  
For you question about the hook position, I want to explain more about the  
background why we want to introduce these hooks.  
We wrote a diskquota extension <https://github.com/greenplum-db/diskquota>  
for Postgresql(which is inspired by Heikki's pg_quota  
<https://github.com/hlinnaka/pg_quota>). Diskquota extension is used to  
control the disk usage in Postgresql in a fine-grained way, which means:  
1. You could set disk quota limit at schema level or role level.  
2. A background worker will gather the current disk usage for each  
schema/role in realtime.  
3. A background worker will generate the blacklist for schema/role whose  
quota limit is exceeded.  
4. New transaction want to insert data into the schema/role in the  
blacklist will be cancelled.  
  
In step 2, gathering the current disk usage for each schema needs to sum  
disk size of all the tables in this schema. This is a time consuming  
operation. We want to use hooks in SMGR to detect the Active Table, and  
only recalculate the disk size of all the Active Tables.  
For example, the smgrextend hook indicates that you allocate a new block  
and the table need to be treated as Active Table.  
  
Do you have some better hook positions recommend to solve the above user  
case?  
Thanks in advance.  
  
Hubert  
```  
  
disk quota的引入，对数据库写入操作性能影响较小。2~3%    
  
        
## 参考        
https://commitfest.postgresql.org/26/1883/  
  
https://www.postgresql.org/message-id/flat/CAB0yre=RP_ho6Bq4cV23ELKxRcfhV2Yqrb1zHp0RfUPEWCnBRw@mail.gmail.com  
  
https://github.com/greenplum-db/diskquota  
  
https://github.com/hlinnaka/pg_quota  
  
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
  
  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
