## 作为Ceph缓存层的SSD盘故障, 如何更换?   
                                      
### 作者                                      
digoal                                      
                                      
### 日期                                      
2025-08-12                                      
                                      
### 标签                                      
PostgreSQL , PolarDB , DuckDB , 共享存储 , 块设备 , pfs , direct io , ceph , 2层存储架构 , ssd , 机械盘 , 缓存层 , 存储层 , bcache , flashcache , zfs l2arc , lvm cache      
                                      
----                                      
                                      
## 背景  
  
接上一篇:  
- [《PolarDB存算分离共享存储 : Ceph SSD+机械盘 2层存储 典型配置实践》](../202508/20250812_03.md)
  
本篇分享: 作为Ceph缓存层的SSD盘故障, 如何更换?
   
您询问的是在Ceph集群中如何更换故障的SSD盘，这涉及到cache tier中SSD OSD的替换操作。<cite/>

## SSD故障更换详细步骤

### 1. 确认故障状态

首先检查故障SSD的状态：

```bash
# 检查OSD状态
ceph osd tree
ceph osd status

# 检查具体故障OSD（假设故障OSD为osd.40）
ceph osd dump | grep osd.40
```

### 2. 标记OSD为out状态

将故障的SSD OSD标记为out，让数据迁移到其他OSD：

```bash
# 标记OSD为out（假设故障SSD OSD ID为40）
ceph osd out osd.40

# 监控数据迁移进度
ceph -w
```

### 3. 停止OSD服务

在故障主机上停止OSD服务：

```bash
# 使用cephadm停止OSD服务
ceph orch daemon stop osd.40

# 或者直接停止systemd服务
systemctl stop ceph-osd@40
```

### 4. 移除故障OSD

从集群中完全移除故障OSD：  

```bash
# 移除OSD（--replace保留OSD ID用于新设备）
ceph orch osd rm 40 --replace --zap

# 监控移除状态
ceph orch osd rm status
```

### 5. 物理更换SSD设备

- 关闭主机电源
- 更换故障的SSD设备（/dev/nvme1n1）
- 重新启动主机

### 6. 准备新SSD设备

确保新SSD设备可用：  

```bash
# 清理新设备（如果需要）
ceph orch device zap <hostname> /dev/nvme1n1

# 检查设备状态
ceph orch device ls
```

### 7. 重新部署SSD OSD

使用原有的OSD规格重新部署：  

```bash
# 应用SSD OSD规格（会自动使用被标记为destroyed的OSD ID）
ceph orch apply osd --service-id ssd_tier --dry-run

# 确认无误后执行
ceph orch apply osd --service-id ssd_tier
```

### 8. 验证新OSD状态

确认新OSD正常工作：

```bash
# 检查新OSD状态
ceph osd tree
ceph osd status

# 确认OSD已加入正确的CRUSH设备类
ceph osd crush tree --show-shadow

# 检查cache tier状态
ceph osd pool stats cache_pool
```

### 9. 重新配置cache tier（如果需要）

如果cache tier配置受到影响，重新设置：

```bash
# 检查cache tier关系
ceph osd tier ls storage_pool

# 如果需要重新设置overlay
ceph osd tier set-overlay storage_pool cache_pool
```

### 10. 监控集群恢复

监控集群健康状态和数据恢复：

```bash
# 监控集群状态
ceph health detail
ceph -s

# 监控PG恢复进度
ceph pg stat
```

## 注意事项

1. **数据安全**: 在cache tier中，SSD故障通常不会导致数据丢失，因为数据最终存储在HDD层
2. **性能影响**: SSD故障期间，缓存功能会受影响，读写性能可能下降
3. **自动化**: 使用`--replace`标志可以保留原OSD ID，简化重新部署过程  

## Notes

这个流程利用了cephadm的设备替换功能  ，可以自动化处理大部分替换步骤。由于您使用的是cache tier架构，SSD故障主要影响缓存性能，不会造成数据丢失，因为持久化数据存储在HDD层。<cite/>

  
