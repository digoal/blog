## 作为Ceph存储层的机械盘故障, 如何更换?
                                      
### 作者                                      
digoal                                      
                                      
### 日期                                      
2025-08-12                                      
                                      
### 标签                                      
PostgreSQL , PolarDB , DuckDB , 共享存储 , 块设备 , pfs , direct io , ceph , 2层存储架构 , ssd , 机械盘 , 缓存层 , 存储层 , bcache , flashcache , zfs l2arc , lvm cache      
                                      
----                                      
                                      
## 背景  
  
接上一篇:  
- [《PolarDB存算分离共享存储 : Ceph SSD+机械盘 2层存储 典型配置实践》](../202508/20250812_03.md)
  
本篇分享: 作为Ceph存储层的机械盘故障, 如何更换?
  
您询问的是在Ceph集群中如何更换故障的机械盘（HDD），这涉及到存储层中HDD OSD的替换操作。

## 机械盘故障更换详细步骤

### 1. 确认故障状态

首先检查故障HDD的状态：

```bash
# 检查OSD状态
ceph osd tree
ceph osd status

# 检查具体故障OSD（假设故障OSD为osd.5）
ceph osd dump | grep osd.5
```

### 2. 标记OSD为out状态

将故障的HDD OSD标记为out，触发数据重新平衡：

```bash
# 标记OSD为out（假设故障HDD OSD ID为5）
ceph osd out osd.5

# 监控数据迁移进度
ceph -w
ceph pg stat
```

### 3. 等待数据重新平衡完成

由于机械盘是存储层，需要等待数据完全迁移：

```bash
# 监控集群健康状态
ceph health detail

# 等待所有PG变为active+clean状态
ceph pg stat
```

### 4. 停止OSD服务

在故障主机上停止OSD服务：

```bash
# 使用cephadm停止OSD服务
ceph orch daemon stop osd.5

# 或者直接停止systemd服务
systemctl stop ceph-osd@5
```

### 5. 移除故障OSD

从集群中完全移除故障OSD：  

```bash
# 移除OSD（--replace保留OSD ID用于新设备）
ceph orch osd rm 5 --replace --zap

# 监控移除状态
ceph orch osd rm status
```

### 6. 物理更换HDD设备

- 关闭主机电源或热插拔（如果支持）
- 更换故障的HDD设备（例如/dev/sdb）
- 重新启动主机（如果需要）

### 7. 准备新HDD设备

确保新HDD设备可用：  

```bash
# 清理新设备
ceph orch device zap <hostname> /dev/sdb

# 检查设备状态
ceph orch device ls
```

### 8. 重新部署HDD OSD

使用原有的OSD规格重新部署：  

```bash
# 应用HDD OSD规格（会自动使用被标记为destroyed的OSD ID）
ceph orch apply osd --service-id hdd_tier --dry-run

# 确认无误后执行
ceph orch apply osd --service-id hdd_tier
```

### 9. 验证新OSD状态

确认新OSD正常工作：

```bash
# 检查新OSD状态
ceph osd tree
ceph osd status

# 确认OSD已加入正确的CRUSH设备类
ceph osd crush tree --show-shadow

# 检查存储池状态
ceph osd pool stats storage_pool
```

### 10. 监控集群恢复

监控集群健康状态和数据恢复：

```bash
# 监控集群状态
ceph health detail
ceph -s

# 监控PG恢复进度
ceph pg stat

# 检查数据分布
ceph osd df
```

## 重要注意事项

1. **数据安全**: 机械盘故障可能导致数据丢失，但EC编码（k=6, m=2）可以容忍最多2个OSD同时故障
2. **性能影响**: 数据重新平衡期间会影响集群性能，建议在低峰期进行
3. **容量规划**: 确保剩余OSD有足够容量承载重新分布的数据
4. **监控重要**: 密切监控重新平衡过程，确保集群健康

## 自动化替换功能

Ceph还提供了自动化设备替换功能：  

```bash
# 使用自动化替换命令
ceph orch device replace <hostname> <device-path>

# 例如：
ceph orch device replace 192.168.1.2 /dev/sdb
```

## Notes

机械盘作为存储层的替换比SSD缓存层更复杂，因为涉及实际数据的迁移。使用`--replace`标志可以保留OSD ID，简化重新部署过程。由于您使用的是EC编码配置，系统可以容忍一定数量的磁盘故障而不丢失数据。

  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
