## 为什么 vacuum 不仅清理dead tuple, 还清理clog?   
          
### 作者          
digoal          
          
### 日期          
2025-09-21          
          
### 标签          
PostgreSQL , PolarDB , DuckDB , xid wrapper , epoch , vacuum , freeze , truncate clog , clog buffer , transaction_buffers , 事务状态 , tuple header , hit bits , t_infomask , lwlock , slru , pg_stat_slru , pg_stat_activity     
          
----          
          
## 背景    
vacuum 清理 dead tuple可以理解, 但是为何要清理clog呢? 原来并不简单!  
  
下面分几个部分来进行详细说明  
- 1、何时清理clog  
- 2、清理clog的机制  
- 3、为什么要清理clog  
- 4、除了清理clog, 还有什么机制加速事务状态判断  
- 5、如何发现clog buffer 不足  
- 6、如何配置clog buffer  
  
## 1、清理clog的时机和机制  
  
### VACUUM 清理 CLOG 的时机  
  
VACUUM 清理 CLOG 的时机主要由以下几个因素决定：   
  
*核心是当vacuum freeze后推进了实例级的olddest xid时*       
  
1. **事务 ID 年龄阈值**：当表的 `relfrozenxid` 超过 `autovacuum_freeze_max_age` 时，会强制触发 autovacuum 并进行freeze  
  
2. **防止事务 ID 回卷**：系统会在距离回卷点还有 4000 万个事务时开始发出警告    
  
3. **紧急情况**：当距离回卷点少于 300 万个事务时，系统会拒绝分配新的 XID    
  
### VACUUM 清理 CLOG 的机制  
  
#### 1. 冻结截止点计算  
  
VACUUM 通过 `vacuum_get_cutoffs()` 函数计算冻结截止点：   
  
整个实例, 在此之前的dead tuple都已清理, 在此之前的所有tuple对所有事务都是可见的.   
  
注: 由于xid是32位的取值空间有限, 需要重复利用. 如果把32位的所有取值投射到一个圆上, 重复利用xid的过程中, 始终有一半的xid是过去状态, 一半是未来状态. 为了防止xid回卷, 通过移动OldestXmin来标记圆的哪边是过去, 哪边是未来.  
- 在此OldestXmin之前指过去  
- 在此OldestXmin之后指未来  
  
https://github.com/postgres/postgres/blob/REL_18_STABLE/src/backend/commands/vacuum.c  
  
**File:** src/backend/commands/vacuum.c (L1102-1105)  
```c  
/*  
 * vacuum_get_cutoffs() -- compute OldestXmin and freeze cutoff points  
 *  
 * The target relation and VACUUM parameters are our inputs.  
 *  
 * Output parameters are the cutoffs that VACUUM caller should use.  
 *  
 * Return value indicates if vacuumlazy.c caller should make its VACUUM  
 * operation aggressive.  An aggressive VACUUM must advance relfrozenxid up to  
 * FreezeLimit (at a minimum), and relminmxid up to MultiXactCutoff (at a  
 * minimum).  
 */  
bool  
vacuum_get_cutoffs(Relation rel, const VacuumParams params,  
				   struct VacuumCutoffs *cutoffs)  
{  
```  
  
#### 2. 三阶段清理过程  
  
VACUUM 采用三阶段清理机制： [6](#0-5)   
  
- **阶段 I**：扫描堆页面，修剪和冻结tuple, 并记录已修剪和冻结的tuple id给下阶段使用(在17版本后使用txid store结构来存储, 以节省空间, 防止vacuum超级大表时需要多次扫描index.)。  参考: [《PostgreSQL 17 preview - 使用TidStore数据结构存储dead tupleids, 提升vacuum效率, 为什么PG单表不建议超过8.9亿条记录?》](../202404/20240402_02.md)    
- **阶段 II**：索引清理，删除tuple id对应dead索引条目    
- **阶段 III**：堆清理，标记dead tuple为未使用(即可用空间)  
  
#### 3. CLOG 截断操作  
  
在 VACUUM 完成后，系统会调用 `vac_truncate_clog()` 来截断 CLOG：   
  
**File:** src/backend/commands/vacuum.c (L1957-1964)  
```c  
	AdvanceOldestCommitTsXid(frozenXID);  
  
	/*  
	 * Truncate CLOG, multixact and CommitTs to the oldest computed value.  
	 */  
	TruncateCLOG(frozenXID, oldestxid_datoid);  
	TruncateCommitTs(frozenXID);  
	TruncateMultiXact(minMulti, minmulti_datoid);  
```  
  
CLOG 页面的截断基于事务 ID 比较逻辑：   
  
**File:** src/backend/access/transam/clog.c (L1020-1033)  
```c  
static bool  
CLOGPagePrecedes(int64 page1, int64 page2)  
{  
	TransactionId xid1;  
	TransactionId xid2;  
  
	xid1 = ((TransactionId) page1) * CLOG_XACTS_PER_PAGE;  
	xid1 += FirstNormalTransactionId + 1;  
	xid2 = ((TransactionId) page2) * CLOG_XACTS_PER_PAGE;  
	xid2 += FirstNormalTransactionId + 1;  
  
	return (TransactionIdPrecedes(xid1, xid2) &&  
			TransactionIdPrecedes(xid1, xid2 + CLOG_XACTS_PER_PAGE - 1));  
}  
```  
  
CLOG 清理(截断)是 VACUUM 操作的重要组成部分，vacuum freeze的主要目的是防止事务 ID 回卷并回收存储空间。清理时机发生在vacuum freeze并推进了实例级OldestXmin时. vacuum freeze由多个配置参数控制，包括 `vacuum_freeze_min_age`、`vacuum_freeze_table_age` 和 `autovacuum_freeze_max_age`。整个过程通过精确的事务 ID 比较和多阶段清理机制确保数据一致性。  
  
## 2、为什么要清理(截断)clog  
  
截断 CLOG 的重要原因确实是防止 CLOG 缓存的内存空间耗尽影响性能。   
  
### CLOG 缓存内存管理  
  
CLOG 系统使用有限的共享内存缓冲区来缓存事务状态信息。系统通过 `CLOGShmemBuffers()` 函数计算缓冲区数量，默认情况下会根据 `shared_buffers` 自动调优，每 1GB 共享缓冲区分配 2MB CLOG 缓冲区，最多 8MB。    
  
**File:** src/backend/access/transam/clog.c (L758-773)  
```c  
/*  
 * Number of shared CLOG buffers.  
 *  
 * If asked to autotune, use 2MB for every 1GB of shared buffers, up to 8MB.  
 * Otherwise just cap the configured amount to be between 16 and the maximum  
 * allowed.  
 */  
static int  
CLOGShmemBuffers(void)  
{  
	/* auto-tune based on shared buffers */  
	if (transaction_buffers == 0)  
		return SimpleLruAutotuneBuffers(512, 1024);  
  
	return Min(Max(16, transaction_buffers), CLOG_MAX_ALLOWED_BUFFERS);  
}  
```  
  
### 内存限制机制  
  
CLOG 对缓冲区数量有特殊的限制： 由于每个事务在 CLOG 中只占用 2 位空间，系统设置了比通用 SLRU 更小的缓冲区限制，以 `CLOG_MAX_ALLOWED_BUFFERS` 宏定义。   
  
**File:** src/backend/access/transam/clog.c (L67-74)  
```c  
/*  
 * Because space used in CLOG by each transaction is so small, we place a  
 * smaller limit on the number of CLOG buffers than SLRU allows.  No other  
 * SLRU needs this.  
 */  
#define CLOG_MAX_ALLOWED_BUFFERS \  
	Min(SLRU_MAX_ALLOWED_BUFFERS, \  
		(((MaxTransactionId / 2) + (CLOG_XACTS_PER_PAGE - 1)) / CLOG_XACTS_PER_PAGE))  
```  
  
### 截断的性能考虑  
  
当 CLOG 缓冲区接近满载时，系统需要更频繁地从磁盘(也就是clog文件)读取旧的 CLOG 页面，这会严重影响性能。 `TruncateCLOG()` 函数通过删除不再需要的旧 CLOG 段文件来释放缓冲区空间，确保系统能够高效地访问活跃事务的状态信息。  
  
**File:** src/backend/access/transam/clog.c (L965-999)  
```c  
void  
TruncateCLOG(TransactionId oldestXact, Oid oldestxid_datoid)  
{  
	int64		cutoffPage;  
  
	/*  
	 * The cutoff point is the start of the segment containing oldestXact. We  
	 * pass the *page* containing oldestXact to SimpleLruTruncate.  
	 */  
	cutoffPage = TransactionIdToPage(oldestXact);  
  
	/* Check to see if there's any files that could be removed */  
	if (!SlruScanDirectory(XactCtl, SlruScanDirCbReportPresence, &cutoffPage))  
		return;					/* nothing to remove */  
  
	/*  
	 * Advance oldestClogXid before truncating clog, so concurrent xact status  
	 * lookups can ensure they don't attempt to access truncated-away clog.  
	 *  
	 * It's only necessary to do this if we will actually truncate away clog  
	 * pages.  
	 */  
	AdvanceOldestClogXid(oldestXact);  
  
	/*  
	 * Write XLOG record and flush XLOG to disk. We record the oldest xid  
	 * we're keeping information about here so we can ensure that it's always  
	 * ahead of clog truncation in case we crash, and so a standby finds out  
	 * the new valid xid before the next checkpoint.  
	 */  
	WriteTruncateXlogRec(cutoffPage, oldestXact, oldestxid_datoid);  
  
	/* Now we can remove the old CLOG segment(s) */  
	SimpleLruTruncate(XactCtl, cutoffPage);  
}  
```  
  
## 文档中的说明  
  
文档明确提到了这个性能考虑： 当 `autovacuum_freeze_max_age` 设置过高时，`pg_xact` 目录会占用更多空间。例如，设置为最大值 20 亿事务时，`pg_xact` 可能增长到约 0.5GB，这直接影响 CLOG 缓存的内存使用。   
  
**File:** doc/src/sgml/maintenance.sgml (L571-587)  
```text  
    (and <varname>vacuum_freeze_table_age</varname> along with it) is that  
    the <filename>pg_xact</filename> and <filename>pg_commit_ts</filename>  
    subdirectories of the database cluster will take more space, because it  
    must store the commit status and (if <varname>track_commit_timestamp</varname> is  
    enabled) timestamp of all transactions back to  
    the <varname>autovacuum_freeze_max_age</varname> horizon.  The commit status uses  
    two bits per transaction, so if  
    <varname>autovacuum_freeze_max_age</varname> is set to its maximum allowed value  
    of two billion, <filename>pg_xact</filename> can be expected to grow to about half  
    a gigabyte and <filename>pg_commit_ts</filename> to about 20GB.  If this  
    is trivial compared to your total database size,  
    setting <varname>autovacuum_freeze_max_age</varname> to its maximum allowed value  
    is recommended.  Otherwise, set it depending on what you are willing to  
    allow for <filename>pg_xact</filename> and <filename>pg_commit_ts</filename> storage.  
    (The default, 200 million transactions, translates to about 50MB  
    of <filename>pg_xact</filename> storage and about 2GB of <filename>pg_commit_ts</filename>  
    storage.)  
```  
  
CLOG 截断是一个重要的内存管理机制。通过及时清理旧的事务状态信息文件，系统能够保持 CLOG 缓冲区的高效运行，避免因内存不足导致的频繁磁盘 I/O 操作。这种设计确保了 PostgreSQL 在高并发事务环境下的性能稳定性。  
  
## 3、通过tuple header hit bits来防止经常访问clog文件  
  
除了截断 CLOG 之外，PostgreSQL 还有其他重要措施来防止频繁访问 CLOG 获取 tuple 事务状态，其中最重要的就是 hint bits（提示位）机制。   
  
### Hint Bits 机制  
  
Hint bits 是 PostgreSQL 中一个关键的性能优化机制，用于缓存事务状态信息直接在 tuple header 中。 当系统确定某个事务已经提交或中止时，会在相关 tuple 的 `t_infomask` 字段中设置相应的 hint bits，避免后续访问需要再次查询 CLOG。  
  
**File:** src/backend/access/heap/heapam_visibility.c (L6-11)  
```c  
 * NOTE: all the HeapTupleSatisfies routines will update the tuple's  
 * "hint" status bits if we see that the inserting or deleting transaction  
 * has now committed or aborted (and it is safe to set the hint bits).  
 * If the hint bits are changed, MarkBufferDirtyHint is called on  
 * the passed-in buffer.  The caller must hold not only a pin, but at least  
 * shared buffer content lock on the buffer containing the tuple.  
```  
  
用户在执行dml, 对数据库产生增删改查, 可能涉及很多行, 但是在事务结束(提交或回滚)时, 并不会立即设置这些受影响行的tuple header里的hit bits值, 而是推到后面, 所以事务结束命令可以很快完成.    
  
注: copy 命令有freeze选项, 如果设置了, 导入的tuple会被直接设置为freeze, 无需从clog判断其提交状态. 通常用于加速大批量数据导入后的查询性能(无需访问clog, 也无需修改hit bits), 例如pg_restore时.    
  
#### 主要的 Hint Bits  
  
系统使用以下几种主要的 hint bits：   
  
- `HEAP_XMIN_COMMITTED`: 表示插入事务已提交  
- `HEAP_XMIN_INVALID`: 表示插入事务已中止    
- `HEAP_XMAX_COMMITTED`: 表示删除/更新事务已提交  
- `HEAP_XMAX_INVALID`: 表示删除/更新事务已中止  
  
#### SetHintBits 函数 `SetHintBits()` 函数负责安全地设置 hint bits。该函数会检查 WAL 刷新状态，确保只有在安全的情况下才设置 hint bits，避免违反 WAL-before-data 规则。  
  
**File:** src/backend/access/heap/heapam_visibility.c (L113-132)  
```c  
static inline void  
SetHintBits(HeapTupleHeader tuple, Buffer buffer,  
			uint16 infomask, TransactionId xid)  
{  
	if (TransactionIdIsValid(xid))  
	{  
		/* NB: xid must be known committed here! */  
		XLogRecPtr	commitLSN = TransactionIdGetCommitLSN(xid);  
  
		if (BufferIsPermanent(buffer) && XLogNeedsFlush(commitLSN) &&  
			BufferGetLSNAtomic(buffer) < commitLSN)  
		{  
			/* not flushed and no LSN interlock, so don't set hint */  
			return;  
		}  
	}  
  
	tuple->t_infomask |= infomask;  
	MarkBufferDirtyHint(buffer, true);  
}  
```  
  
### 可见性检查中的 Hint Bits 使用  
  
在各种可见性检查函数中，系统会优先检查 hint bits，只有在 hint bits 未设置时才会访问 CLOG：   
  
HeapTupleSatisfiesMVCC 中的优化 : 在 MVCC 可见性检查中，系统首先检查 `HeapTupleHeaderXminCommitted(tuple)`，如果 hint bit 已设置，就无需访问 CLOG。  
  
**File:** src/backend/access/heap/heapam_visibility.c (L977-999)  
```c  
	if (!HeapTupleHeaderXminCommitted(tuple))  
	{  
		if (HeapTupleHeaderXminInvalid(tuple))  
			return false;  
  
		/* Used by pre-9.0 binary upgrades */  
		if (tuple->t_infomask & HEAP_MOVED_OFF)  
		{  
			TransactionId xvac = HeapTupleHeaderGetXvac(tuple);  
  
			if (TransactionIdIsCurrentTransactionId(xvac))  
				return false;  
			if (!XidInMVCCSnapshot(xvac, snapshot))  
			{  
				if (TransactionIdDidCommit(xvac))  
				{  
					SetHintBits(tuple, buffer, HEAP_XMIN_INVALID,  
								InvalidTransactionId);  
					return false;  
				}  
				SetHintBits(tuple, buffer, HEAP_XMIN_COMMITTED,  
							InvalidTransactionId);  
			}  
```  
  
其他可见性函数的类似优化 : 在 `HeapTupleSatisfiesVacuum` 等函数中也采用了相同的策略，优先检查 hint bits。  
  
**File:** src/backend/access/heap/heapam_visibility.c (L1221-1242)  
```c  
	if (!HeapTupleHeaderXminCommitted(tuple))  
	{  
		if (HeapTupleHeaderXminInvalid(tuple))  
			return HEAPTUPLE_DEAD;  
		/* Used by pre-9.0 binary upgrades */  
		else if (tuple->t_infomask & HEAP_MOVED_OFF)  
		{  
			TransactionId xvac = HeapTupleHeaderGetXvac(tuple);  
  
			if (TransactionIdIsCurrentTransactionId(xvac))  
				return HEAPTUPLE_DELETE_IN_PROGRESS;  
			if (TransactionIdIsInProgress(xvac))  
				return HEAPTUPLE_DELETE_IN_PROGRESS;  
			if (TransactionIdDidCommit(xvac))  
			{  
				SetHintBits(tuple, buffer, HEAP_XMIN_INVALID,  
							InvalidTransactionId);  
				return HEAPTUPLE_DEAD;  
			}  
			SetHintBits(tuple, buffer, HEAP_XMIN_COMMITTED,  
						InvalidTransactionId);  
		}  
```  
  
### 异步提交的特殊考虑   
对于异步提交事务，系统需要特别小心设置 hint bits。必须确保相关的 WAL 记录已经刷新到磁盘，才能安全地设置 transaction-committed hint bit。  
  
**File:** src/backend/access/transam/README (L822-841)  
```text  
In fact, we store more than one LSN for each clog page.  This relates to  
the way we set transaction status hint bits during visibility tests.  
We must not set a transaction-committed hint bit on a relation page and  
have that record make it to disk prior to the WAL record of the commit.  
Since visibility tests are normally made while holding buffer share locks,  
we do not have the option of changing the page's LSN to guarantee WAL  
synchronization.  Instead, we defer the setting of the hint bit if we have  
not yet flushed WAL as far as the LSN associated with the transaction.  
This requires tracking the LSN of each unflushed async commit.  It is  
convenient to associate this data with clog buffers: because we will flush  
WAL before writing a clog page, we know that we do not need to remember a  
transaction's LSN longer than the clog page holding its commit status  
remains in memory.  However, the naive approach of storing an LSN for each  
clog position is unattractive: the LSNs are 32x bigger than the two-bit  
commit status fields, and so we'd need 256K of additional shared memory for  
each 8K clog buffer page.  We choose instead to store a smaller number of  
LSNs per page, where each LSN is the highest LSN associated with any  
transaction commit in a contiguous range of transaction IDs on that page.  
This saves storage at the price of some possibly-unnecessary delay in  
setting transaction hint bits.  
```  
  
### UpdateXmaxHintBits 函数   
`UpdateXmaxHintBits()` 函数专门用于在等待 XMAX 事务结束后更新 hint bits，进一步减少后续的 CLOG 访问。  
  
**File:** src/backend/access/heap/heapam.c (L1987-2003)  
```c  
static void  
UpdateXmaxHintBits(HeapTupleHeader tuple, Buffer buffer, TransactionId xid)  
{  
	Assert(TransactionIdEquals(HeapTupleHeaderGetRawXmax(tuple), xid));  
	Assert(!(tuple->t_infomask & HEAP_XMAX_IS_MULTI));  
  
	if (!(tuple->t_infomask & (HEAP_XMAX_COMMITTED | HEAP_XMAX_INVALID)))  
	{  
		if (!HEAP_XMAX_IS_LOCKED_ONLY(tuple->t_infomask) &&  
			TransactionIdDidCommit(xid))  
			HeapTupleSetHintBits(tuple, buffer, HEAP_XMAX_COMMITTED,  
								 xid);  
		else  
			HeapTupleSetHintBits(tuple, buffer, HEAP_XMAX_INVALID,  
								 InvalidTransactionId);  
	}  
}  
```  
  
Hint bits 机制是 PostgreSQL 避免频繁 CLOG 访问的核心优化策略。通过在 tuple header 中直接缓存事务状态，系统可以显著减少对 CLOG 的访问次数，特别是在高并发场景下。这种机制与 CLOG 截断相结合，形成了完整的事务状态管理和性能优化体系。  
  
## 4、通过 pg_stat_slru 视图发现clog buffer 不足, 如何配置clog buffer?  
  
您询问的是如何观测 CLOG buffer 是否已不足。根据代码分析，PostgreSQL 提供了多种方式来监控 CLOG 缓冲区的使用情况。<cite/>  
  
### 通过 pg_stat_slru 视图观测  
  
PostgreSQL 提供了 `pg_stat_slru` 系统视图来监控 SLRU（包括 CLOG）的统计信息。 该视图包含以下关键字段来观测缓冲区状态：  
  
- `blks_zeroed`: 为此 SLRU 清零的块数  
- `blks_hit`: 此 SLRU 的缓冲区命中次数    
- `blks_read`: 为此 SLRU 读取的块数  
- `blks_written`: 为此 SLRU 写入的块数  
- `blks_exists`: 为此 SLRU 检查存在性的块数  
- `flushes`: 此 SLRU 的脏数据刷新次数  
  
### CLOG 缓冲区配置和限制  
  
CLOG 缓冲区的数量由 `CLOGShmemBuffers()` 函数确定。 系统会根据 `transaction_buffers` GUC参数或自动调优来设置缓冲区数量，最大不超过 `CLOG_MAX_ALLOWED_BUFFERS`。   
  
**File:** src/backend/access/transam/clog.c (L72-74)  
```c  
#define CLOG_MAX_ALLOWED_BUFFERS \  
	Min(SLRU_MAX_ALLOWED_BUFFERS, \  
		(((MaxTransactionId / 2) + (CLOG_XACTS_PER_PAGE - 1)) / CLOG_XACTS_PER_PAGE))  
```  
  
**File:** src/backend/access/transam/clog.c (L765-773)  
```c  
static int  
CLOGShmemBuffers(void)  
{  
	/* auto-tune based on shared buffers */  
	if (transaction_buffers == 0)  
		return SimpleLruAutotuneBuffers(512, 1024);  
  
	return Min(Max(16, transaction_buffers), CLOG_MAX_ALLOWED_BUFFERS);  
}  
```  
  
### 观测缓冲区不足的指标  
  
#### 1. 缓冲区命中率监控  
  
通过计算 `blks_hit / (blks_hit + blks_read)` 可以得到 CLOG 缓冲区的命中率。命中率过低表明缓冲区可能不足。   
  
#### 2. 读取频率监控  
  
`blks_read` 字段显示从磁盘读取 CLOG 页面的次数。如果这个值增长很快，说明缓冲区无法满足需求。   
  
#### 3. 刷新频率监控  
  
`flushes` 字段显示脏页刷新的频率。频繁的刷新可能表明缓冲区压力较大。   
  
### 实际监控查询示例  
  
您可以使用以下查询来监控 CLOG 缓冲区状态：  
  
```sql  
SELECT name, blks_hit, blks_read,   
       CASE WHEN (blks_hit + blks_read) > 0   
            THEN round(blks_hit::numeric / (blks_hit + blks_read) * 100, 2)   
            ELSE 0   
       END as hit_ratio_percent,  
       flushes, stats_reset  
FROM pg_stat_slru   
WHERE name = 'transaction';  
```  
  
### 统计函数支持  
  
系统还提供了底层的统计访问函数。  例如 `pg_stat_get_buf_alloc` 函数可以获取缓冲区分配的信息。  
  
**File:** src/include/catalog/pg_proc.dat (L5991-5993)  
```text  
{ oid => '2859', descr => 'statistics: number of buffer allocations',  
  proname => 'pg_stat_get_buf_alloc', provolatile => 's', proparallel => 'r',  
  prorettype => 'int8', proargtypes => '', prosrc => 'pg_stat_get_buf_alloc' },  
```  
  
观测 CLOG buffer 不足主要依赖 `pg_stat_slru` 视图中的统计数据。重点关注命中率、读取频率和刷新频率等指标。如果发现命中率持续偏低或读取频率过高，可能需要考虑调整 `transaction_buffers` 参数来增加 CLOG 缓冲区数量。  
  
  
## 5、通过等待事件发现clog buffer 不足   
  
`pg_stat_activity` 视图确实可以用来判断 CLOG 相关的等待事件，这也是一个很好的监控 CLOG buffer 不足的方法。   
  
### pg_stat_activity 视图中的等待事件  
  
`pg_stat_activity` 视图包含 `wait_event_type` 和 `wait_event` 字段，可以显示进程当前等待的具体事件。   
  
### CLOG 相关的等待事件类型  
  
当 CLOG buffer 不足时，可能会出现以下类型的等待事件：  
  
#### 1. LWLock 等待事件  
系统文档显示 LWLock 类型的等待事件保护共享内存中的特定数据结构。 CLOG 缓冲区访问需要获取相应的轻量级锁，当缓冲区竞争激烈时会出现 LWLock 等待。  
  
**File:** doc/src/sgml/monitoring.sgml (L1114-1121)  
```text  
      <entry><literal>LWLock</literal></entry>  
      <entry> The server process is waiting for a lightweight lock.  
       Most such locks protect a particular data structure in shared memory.  
       <literal>wait_event</literal> will contain a name identifying the purpose  
       of the lightweight lock.  (Some locks have specific names; others  
       are part of a group of locks each with a similar purpose.)  
       See <xref linkend="wait-event-lwlock-table"/>.  
      </entry>  
```  
  
#### 2. IO 等待事件  
当 CLOG buffer 不足导致频繁磁盘读取时，会出现 IO 类型的等待事件。   
  
**File:** doc/src/sgml/monitoring.sgml (L1088-1092)  
```text  
      <entry><literal>IO</literal></entry>  
      <entry>The server process is waiting for an I/O operation to complete.  
       <literal>wait_event</literal> will identify the specific wait point;  
       see <xref linkend="wait-event-io-table"/>.  
      </entry>  
```  
  
### 监控查询示例  
  
您可以使用以下查询来监控 CLOG 相关的等待事件：  
  
```sql  
SELECT pid, wait_event_type, wait_event, state, query   
FROM pg_stat_activity   
WHERE wait_event_type IN ('LWLock', 'IO')   
  AND wait_event IS NOT NULL  
  AND state = 'active';  
```  
  
### 等待事件的查看方法  
  
文档提供了查看等待事件的示例： 您可以通过查询 `pg_stat_activity` 来识别当前等待的进程和具体的等待事件。  
  
**File:** doc/src/sgml/monitoring.sgml (L1140-1146)  
```text  
SELECT pid, wait_event_type, wait_event FROM pg_stat_activity WHERE wait_event is NOT NULL;  
 pid  | wait_event_type | wait_event  
------+-----------------+------------  
 2540 | Lock            | relation  
 6644 | LWLock          | ProcArray  
(2 rows)  
</programlisting>  
```  
  
### 与 pg_wait_events 视图结合使用  
  
为了获得更详细的等待事件描述，可以将 `pg_stat_activity` 与 `pg_wait_events` 视图连接：   
  
```sql  
SELECT a.pid, a.wait_event, w.description  
FROM pg_stat_activity a   
JOIN pg_wait_events w ON (a.wait_event_type = w.type AND a.wait_event = w.name)  
WHERE a.wait_event IS NOT NULL AND a.state = 'active';  
```  
  
**File:** doc/src/sgml/monitoring.sgml (L1149-1158)  
```text  
SELECT a.pid, a.wait_event, w.description  
  FROM pg_stat_activity a JOIN  
       pg_wait_events w ON (a.wait_event_type = w.type AND  
                            a.wait_event = w.name)  
  WHERE a.wait_event is NOT NULL and a.state = 'active';  
-[ RECORD 1 ]------------------------------------------------------------------  
pid         | 686674  
wait_event  | WALInitSync  
description | Waiting for a newly initialized WAL file to reach durable storage  
</programlisting>  
```  
  
  
PostgreSQL 中有多个与 CLOG（事务提交日志）相关的等待事件。  
  
### CLOG 相关的 LWLock 等待事件  
  
在 PostgreSQL 的等待事件定义中，有几个直接与 CLOG 相关的 LWLock 等待事件：  
  
### 1. XactBuffer   
这个等待事件表示"等待事务状态 SLRU 缓冲区上的 I/O 操作"。当进程需要访问 CLOG 缓冲区但缓冲区正在进行 I/O 操作时会出现此等待。  
  
**File:** src/backend/utils/activity/wait_event_names.txt (L368-368)  
```text  
XactBuffer	"Waiting for I/O on a transaction status SLRU buffer."  
```  
  
### 2. XactSLRU    
这个等待事件表示"等待访问事务状态 SLRU 缓存"。当多个进程同时尝试访问 CLOG SLRU 缓存时会出现此等待。  
  
**File:** src/backend/utils/activity/wait_event_names.txt (L406-406)  
```text  
XactSLRU	"Waiting to access the transaction status SLRU cache."  
```  
  
### 3. XactTruncation    
这个等待事件表示"等待执行 `pg_xact_status` 或更新可用的最旧事务 ID"。这与 CLOG 截断操作相关。  
  
**File:** src/backend/utils/activity/wait_event_names.txt (L346-346)  
```text  
XactTruncation	"Waiting to execute <function>pg_xact_status</function> or update the oldest transaction ID available to it."  
```  
  
### CLOG 相关的 IO 等待事件  
  
当 CLOG 缓冲区不足导致频繁磁盘访问时，可能出现以下 IO 等待事件：  
  
#### SLRU_READ 和 SLRU_WRITE    
这些等待事件分别表示"等待读取 SLRU 页面"、"等待 SLRU 数据在页面写入后到达持久存储"和"等待写入 SLRU 页面"。  
  
**File:** src/backend/utils/activity/wait_event_names.txt (L247-249)  
```text  
SLRU_READ	"Waiting for a read of an SLRU page."  
SLRU_SYNC	"Waiting for SLRU data to reach durable storage following a page write."  
SLRU_WRITE	"Waiting for a write of an SLRU page."  
```  
  
### 监控 CLOG 等待事件的方法  
  
您可以使用以下查询来监控 CLOG 相关的等待事件：  
  
```sql  
SELECT pid, wait_event_type, wait_event, state, query   
FROM pg_stat_activity   
WHERE wait_event IN ('XactBuffer', 'XactSLRU', 'XactTruncation', 'SLRU_READ', 'SLRU_WRITE', 'SLRU_SYNC')  
  AND wait_event IS NOT NULL;  
```  
  
### 等待事件的实现机制  
  
等待事件通过 `pgstat_report_wait_start()` 函数报告：   
  
**File:** src/include/utils/wait_event.h (L68-76)  
```text  
static inline void  
pgstat_report_wait_start(uint32 wait_event_info)  
{  
	/*  
	 * Since this is a four-byte field which is always read and written as  
	 * four-bytes, updates are atomic.  
	 */  
	*(volatile uint32 *) my_wait_event_info = wait_event_info;  
}  
```  
  
系统会将等待事件信息存储为 4 字节，其中第一个字节表示等待事件类别，后续 3 字节表示具体的等待事件。    
  
**File:** src/include/utils/wait_event.h (L54-58)  
```text  
 *	as 4-bytes where first byte represents the wait event class (type of  
 *	wait, for different types of wait, refer WaitClass) and the next  
 *	3-bytes represent the actual wait event.  Currently 2-bytes are used  
 *	for wait event which is sufficient for current usage, 1-byte is  
 *	reserved for future usage.  
```  
  
  
CLOG 相关的等待事件主要集中在 LWLock 和 IO 两个类别中。通过监控这些等待事件，可以有效识别 CLOG 缓冲区不足或访问竞争的问题。结合 `pg_stat_slru` 视图的统计数据，可以全面了解 CLOG 系统的性能状况。  
  
`pg_stat_activity` 视图通过等待事件监控是判断 CLOG buffer 不足的有效方法，特别是当出现与 CLOG 访问相关的 LWLock 或 IO 等待事件时。这种方法可以实时观察到系统中因 CLOG 缓冲区竞争而阻塞的进程，是对 `pg_stat_slru` 视图统计数据的有力补充。  
  
  
  
## 参考  
https://deepwiki.com/postgres/postgres  
  
https://www.postgresql.org/docs/current/runtime-config-resource.html#RUNTIME-CONFIG-RESOURCE-MEMORY  
  
https://www.postgresql.org/docs/current/monitoring-stats.html#WAIT-EVENT-LWLOCK-TABLE  
  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
