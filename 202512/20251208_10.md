## 跟着 ParadeDB 学 AI 搜索: 4 什么是倒数排名融合？ (What is Reciprocal Rank Fusion?)      
                
### 作者                
digoal                
                
### 日期                
2025-12-08                
                
### 标签                
PostgreSQL , 搜索 , paradedb , tantivy , 语义搜索 , 关键词搜索 , ranking , 混合搜索 , RAG , RRF               
                
----                
                
## 背景           
看完 paradedb 的文档 , 我知道它也在朝着 AI 搜索数据库的方向发展.         
        
AI 搜索, 目前的共识需求是: 语义搜索 , 关键词搜索 , 标量搜索 , 混合搜索! ( 个人认为应该还要加上 图、GIS等多模态功能 )          
        
目前围绕AI 搜索需求在做的产品, 我大概总结一下:        
- PG 的插件: vectorchord + vectorchord-bm25 + pg_tokenizer        
- PG 商业发行版: 海量 vastbase 向量版、vexdb        
- PG 的插件(本文主角): paradedb        
- OceanBase SeekDB.        
- DuckDB: vss + fts         
        
好的, 话不多说, 下面就跟着 ParadeDB 文档来体系化学习一下AI 搜索        
        
https://www.paradedb.com/learn        
              
## 什么是倒数排名融合？ (What is Reciprocal Rank Fusion?)  
  
### 什么是倒数排名融合（Reciprocal Rank Fusion）？  
  
**倒数排名融合 (Reciprocal Rank Fusion, RRF)** 是一种将多个搜索结果排名列表合并为一个单一排名的技术。RRF最初是为**信息检索 (Information Retrieval)** 研究而开发的，现已成为现代搜索系统中必不可少的组成部分，它允许对多种检索方法（例如在**混合搜索 (Hybrid Search)** 应用中结合**词汇搜索 (Lexical Search)** 和**语义搜索 (Semantic Search)** 结果）进行排名。  
  
RRF的精妙之处在于其**简洁性 (simplicity)** ：它不要求对每个评分系统中的分数进行归一化处理，而是直接使用文档在排名列表中的**位次 (position/rank)** 。  
  
## RRF 的工作原理 (How RRF Works)  
  
RRF遵循一个简单的原则：在多种搜索方法中都排名靠前的文档，很可能具有真正的相关性。  
  
标准的RRF公式平等对待所有排名来源，但**加权RRF (Weighted RRF)** 允许您为每种方法分配不同的**权重 (weights)** 。  
  
例如，在结合 **BM25** 和**向量搜索 (Vector Search)** 时，您可以分别分配1.0和0.7的权重，以表明您更看重词汇意义而非语义意义。  
  
$$\text{WeightedRRF}(d) = \sum_{r \in R} w_r \cdot \frac{1}{k + rank_r(d)}$$  
  
其中：  
  
  * $d$ 是一个文档  
  * $R$ 是排名列表的集合  
  * $rank_r(d)$ 是文档 $d$ 在排名 $r$ 中的**位次 (rank)**  
  * $w_r$ 是排名 $r$ 的**权重 (weight)** （通常在0到1之间）。在非加权/传统RRF中，此值始终为1。  
  * $k$ 是一个常量（通常为60），用于控制融合行为  
  
融合过程如下：  
  
1.  从不同的检索方法中获取多个排名列表（舍弃实际的评分数值）。  
2.  计算出现在任一列表中的每个文档的RRF分数，并乘以权重（如果使用）。  
3.  合并所有文档，并根据它们的总RRF分数进行排序。  
  
未出现在某一排名中的文档对该排名的总和贡献为零。  
  
常数 $k=60$ 几乎总是被使用，因为它已被**经验证明 (empirically shown)** 在不同的数据集上表现良好。  
  
> $k$ 可以根据您的具体用例和数据特性进行调整。较低的值（20-40）会赋予靠前结果更大的影响，较高的值（80-100）会产生更平缓的贡献差异。  
> $k$ 可以根据您的**具体用例 (specific use case)** 和**数据特性 (data characteristics)** 进行调整。较低的值（20-40）会赋予**靠前结果 (top results)** 更大的影响，较高的值（80-100）会产生更平缓的**贡献差异 (contribution difference)** 。  
  
## RRF 效果好的原因 (Why RRF Works Well)  
  
RRF具有三个关键优势：  
  
  * **简洁性 (Simplicity)** ：无需训练数据、复杂的优化或归一化。易于实现且计算快速。  
  * **稳健性 (Robustness)** ：在不进行归一化的情况下适用于不同的分数尺度。能够优雅地处理部分结果。  
  * **有效性 (Effectiveness)** ：通常优于更复杂的融合技术，尤其是在结合**互补方法 (complementary methods)** 时。  
  
研究一致表明，在结合不同的检索方法（例如**关键词搜索 (keyword search)** 和**语义相似性 (semantic similarity)** ）时，RRF非常有效。  
  
  
## 何时使用 RRF (When to Use RRF)  
  
虽然RRF可以在任何需要将多个评分系统合并到一个单一查询中的时候使用，但它在以下几种情况下表现出色：  
  
  * **混合搜索系统 (Hybrid Search Systems)** ：结合**词汇搜索（BM25）(Lexical Search (BM25))** 和**语义向量搜索 (Semantic Vector Search)** ：  
      * BM25 查找特定的**关键词 (keywords)** 和**技术术语 (technical terms)**  
      * 向量搜索捕获**概念相似性 (conceptual similarity)**  
      * RRF 利用了两者的优势  
  * **多字段搜索 (Multi-Field Search)** ：对文档的不同部分进行搜索，并产生单独的排名：  
      * 标题搜索结果  
      * 正文内容结果  
      * 元数据结果  
  * **个性化 (Personalization)** ：将一般相关性与基于用户行为或偏好的**个性化信号 (personalized signals)** 相结合。  
  
## 示例：RRF 的实际应用 (Example: RRF in Action)  
  
考虑使用词汇搜索和语义搜索对 *machine learning tutorial*（机器学习教程）进行搜索：  
  
| 词汇搜索结果 (Lexical Search Results) | 位次 (Rank) | 语义搜索结果 (Semantic Search Results) | 位次 (Rank) |  
| :--- | :--- | :--- | :--- |  
| "Complete Machine Learning Tutorial Guide" | 1 | "AI and Deep Learning Fundamentals" | 1 |  
| "Tutorial: Introduction to ML Algorithms" | 2 | "Complete Machine Learning Tutorial Guide" | 2 |  
| "Python Machine Learning Handbook" | 3 | "Beginner's Guide to Neural Networks" | 3 |  
  
**RRF 计算 ( $k=60$ )：**  
  
  * "Complete ML Tutorial" 出现在两个列表中（**位次 1** 和 **2**）： $1/61 + 1/62 = 0.0326$  
  * "AI and Deep Learning" 仅出现在语义搜索中（**位次 1**）： $1/61 = 0.0164$  
  * "Tutorial: Intro to ML" 仅出现在词汇搜索中（**位次 2**）： $1/62 = 0.0161$  
  
权重允许您强调某一检索方法而弱化另一方法。例如，在混合设置中：  
  
  * BM25 可能被赋予1.0的权重，以强调**词汇精度 (lexical precision)** 。  
  * 向量搜索模型可能被赋予0.7的权重，以强调**语义相似性 (semantic similarity)** 。  
  
效果简单而强大：RRF仍然奖励排名器之间的一致性，但权重让您可以编码您最信任的信号。这使得**加权RRF (weighted RRF)** 在检索源的质量或目的有所不同的生产系统中特别有用。  
  
## 在 SQL 中的实现 (Implementation in SQL)  
  
各种数据库和搜索引擎都预先实现了 RRF，但它是一个非常简单的公式，可以很容易地在 SQL 中演示如下：  
  
```sql  
WITH fulltext AS (  
  SELECT id, RANK() OVER (ORDER BY score DESC) AS rank  
  FROM (  
    SELECT id, pdb.score(id) AS score  
    FROM mock_items  
    WHERE description @@@ 'keyboard'  
    ORDER BY pdb.score(id) DESC  
    LIMIT 20  
  )  
),  
--- Semantic search, using pgvector and cosine distance for ranking  
semantic AS (  
  SELECT  
    id,  
    RANK() OVER (ORDER BY embedding <=> '[1,2,3]') AS rank  
  FROM mock_items  
  ORDER BY embedding <=> '[1,2,3]'  
  LIMIT 20  
),  
  
-- Calculate RRF contributions from each ranker  
rrf AS (  
  SELECT id, 1.0 / (60 + rank) AS s FROM fulltext  
  UNION ALL  
  SELECT id, 1.0 / (60 + rank) AS s FROM semantic  
)  
  
-- Sum the RRF scores, order by them, and join back the original data  
SELECT  
  m.id,  
  sum(s),  
  m.description  
FROM rrf  
JOIN mock_items AS m USING (id)  
GROUP BY m.id, m.description  
ORDER BY sum(s) DESC  
LIMIT 5;  
```  
  
## 总结 (Summary)  
  
**倒数排名融合 (Reciprocal Rank Fusion)** 提供了一种优雅的解决方案，用于组合多个搜索排名，而没有基于分数的系统所带来的复杂性。它的**简洁性 (simplicity)** 、**稳健性 (robustness)** 和经证实的**有效性 (effectiveness)** 使其成为需要合并不同检索技术结果的**混合搜索系统 (hybrid search systems)** 的标准方法。  
    
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
