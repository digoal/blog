## 跟着 ParadeDB 学 AI 搜索: 6 什么是向量搜索（Vector Search）？      
                    
### 作者                    
digoal                    
                    
### 日期                    
2025-12-08                    
                    
### 标签                    
PostgreSQL , 搜索 , paradedb , tantivy , 语义搜索 , 关键词搜索 , ranking , 混合搜索 , RAG , RRF                   
                    
----                    
                    
## 背景               
看完 paradedb 的文档 , 我知道它也在朝着 AI 搜索数据库的方向发展.             
            
AI 搜索, 目前的共识需求是: 语义搜索 , 关键词搜索 , 标量搜索 , 混合搜索! ( 个人认为应该还要加上 图、GIS等多模态功能 )              
            
目前围绕AI 搜索需求在做的产品, 我大概总结一下:            
- PG 的插件: vectorchord + vectorchord-bm25 + pg_tokenizer            
- PG 商业发行版: 海量 vastbase 向量版、vexdb            
- PG 的插件(本文主角): paradedb            
- OceanBase SeekDB.            
- DuckDB: vss + fts             
            
好的, 话不多说, 下面就跟着 ParadeDB 文档来体系化学习一下AI 搜索   
            
https://www.paradedb.com/learn            
                  
## 什么是向量搜索（Vector Search）？  
  
**向量搜索（Vector Search）** ，也称为**相似性搜索（Similarity Search）** 和**语义搜索（Semantic Search）** ，侧重于根据**语义（semantic meaning）** 查找相似内容，而非精确的关键词匹配。与传统**全文搜索（Full-Text Search）** 提问“哪些文档包含这些词元（tokens）？”不同，向量搜索提问“哪些文档的含义与此相似？”  
  
这种语义理解使其在**自然语言查询（natural language queries）** 、内容推荐以及含义比精确术语更重要的应用中特别有价值。  
  
向量搜索通过三个核心组件运行：**嵌入生成（Embedding Generation）** 、**索引（Indexing）** 和**查询（Querying）** 。**嵌入生成**将文本转换为**数值向量（numerical vectors）** ，**索引**将这些向量存储在专门的数据结构中，而**查询**则使用数学相似性计算来查找最相关的内容。  
  
向量搜索和向量索引可以由专门的**向量数据库（vector databases）** （如 Pinecone）、带有向量索引的搜索引擎（如 Elasticsearch），或带有向量扩展的通用数据库（如带有 pgvector 的 PostgreSQL）提供。  
  
  
  
## 嵌入生成（Embedding Generation）  
  
**嵌入生成**是让向量搜索看似理解意图的基础。**机器学习模型（Machine learning models）** 将文本转换为捕获**语义**的**密集数值向量（dense numerical vectors）** 。这不是一门精确的科学，就像两个人对句子可能有不同的理解一样，不同的嵌入模型也可能如此。  
  
### 嵌入流程（The Embedding Pipeline）  
  
嵌入过程通过以下几个步骤将原始文本转换为可搜索的向量：  
  
* **文本预处理（Text preprocessing）** ：清洗、规范化（normalizing）和对输入文本进行分块（chunking）。由于嵌入系统无法处理大型文档，输入文本将被分解成单独嵌入的较小**块（chunks）** 。  
* **模型推理（Model inference）** ：将文本块运行通过本地或远程嵌入模型，以生成**高维向量（high-dimensional vectors）** 。  
* **向量规范化（Vector normalization）** ：对向量进行规范化，以实现一致的相似性计算。  
  
所有向量搜索系统都必须决定是本地运行嵌入模型还是使用远程 API。  
  
像 BGE-M3 或开源替代方案这样的**本地模型（Local models）** 提供了对延迟、成本和数据隐私的完全控制。您可以优化推理速度并避免按请求收取的 API 费用，但需要计算资源和模型管理。  
  
像 OpenAI 或 Anthropic 的嵌入服务这样的**远程 API（Remote APIs）** 提供了便利，无需基础设施开销。然而，它们会引入**网络延迟（network latency）** 、按请求收取的费用以及将数据发送到外部服务时潜在的隐私问题。  
  
**嵌入生成速度**直接影响用户体验。本地模型可以针对您的硬件进行优化并进行批处理以提高效率，而远程 API 则面临网络往返延迟。对于实时应用，**嵌入预计算（embedding pre-computation）** 或**缓存策略（caching strategies）** 都变得至关重要。  
  
模型的**维度（dimensionality）** 也会影响嵌入速度和存储要求：更高的维度通常意味着更高的准确性，但会带来更高的计算和存储成本。  
  
  
  
## 索引（Indexing）  
  
**索引（Indexing）** 将生成的向量存储在针对快速相似性搜索而优化的数据结构中。与构建词元**倒排索引（inverted indexes）** 的传统搜索不同，向量搜索为**高维数值数据（high-dimensional numerical data）** 创建专门的索引。这些索引允许查询有效地找到相似向量，而无需比较每一对向量。不同的索引策略针对各种性能特征进行优化：  
  
* **HNSW (Hierarchical Navigable Small World)** ：构建多层图结构，用于快速**近似搜索（approximate search）** ，并具有良好的**召回率（recall）** 。  
* **IVF (Inverted File Index)** ：使用 k-means 将向量分区成**簇（clusters）** ，只搜索相关的簇。  
* **DiskANN**：针对 **SSD 存储**进行了优化，支持在大于 RAM 的数据集上进行向量搜索。  
  
还存在许多用于特定用例的其他索引类型，每种类型都在搜索速度、准确性和内存要求之间进行权衡。  
  
### 示例：构建向量索引  
  
考虑对两个简单文档进行索引：  
  
| ID | 文本 |  
| :--- | :--- |  
| 1 | "machine learning tutorial" (机器学习教程) |  
| 2 | "AI programming guide" (AI 编程指南) |  
  
在**嵌入生成**之后，每个文档都变成一个**高维向量**：  
  
| 文档 | 向量（简化的 3D 表示） |  
| :--- | :--- |  
| 1 | [0.8, 0.3, 0.1] |  
| 2 | [0.7, 0.4, 0.2] |  
  
**向量索引（vector index）** 将这些向量及其文档 ID 一起存储，并针对快速相似性搜索操作进行了优化。索引类型的选择（**HNSW**、**IVF** 等）决定了这些向量在搜索期间的组织和访问方式。  
  
  
  
## 查询（Querying）  
  
**向量搜索**将用户查询转换为向量，并通过数学**距离计算（distance calculations）** 找到最相似的文档。  
  
过程很简单：使用相同的嵌入模型将查询转换为向量，计算与所有索引向量的**相似性得分（similarity scores）** ，并返回按相似性排名的结果。  
  
**相似性度量（Similarity measures）** 决定了向量之间的接近程度：  
  
* **余弦相似性（Cosine similarity）** ：测量向量之间的角度（最常见）。  
* **点积（Dot product）** ：同时考虑角度和大小。  
* **欧几里得距离（Euclidean distance）** ：向量空间中的直线距离。  
  
向量搜索系统通常提供额外的查询功能，例如按**元数据（metadata）** 过滤、用于提高速度的**近似搜索（approximate search）** 以及用于确保结果质量的**阈值过滤（threshold filtering）** 。  
  
需要注意的是，向量系统没有**词元（tokens）** 或单词的概念，因此不存在精确匹配和邻近性等概念。结果的正确性还取决于嵌入模型的语义理解是否与最终用户匹配。  
  
  
  
## 向量搜索的优势（Where Vector Search Excels）  
  
向量搜索在**语义理解**提供明显优势的应用中表现出色：  
  
* **内容推荐（Content recommendation）** ：查找概念上相似的内容，无论确切措辞如何。  
* **语义搜索（Semantic search）** ：像“为什么我的网站很慢？”这样的自然语言查询可以找到有关优化、性能和 CDN 的文章。  
* **检索增强生成（Retrieval-Augmented Generation，RAG）** ：为**语言模型（language models）** 查找相关的上下文文档，以提供准确、有依据的回复。  
* **多模态应用（Multimodal applications）** ：视觉相似性搜索、文本和图像之间的跨模态搜索、音频/视频内容匹配。  
  
  
  
## 向量搜索的局限性（When Vector Search Is Not Enough）  
  
虽然向量搜索擅长**语义相似性（semantic similarity）** ，但在用户需要**精确关键词匹配（exact keyword matching）** 或精确术语时，它存在局限性：  
  
* **精确关键词要求** ：产品代码、技术规格或专有名称通常需要精确的**词汇匹配（lexical matching）** 。  
* **位置查询（Positional queries）** ：向量索引没有文档中单词或位置的概念。  
  
向量搜索比传统搜索需要更多的存储和计算资源。即使在查询时，生成嵌入和计算相似性得分与 **BM25** 相比，也会增加明显的**延迟（latency）** 。  
  
在许多场景中，结合了向量搜索和传统全文搜索的**混合搜索（Hybrid search）** 方法通常能提供最佳解决方案：  
  
* **全文搜索**用于精确关键词匹配和**布尔逻辑（boolean logic）** 。  
* **向量搜索**用于语义相似性和基于概念的检索。  
* **排名算法（Ranking algorithms）** ，如**倒数排名融合（Reciprocal Rank Fusion，RRF）** ，它融合了这两种方法以实现最佳的相关性。  
  
  
  
## 总结（Summary）  
  
**向量搜索**代表了**信息检索（information retrieval）** 领域的一个不同发展方向，它通过将数据表示为**高维数值向量**并使用数学**相似性度量（similarity measures）** 进行检索，从而实现对**语义相似内容（semantically similar content）** 的发现。这种方法擅长理解含义和上下文，但无法搜索精确的单词或短语。  
  
这项技术对于需要细致理解内容关系的**推荐系统（recommendation systems）** 和**语义搜索实现（semantic search implementations）** 已变得至关重要。  
  
    
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
