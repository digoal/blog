## 大学生数据库实践课: 8 embedding 文本切分方法介绍     
                
### 作者                
digoal                
                
### 日期                
2025-12-10                
                
### 标签                
PostgreSQL , DuckDB , 语义搜索 , 向量搜索 , 关键词检索 , 全文检索 , 标量检索 , 混合搜索 , 多模态搜索 , 重排序 , embedding , document split , ORC , 大模型 , 多模态大模型 , Dify , 压力测试 , 索引优化 , 倒排向量索引 , Ivfflat , 图向量索引 , HNSW , DiskANN , 量化 , rabitq , sbq , 二值量化 , bm25 , 相关性 , 相似性 , 召回率 , pgbench , 数据集 , ann-benchmarks , 图搜索 , PGQ , 递归 , 深度优先 , 广度优先 , 最短路径 , N度关系 , LLM , Ollama                
                
----                
                
## 背景                
  
dify deepwiki:  
  
https://deepwiki.com/search/-1rag-2embedding-3embedding-4_2ef7228a-be62-4715-8e32-3a3c7e61c3f0?mode=fast    
  
```  
面向大学生通俗讲解以下内容:   
1、RAG 介绍   
2、为什么要embedding?   
3、embedding 之前为什么要对文本进行切分?   
4、文本切分的方法以及各自的优缺点介绍  
```  
  
-----  
  
# RAG技术通俗讲解  
  
## 1. RAG介绍  
  
RAG（Retrieval-Augmented Generation，检索增强生成）是一种让AI模型能够利用外部知识库来回答问题的技术。想象一下，这就像给AI一个"图书馆"，当它遇到问题时，可以先去图书馆查找相关资料，然后基于这些资料给出更准确的答案。  
  
在Dify系统中，RAG通过以下流程工作：  
1. 文档被上传到知识库  
2. 系统对文档进行分段和预处理  
3. 将分段转换为向量（embedding）存储  
4. 用户提问时，系统检索相关分段  
5. 将检索到的内容作为上下文提供给AI模型  
  
## 2. 为什么要embedding？  
  
Embedding（嵌入）是将文本转换为数学向量的过程，就像给每段文字一个"身份证号码"。这样做的原因是：  
  
- **计算机理解文字的方式**：计算机不直接理解文字，但擅长计算数字。通过embedding，文字变成了可以计算距离的向量    
- **语义相似性计算**：意思相近的文字，它们的向量在数学空间中距离也相近  
- **高效检索**：可以快速找到与问题最相关的知识片段  
  
在Dify中，embedding是高质量索引模式的核心，能帮助LLM生成更准确的答案  。  
  
## 3. embedding之前为什么要对文本进行切分？  
  
文本切分（分段）是RAG系统中的关键步骤，原因如下：  
  
- **处理长度限制**：AI模型有上下文长度限制，不能一次性处理太长的文档  
- **提高检索精度**：将长文档分成小段，可以更精确地匹配用户问题  
- **保持语义完整性**：合理的分段能保持每个片段的语义完整性  
  
正如Dify的界面说明："分段的目的是将长文本拆分成较小的段落，以便模型更有效地处理和理解。这有助于提高模型生成的结果的质量和相关性"  。  
  
## 4. 文本切分的方法及优缺点  
  
### 4.1 递归字符切分（RecursiveCharacterTextSplitter）  
  
这是最常用的切分方法，按照分隔符优先级递归切分：  
  
```python  
# 默认分隔符优先级  
separators = ["\n\n", "\n", "。", ". ", " ", ""]  
```  
  
**优点**：  
- 保持文档结构（段落 > 句子 > 单词 > 字符）  
- 语义完整性较好  
- 支持多种语言    
  
**缺点**：  
- 可能产生过长或过短的片段  
- 对特殊格式文档处理不佳  
  
### 4.2 固定分隔符切分（FixedRecursiveCharacterTextSplitter）  
  
优先使用指定的固定分隔符进行切分：  
  
```python  
def split_text(self, text: str) -> list[str]:  
    if self._fixed_separator:  
        chunks = text.split(self._fixed_separator)  
    else:  
        chunks = [text]  
```  
  
**优点**：  
- 适合结构化文档  
- 切分结果可预测  
- 支持自定义分隔符    
  
**缺点**：  
- 灵活性较差  
- 可能破坏语义完整性  
  
### 4.3 Token切分（TokenTextSplitter）  
  
基于token数量而非字符数进行切分：  
  
**优点**：  
- 更精确控制模型输入长度  
- 考虑不同语言的token差异  
  
**缺点**：  
- 可能在单词中间切分  
- 需要额外的tokenizer  
  
### 4.4 父子分段模式  
  
Dify特有的分段模式，将文档分为父块和子块：  
  
- **子块**：用于检索，更小更精确  
- **父块**：用于上下文，包含更完整信息  
  
**优点**：  
- 检索精度高  
- 上下文丰富  
- 适合复杂文档    
  
**缺点**：  
- 实现复杂  
- 存储开销大  
  
## 切分参数配置  
  
在实际应用中，还需要考虑以下参数：  
  
- **最大分段长度**：控制每个片段的大小，通常50-4000token    
- **重叠长度**：相邻片段的重叠部分，保持语义连续性，建议10%-25%    
- **分隔符**：用于切分的字符，如`\n\n`（段落）、`\n`（行）等    
  
## Notes  
  
- Dify支持自动和自定义两种分段模式，自动模式适合新手，自定义模式提供更多控制    
- 文本预处理规则包括去除多余空格、URL、停用词等，能提高检索质量    
- 高质量索引模式使用embedding模型，经济模式使用关键词，各有优劣   
    
---  

**要义图示**  

### 1. RAG 数据处理流水线

这张图展示了文档从上传到变为 AI 可搜索知识的“工业流程”，清晰标注了切分（Split）和嵌入（Embedding）所处的位置。

```mermaid
graph TD
    Doc[1\. 原始文档: PDF/Word/Markdown] --> Cleaning[2\. 文本清洗: 去除乱码/空格]
    Cleaning --> Splitting[3\. 文本切分: Chunking]
    Splitting --> Embedding[4\. 向量化: Embedding 模型]
    Embedding --> VectorDB[(5\. 向量数据库: PostgreSQL/pgvector)]
    
    User((用户提问)) --> QueryEmb[提问向量化]
    QueryEmb --> Search[向量相似度检索]
    VectorDB --> Search
    Search --> Context[召回相关片段]
    Context --> LLM[AI 生成最终回答]

    style Splitting fill:#f96,stroke:#333,stroke-width:2px
    style Embedding fill:#f96,stroke:#333,stroke-width:2px
```



### 2. 为什么需要“切分”？（语义与长度的平衡）

这张图解释了文本切分的核心矛盾：如果切得太大或太小会发生什么。

```mermaid
graph LR
    subgraph Too_Large [切分太长]
        L1[噪声多]
        L2[超出 LLM 窗口]
        L3[检索不精准]
    end

    subgraph Optimal [合理切分]
        O1[语义完整]
        O2[检索精准]
        O3[上下文丰富]
    end

    subgraph Too_Small [切分太短]
        S1[丢失背景信息]
        S2[语义碎片化]
        S3[AI 无法理解原意]
    end

    Too_Large --- Optimal --- Too_Small
```



### 3. 四种主流文本切分算法对比

通过脑图形式，帮助学生快速记忆不同切分方法的优缺点。

```mermaid
mindmap
  root((文本切分方法))
    递归字符切分
      特点: 优先级 \n\n > \n > 句号
      优点: 保持段落和句子结构
      场景: 通用文档/最推荐
    固定分隔符切分
      特点: 强行按指定符号拆分
      优点: 结果可控
      场景: 结构化表格/CSV
    Token 切分
      特点: 按模型能读入的字数切
      优点: 绝对不超出模型限制
      场景: 严格控制成本/长文本
    父子分段模式
      特点: 小块检索 + 大块生成
      优点: 兼顾精度与上下文
      场景: 复杂专业文档
```



### 4. 切分参数示意图（Chunk Size vs. Overlap）

这张图直观演示了“分段长度”与“重叠长度”是如何协同工作以保证语义不丢失的。

```mermaid
graph TD
    subgraph Document [完整文档流]
        direction LR
        C1[片段 1: Chunk 1]
        C2[片段 2: Chunk 2]
        C3[片段 3: Chunk 3]
    end

    C1 -- "重叠部分 Overlap" --> C2
    C2 -- "重叠部分 Overlap" --> C3

    %% 用普通节点模拟“底部注释”
    Note1["比如 500 Tokens"]:::note
    Note2["包含前一段末尾的 50 Tokens"]:::note
    Note3["..."]:::note

    C1 --> Note1
    C2 --> Note2
    C3 --> Note3

    classDef note fill:none,stroke:none,color:#666,font-size:12px,font-style:italic;
```
  

### 实践小贴士（给同学们的实验建议）：

1. **关于重叠（Overlap）**：为什么要重叠？想象一下，如果一个重要的事实刚好在切分点被“咔嚓”剪断了，AI 就无法理解前半句和后半句的关系。**建议重叠率设为 10%-20%**。
2. **选择切分器**：如果你不知道选哪个，**递归字符切分（RecursiveCharacterTextSplitter）** 永远是你的首选，因为它最符合人类写文章的逻辑（先分段，再分句）。
3. **调试技巧**：在 Dify 等平台上传文档后，一定要先看“预览分段”，看看你的标题是否和内容被分开了。如果分开了，说明你需要调整分隔符或增加片段长度。

  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
