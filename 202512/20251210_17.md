## 大学生数据库实践课: 8 embedding 文本切分方法介绍     
                
### 作者                
digoal                
                
### 日期                
2025-12-10                
                
### 标签                
PostgreSQL , DuckDB , 语义搜索 , 向量搜索 , 关键词检索 , 全文检索 , 标量检索 , 混合搜索 , 多模态搜索 , 重排序 , embedding , document split , ORC , 大模型 , 多模态大模型 , Dify , 压力测试 , 索引优化 , 倒排向量索引 , Ivfflat , 图向量索引 , HNSW , DiskANN , 量化 , rabitq , sbq , 二值量化 , bm25 , 相关性 , 相似性 , 召回率 , pgbench , 数据集 , ann-benchmarks , 图搜索 , PGQ , 递归 , 深度优先 , 广度优先 , 最短路径 , N度关系 , LLM , Ollama                
                
----                
                
## 背景                
  
dify deepwiki:  
  
https://deepwiki.com/search/-1rag-2embedding-3embedding-4_2ef7228a-be62-4715-8e32-3a3c7e61c3f0?mode=fast    
  
```  
面向大学生通俗讲解以下内容:   
1、RAG 介绍   
2、为什么要embedding?   
3、embedding 之前为什么要对文本进行切分?   
4、文本切分的方法以及各自的优缺点介绍  
```  
  
-----  
  
# RAG技术通俗讲解  
  
## 1. RAG介绍  
  
RAG（Retrieval-Augmented Generation，检索增强生成）是一种让AI模型能够利用外部知识库来回答问题的技术。想象一下，这就像给AI一个"图书馆"，当它遇到问题时，可以先去图书馆查找相关资料，然后基于这些资料给出更准确的答案。  
  
在Dify系统中，RAG通过以下流程工作：  
1. 文档被上传到知识库  
2. 系统对文档进行分段和预处理  
3. 将分段转换为向量（embedding）存储  
4. 用户提问时，系统检索相关分段  
5. 将检索到的内容作为上下文提供给AI模型  
  
## 2. 为什么要embedding？  
  
Embedding（嵌入）是将文本转换为数学向量的过程，就像给每段文字一个"身份证号码"。这样做的原因是：  
  
- **计算机理解文字的方式**：计算机不直接理解文字，但擅长计算数字。通过embedding，文字变成了可以计算距离的向量    
- **语义相似性计算**：意思相近的文字，它们的向量在数学空间中距离也相近  
- **高效检索**：可以快速找到与问题最相关的知识片段  
  
在Dify中，embedding是高质量索引模式的核心，能帮助LLM生成更准确的答案  。  
  
## 3. embedding之前为什么要对文本进行切分？  
  
文本切分（分段）是RAG系统中的关键步骤，原因如下：  
  
- **处理长度限制**：AI模型有上下文长度限制，不能一次性处理太长的文档  
- **提高检索精度**：将长文档分成小段，可以更精确地匹配用户问题  
- **保持语义完整性**：合理的分段能保持每个片段的语义完整性  
  
正如Dify的界面说明："分段的目的是将长文本拆分成较小的段落，以便模型更有效地处理和理解。这有助于提高模型生成的结果的质量和相关性"  。  
  
## 4. 文本切分的方法及优缺点  
  
### 4.1 递归字符切分（RecursiveCharacterTextSplitter）  
  
这是最常用的切分方法，按照分隔符优先级递归切分：  
  
```python  
# 默认分隔符优先级  
separators = ["\n\n", "\n", "。", ". ", " ", ""]  
```  
  
**优点**：  
- 保持文档结构（段落 > 句子 > 单词 > 字符）  
- 语义完整性较好  
- 支持多种语言    
  
**缺点**：  
- 可能产生过长或过短的片段  
- 对特殊格式文档处理不佳  
  
### 4.2 固定分隔符切分（FixedRecursiveCharacterTextSplitter）  
  
优先使用指定的固定分隔符进行切分：  
  
```python  
def split_text(self, text: str) -> list[str]:  
    if self._fixed_separator:  
        chunks = text.split(self._fixed_separator)  
    else:  
        chunks = [text]  
```  
  
**优点**：  
- 适合结构化文档  
- 切分结果可预测  
- 支持自定义分隔符    
  
**缺点**：  
- 灵活性较差  
- 可能破坏语义完整性  
  
### 4.3 Token切分（TokenTextSplitter）  
  
基于token数量而非字符数进行切分：  
  
**优点**：  
- 更精确控制模型输入长度  
- 考虑不同语言的token差异  
  
**缺点**：  
- 可能在单词中间切分  
- 需要额外的tokenizer  
  
### 4.4 父子分段模式  
  
Dify特有的分段模式，将文档分为父块和子块：  
  
- **子块**：用于检索，更小更精确  
- **父块**：用于上下文，包含更完整信息  
  
**优点**：  
- 检索精度高  
- 上下文丰富  
- 适合复杂文档    
  
**缺点**：  
- 实现复杂  
- 存储开销大  
  
## 切分参数配置  
  
在实际应用中，还需要考虑以下参数：  
  
- **最大分段长度**：控制每个片段的大小，通常50-4000token    
- **重叠长度**：相邻片段的重叠部分，保持语义连续性，建议10%-25%    
- **分隔符**：用于切分的字符，如`\n\n`（段落）、`\n`（行）等    
  
## Notes  
  
- Dify支持自动和自定义两种分段模式，自动模式适合新手，自定义模式提供更多控制    
- 文本预处理规则包括去除多余空格、URL、停用词等，能提高检索质量    
- 高质量索引模式使用embedding模型，经济模式使用关键词，各有优劣   
    
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
