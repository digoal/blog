## 大学生数据库实践课: 9 embedding 文本切分实操      
                  
### 作者                  
digoal                  
                  
### 日期                  
2025-12-10                  
                  
### 标签                  
PostgreSQL , DuckDB , 语义搜索 , 向量搜索 , 关键词检索 , 全文检索 , 标量检索 , 混合搜索 , 多模态搜索 , 重排序 , embedding , document split , ORC , 大模型 , 多模态大模型 , Dify , 压力测试 , 索引优化 , 倒排向量索引 , Ivfflat , 图向量索引 , HNSW , DiskANN , 量化 , rabitq , sbq , 二值量化 , bm25 , 相关性 , 相似性 , 召回率 , pgbench , 数据集 , ann-benchmarks , 图搜索 , PGQ , 递归 , 深度优先 , 广度优先 , 最短路径 , N度关系 , LLM , Ollama                  
                  
----                  
                  
## 背景                  
  
postgresml deepwiki:  
  
https://deepwiki.com/search/-1-2-3-4embedding-5embedding-t_f270b6c6-dce9-452e-847a-6cbace2e2aff?mode=fast  
  
面向大学生通俗的给出下面内容的介绍和实操:    
1、文本切分的方法以及各自的优缺点介绍;  
2、进行文本切分之前, 需要配置哪些依赖项;  
3、每种文本切分的实操;  
4、切分后的文件进行embedding;  
5、基于embedding数据进行语义搜索, 并返回TOP-N的原始内容片段;  
    
-----  
  
# 文本切分与语义搜索实操指南  
  
## 概述  
  
PostgresML提供了完整的文本处理和语义搜索解决方案，通过Korvus SDK可以轻松实现文本切分、向量化嵌入和相似度搜索  。  
  
  
  
## 1. 文本切分方法及优缺点  
  
### 主要切分方法  
  
**Recursive Character Splitter（递归字符切分器）**  
- 优点：保持段落完整性，支持重叠切分，适合大多数文档  
- 缺点：可能破坏句子结构  
- 适用场景：长文档、文章、书籍章节    
  
**其他切分器**  
- Token-based：基于词汇切分，适合处理代码  
- Semantic：基于语义切分，保持概念完整性  
  
### 配置参数  
- `chunk_size`：切分块大小（字符数）  
- `chunk_overlap`：块间重叠大小，确保上下文连续性  
  
  
  
## 2. 依赖项配置  
  
### 环境要求  
- PostgresML数据库（版本 >= 2.7.7）    
- Python >= 3.8.1 或 Node.js  
- pgvector扩展（用于向量索引）  
  
### 安装SDK  
```bash  
# Python  
pip install pgml  
  
# JavaScript    
npm install korvus  
```  
  
### 环境变量  
```bash  
export DATABASE_URL="postgresql://user:pass@host:port/db"  
```  
  
  
  
## 3. 文本切分实操  
  
### Python实现  
  
```python  
from korvus import Collection, Pipeline  
import asyncio  
  
# 创建管道配置  
pipeline = Pipeline(  
    "v1",  
    {  
        "text": {  
            "splitter": {  
                "model": "recursive_character",  
                "parameters": {  
                    "chunk_size": 1500,  
                    "chunk_overlap": 40  
                }  
            },  
            "semantic_search": {  
                "model": "Alibaba-NLP/gte-base-en-v1.5"  
            }  
        }  
    }  
)  
  
async def main():  
    collection = Collection("demo")  
    await collection.add_pipeline(pipeline)  
      
    # 上传文档（自动切分）  
    documents = [  
        {  
            "id": "1",   
            "text": "长文本内容..."  
        }  
    ]  
    await collection.upsert_documents(documents)  
```    
  
### JavaScript实现  
  
```javascript  
const korvus = require("korvus");  
  
const pipeline = korvus.newPipeline("v1", {  
  text: {  
    splitter: {   
      model: "recursive_character"   
    },  
    semantic_search: {  
      model: "mixedbread-ai/mxbai-embed-large-v1"  
    }  
  }  
});  
```    
  
  
  
## 4. 文本嵌入（Embedding）  
  
### 使用pgml.embed函数  
  
```sql  
-- 直接生成嵌入向量  
SELECT pgml.embed('Alibaba-NLP/gte-base-en-v1.5', 'passage: 文本内容');  
```    
  
### 批量处理  
  
```sql  
-- 为表中的所有文本生成嵌入  
UPDATE documents   
SET embedding = pgml.embed('mixedbread-ai/mxbai-embed-large-v1', text);  
```  
  
### 常用嵌入模型  
- `Alibaba-NLP/gte-base-en-v1.5`：通用英文模型  
- `mixedbread-ai/mxbai-embed-large-v1`：高质量多语言模型  
- `intfloat/e5-small-v2`：需要passage:前缀    
  
  
  
## 5. 语义搜索与TOP-N结果  
  
### 向量相似度搜索  
  
```python  
# 执行语义搜索  
results = await collection.vector_search(  
    {  
        "query": {  
            "fields": {  
                "text": {  
                    "query": "搜索问题",  
                    "parameters": {  
                        "prompt": "Represent this sentence for searching relevant passages: "  
                    }  
                }  
            }  
        },  
        "limit": 5  # 返回TOP-5结果  
    },  
    pipeline  
)  
```    
  
### SQL实现  
  
```sql  
-- 使用余弦相似度搜索  
WITH embedded_query AS (  
    SELECT pgml.embed('mixedbread-ai/mxbai-embed-large-v1', '搜索问题')::vector embedding  
)  
SELECT   
    text,  
    embedding <=> (SELECT embedding FROM embedded_query) as cosine_distance  
FROM documents  
ORDER BY cosine_distance  
LIMIT 5;  
```    
  
### 性能优化  
  
创建HNSW索引加速搜索：  
```sql  
CREATE INDEX ON documents   
USING hnsw (embedding vector_cosine_ops);  
```    
  
  
## 完整示例流程  
  
```python  
from korvus import Collection, Pipeline  
import asyncio  
  
async def semantic_search_pipeline():  
    # 1. 初始化  
    collection = Collection("knowledge_base")  
      
    # 2. 配置切分和嵌入管道  
    pipeline = Pipeline(  
        "v1",  
        {  
            "text": {  
                "splitter": {"model": "recursive_character"},  
                "semantic_search": {"model": "mixedbread-ai/mxbai-embed-large-v1"}  
            }  
        }  
    )  
      
    # 3. 添加管道并上传文档  
    await collection.add_pipeline(pipeline)  
    documents = [{"id": "1", "text": "文档内容..."}]  
    await collection.upsert_documents(documents)  
      
    # 4. 执行搜索  
    results = await collection.vector_search(  
        {"query": {"fields": {"text": {"query": "搜索问题"}}}, "limit": 3},  
        pipeline  
    )  
      
    return results  
  
# 运行  
results = asyncio.run(semantic_search_pipeline())  
```    
  
  
  
## Notes  
  
- 文本切分是RAG系统的关键步骤，合理的chunk_size和overlap设置影响检索效果  
- PostgresML支持多种开源嵌入模型，可根据需求选择    
- 向量索引（HNSW）对大规模数据集的性能至关重要  
- Korvus SDK简化了整个流程，自动处理切分、嵌入和搜索的复杂性    
    
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
