## 大学生数据库实践课: 9 embedding 文本切分实操      
                  
### 作者                  
digoal                  
                  
### 日期                  
2025-12-10                  
                  
### 标签                  
PostgreSQL , DuckDB , 语义搜索 , 向量搜索 , 关键词检索 , 全文检索 , 标量检索 , 混合搜索 , 多模态搜索 , 重排序 , embedding , document split , ORC , 大模型 , 多模态大模型 , Dify , 压力测试 , 索引优化 , 倒排向量索引 , Ivfflat , 图向量索引 , HNSW , DiskANN , 量化 , rabitq , sbq , 二值量化 , bm25 , 相关性 , 相似性 , 召回率 , pgbench , 数据集 , ann-benchmarks , 图搜索 , PGQ , 递归 , 深度优先 , 广度优先 , 最短路径 , N度关系 , LLM , Ollama                  
                  
----                  
                  
## 背景                  
  
postgresml deepwiki:  
  
https://deepwiki.com/search/-1-2-3-4embedding-5embedding-t_f270b6c6-dce9-452e-847a-6cbace2e2aff?mode=fast  
  
面向大学生通俗的给出下面内容的介绍和实操:    
1、文本切分的方法以及各自的优缺点介绍;  
2、进行文本切分之前, 需要配置哪些依赖项;  
3、每种文本切分的实操;  
4、切分后的文件进行embedding;  
5、基于embedding数据进行语义搜索, 并返回TOP-N的原始内容片段;  
    
-----  
  
# 文本切分与语义搜索实操指南  
  
## 概述  
  
PostgresML提供了完整的文本处理和语义搜索解决方案，通过Korvus SDK可以轻松实现文本切分、向量化嵌入和相似度搜索  。  
  
  
  
## 1. 文本切分方法及优缺点  
  
### 主要切分方法  
  
**Recursive Character Splitter（递归字符切分器）**  
- 优点：保持段落完整性，支持重叠切分，适合大多数文档  
- 缺点：可能破坏句子结构  
- 适用场景：长文档、文章、书籍章节    
  
**其他切分器**  
- Token-based：基于词汇切分，适合处理代码  
- Semantic：基于语义切分，保持概念完整性  
  
### 配置参数  
- `chunk_size`：切分块大小（字符数）  
- `chunk_overlap`：块间重叠大小，确保上下文连续性  
  
  
  
## 2. 依赖项配置  
  
### 环境要求  
- PostgresML数据库（版本 >= 2.7.7）    
- Python >= 3.8.1 或 Node.js  
- pgvector扩展（用于向量索引）  
  
### 安装SDK  
```bash  
# Python  
pip install pgml  
  
# JavaScript    
npm install korvus  
```  
  
### 环境变量  
```bash  
export DATABASE_URL="postgresql://user:pass@host:port/db"  
```  
  
  
  
## 3. 文本切分实操  
  
### Python实现  
  
```python  
from korvus import Collection, Pipeline  
import asyncio  
  
# 创建管道配置  
pipeline = Pipeline(  
    "v1",  
    {  
        "text": {  
            "splitter": {  
                "model": "recursive_character",  
                "parameters": {  
                    "chunk_size": 1500,  
                    "chunk_overlap": 40  
                }  
            },  
            "semantic_search": {  
                "model": "Alibaba-NLP/gte-base-en-v1.5"  
            }  
        }  
    }  
)  
  
async def main():  
    collection = Collection("demo")  
    await collection.add_pipeline(pipeline)  
      
    # 上传文档（自动切分）  
    documents = [  
        {  
            "id": "1",   
            "text": "长文本内容..."  
        }  
    ]  
    await collection.upsert_documents(documents)  
```    
  
### JavaScript实现  
  
```javascript  
const korvus = require("korvus");  
  
const pipeline = korvus.newPipeline("v1", {  
  text: {  
    splitter: {   
      model: "recursive_character"   
    },  
    semantic_search: {  
      model: "mixedbread-ai/mxbai-embed-large-v1"  
    }  
  }  
});  
```    
  
  
  
## 4. 文本嵌入（Embedding）  
  
### 使用pgml.embed函数  
  
```sql  
-- 直接生成嵌入向量  
SELECT pgml.embed('Alibaba-NLP/gte-base-en-v1.5', 'passage: 文本内容');  
```    
  
### 批量处理  
  
```sql  
-- 为表中的所有文本生成嵌入  
UPDATE documents   
SET embedding = pgml.embed('mixedbread-ai/mxbai-embed-large-v1', text);  
```  
  
### 常用嵌入模型  
- `Alibaba-NLP/gte-base-en-v1.5`：通用英文模型  
- `mixedbread-ai/mxbai-embed-large-v1`：高质量多语言模型  
- `intfloat/e5-small-v2`：需要passage:前缀    
  
  
  
## 5. 语义搜索与TOP-N结果  
  
### 向量相似度搜索  
  
```python  
# 执行语义搜索  
results = await collection.vector_search(  
    {  
        "query": {  
            "fields": {  
                "text": {  
                    "query": "搜索问题",  
                    "parameters": {  
                        "prompt": "Represent this sentence for searching relevant passages: "  
                    }  
                }  
            }  
        },  
        "limit": 5  # 返回TOP-5结果  
    },  
    pipeline  
)  
```    
  
### SQL实现  
  
```sql  
-- 使用余弦相似度搜索  
WITH embedded_query AS (  
    SELECT pgml.embed('mixedbread-ai/mxbai-embed-large-v1', '搜索问题')::vector embedding  
)  
SELECT   
    text,  
    embedding <=> (SELECT embedding FROM embedded_query) as cosine_distance  
FROM documents  
ORDER BY cosine_distance  
LIMIT 5;  
```    
  
### 性能优化  
  
创建HNSW索引加速搜索：  
```sql  
CREATE INDEX ON documents   
USING hnsw (embedding vector_cosine_ops);  
```    
  
  
## 完整示例流程  
  
```python  
from korvus import Collection, Pipeline  
import asyncio  
  
async def semantic_search_pipeline():  
    # 1. 初始化  
    collection = Collection("knowledge_base")  
      
    # 2. 配置切分和嵌入管道  
    pipeline = Pipeline(  
        "v1",  
        {  
            "text": {  
                "splitter": {"model": "recursive_character"},  
                "semantic_search": {"model": "mixedbread-ai/mxbai-embed-large-v1"}  
            }  
        }  
    )  
      
    # 3. 添加管道并上传文档  
    await collection.add_pipeline(pipeline)  
    documents = [{"id": "1", "text": "文档内容..."}]  
    await collection.upsert_documents(documents)  
      
    # 4. 执行搜索  
    results = await collection.vector_search(  
        {"query": {"fields": {"text": {"query": "搜索问题"}}}, "limit": 3},  
        pipeline  
    )  
      
    return results  
  
# 运行  
results = asyncio.run(semantic_search_pipeline())  
```    
  
  
  
## Notes  
  
- 文本切分是RAG系统的关键步骤，合理的chunk_size和overlap设置影响检索效果  
- PostgresML支持多种开源嵌入模型，可根据需求选择    
- 向量索引（HNSW）对大规模数据集的性能至关重要  
- Korvus SDK简化了整个流程，自动处理切分、嵌入和搜索的复杂性    
    
---  

**要义图示**  
  

### 1. 文本处理与搜索全生命周期

这张图展示了从原始文档进入系统，到最后返回搜索结果的完整闭环。

```mermaid
graph TD
    subgraph Data_Ingestion [数据入库阶段]
        Doc[原始文档] --> Splitter[文本切分 Splitter]
        Splitter --> Chunks[文本块 Chunks]
        Chunks --> Embedding[嵌入模型 Embedding]
        Embedding --> VectorDB[(PostgreSQL + pgvector)]
    end

    subgraph Query_Stage [检索阶段]
        UserQ[用户提问] --> Q_Emb[提问向量化]
        Q_Emb --> Search[向量相似度搜索]
        VectorDB --> Search
        Search --> TopN[返回 Top-N 片段]
    end

    style Splitter fill:#f96,stroke:#333
    style Embedding fill:#f96,stroke:#333
```
  

### 2. 实操环境依赖树

在开始实操前，请确保以下“基础设施”已配置妥当。

```mermaid
graph BT
    SDK[Korvus SDK / pgml] --> Python[Python 3.8+ / Node.js]
    Python --> PGML[PostgresML 2.7.7+]
    PGML --> PG[PostgreSQL 核心]
    PG --> PGV[pgvector 扩展]
    
    ENV[DATABASE_URL 环境变量] -.-> SDK
```

  

### 3. 递归字符切分器 (Recursive Character Splitter) 逻辑

通过这张图，你可以理解 `chunk_size` 和 `chunk_overlap` 是如何协同工作的。

```mermaid
graph LR
    subgraph Chunk_1 [片段 1]
        T1[文本内容 A...]
    end
    
    subgraph Overlap [重叠区域 Overlap]
        O1[...重复文本...]
    end
    
    subgraph Chunk_2 [片段 2]
        T2[...文本内容 B]
    end
    
    T1 --- O1
    O1 --- T2

    %% 模拟“跨子图注释”
    Note["重叠确保了语义的连续性，防止上下文被切断"]:::annotation

    %% 可选：用虚线连接到重叠区域（示意关联）
    Overlap -.-> Note

    classDef annotation fill:#e6f7ff,stroke:#1890ff,stroke-dasharray: 5 5, color:#1890ff, font-size:13px, font-style:italic;
```

  

### 4. 自动化管道 (Pipeline) 工作流程

使用 Korvus SDK 时，管道会自动处理切分和向量化。

```mermaid
flowchart LR
    Docs[文档列表] --> Pipeline{Pipeline 配置}
    
    subgraph Pipeline_Config [管道内部自动化]
        direction TB
        S[Splitter: recursive_character]
        M[Model: gte-base / mxbai]
    end
    
    Pipeline --> S --> M --> DB[(Vector Database)]
```

  

### 5. 语义搜索 SQL/代码 执行逻辑

这张图解释了 TOP-N 搜索时，“余弦距离”是如何决定排名先后顺序的。

```mermaid
sequenceDiagram
    participant U as 用户查询
    participant E as Embedding 函数
    participant V as 向量索引 (HNSW)
    participant R as 结果集

    U->>E: "搜索问题"
    E->>V: 转换为向量 [0.12, -0.05, ...]
    V->>V: 执行 <=> (余弦距离计算)
    V->>R: 按照距离从小到大排序 (ORDER BY)
    R->>U: 返回前 N 条原始文本 (LIMIT N)
```

  

### 实验小贴士（给同学们的避坑指南）：

1. **关于 pgvector**：在 SQL 中，`<=>` 代表余弦距离，距离越**小**表示语义越**接近**。
2. **HNSW 索引**：当你的数据量超过 1 万条时，一定要执行 `CREATE INDEX ... USING hnsw`，否则搜索速度会从“毫秒级”掉到“秒级”。
3. **模型选择**：
    * **英文推荐**：`Alibaba-NLP/gte-base-en-v1.5`。
    * **中英混合推荐**：`mixedbread-ai/mxbai-embed-large-v1`。
4. **环境变量**：实操时如果遇到 `Connection Refused`，多半是 `DATABASE_URL` 没有正确 `export` 到当前终端窗口。
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
