## 大学生数据库实践课: 11.3 pgvectorscale向量索引  
  
### 作者  
digoal  
  
### 日期  
2025-12-11  
  
### 标签  
PostgreSQL , DuckDB , 语义搜索 , 向量搜索 , 关键词检索 , 全文检索 , 标量检索 , 混合搜索 , 多模态搜索 , 重排序 , embedding , document split , ORC , 大模型 , 多模态大模型 , Dify , 压力测试 , 索引优化 , 倒排向量索引 , Ivfflat , 图向量索引 , HNSW , DiskANN , 量化 , rabitq , sbq , 二值量化 , bm25 , 相关性 , 相似性 , 召回率 , pgbench , 数据集 , ann-benchmarks , 图搜索 , PGQ , 递归 , 深度优先 , 广度优先 , 最短路径 , N度关系 , LLM , Ollama  
  
----  
  
## 背景  
  
pgvectorscale deepwiki:  
  
https://deepwiki.com/search/-1diskann_5c4b7fbb-3fe1-4688-a478-bce6d948eb20?mode=fast  
  
面向大学生通俗讲解以下内容:  
1、diskann 原理介绍  
2、diskann 索引使用示例  
3、diskann 索引优化示例  
4、sbq 的设计原理  
  
-----  
  
# DiskANN 原理通俗讲解  
  
## 核心思想  
  
DiskANN 是一种基于图的近似最近邻搜索算法，它的核心思想是把高维向量空间中的数据点组织成一个图结构，通过在图上进行贪心搜索来快速找到相似的向量，而不需要和所有向量进行比较。  
  
## 图结构构建  
  
### 1. 邻居关系建立  
每个向量作为图中的一个节点，与它最相似的若干个其他向量建立连接（成为邻居）。这样就形成了一个近似最近邻图。  
  
### 2. 邻居剪枝  
为了避免图中连接过于密集，需要对邻居进行剪枝。算法会优先保留那些距离当前节点更近的邻居，同时确保图的连通性。  
  
## 搜索过程  
  
### 1. 贪心遍历  
搜索时从一个或多个入口节点开始，不断向距离查询向量更近的邻居移动，直到找不到更近的节点为止。  
  
### 2. 候选列表维护  
算法维护一个候选列表，记录搜索过程中遇到的较近节点。通过调整搜索列表大小可以平衡准确性和速度。  
  
### 3. 结果重排序  
为了提高准确性，算法会对找到的候选结果进行精确距离计算和重排序，返回最终的最近邻结果。  
  
## 性能优势  
  
### 1. 子线性复杂度  
由于不需要遍历所有数据点，DiskANN 的搜索复杂度是亚线性的，在大规模数据集上表现优异。  
  
### 2. 内存友好  
通过统计二进制量化（SBQ）等技术，可以在保持较高准确率的同时大幅减少内存占用。  
  
### 3. 支持过滤  
pgvectorscale 的实现还支持基于标签的过滤搜索，可以在向量搜索的同时进行元数据过滤。  
  
## 实际应用  
  
在 pgvectorscale 中，DiskANN 被实现为 PostgreSQL 的访问方法，通过 `diskann_amhandler` 函数注册索引操作回调。  
  
创建索引时可以调整参数如 `num_neighbors`（邻居数量）、`search_list_size`（搜索列表大小）等来优化性能。  
  
## Notes  
  
- DiskANN 是近似算法，结果可能不是完全精确的最近邻，但在大多数应用场景下足够准确  
- pgvectorscale 的实现基于微软的 DiskANN 研究，但针对 PostgreSQL 环境进行了优化  
- 算法支持多种距离度量，包括余弦距离、L2 距离和内积距离  
  
  
  
-----  
  
# DiskANN 索引使用示例  
  
## 基本使用流程  
  
### 1. 创建表和插入数据  
  
首先创建一个包含向量列的表，然后插入数据：  
  
```sql  
-- 创建文档嵌入表  
CREATE TABLE document_embedding (  
    id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,  
    metadata JSONB,  
    contents TEXT,  
    embedding VECTOR(1536)  -- 1536维向量  
);  
```  
  
### 2. 创建 DiskANN 索引  
  
为向量列创建 StreamingDiskANN 索引：  
  
```sql  
-- 使用余弦距离创建索引  
CREATE INDEX document_embedding_idx ON document_embedding  
USING diskann (embedding vector_cosine_ops);  
```  
  
### 3. 执行相似性搜索  
  
使用索引查找最相似的向量：  
  
```sql  
-- 查找与查询向量最相似的10个文档  
SELECT *  
FROM document_embedding  
ORDER BY embedding <=> $1  -- $1 是查询向量  
LIMIT 10;  
```  
  
## 支持的距离度量  
  
DiskANN 支持三种主要的距离度量：  
  
### 余弦距离（Cosine Distance）  
```sql  
-- 创建索引  
CREATE INDEX idx_cosine ON table_name USING diskann (embedding vector_cosine_ops);  
  
-- 查询  
SELECT * FROM table_name ORDER BY embedding <=> query_vector LIMIT 10;  
```  
  
### L2 距离（欧几里得距离）  
```sql  
-- 创建索引  
CREATE INDEX idx_l2 ON table_name USING diskann (embedding vector_l2_ops);  
  
-- 查询  
SELECT * FROM table_name ORDER BY embedding <-> query_vector LIMIT 10;  
```  
  
### 内积距离（Inner Product）  
```sql  
-- 创建索引  
CREATE INDEX idx_ip ON table_name USING diskann (embedding vector_ip_ops);  
  
-- 查询  
SELECT * FROM table_name ORDER BY embedding <#> query_vector LIMIT 10;  
```  
  
## 带标签的过滤搜索  
  
### 1. 创建带标签的表  
  
```sql  
CREATE TABLE documents (  
    id SERIAL PRIMARY KEY,  
    embedding VECTOR(1536),  
    labels SMALLINT[],  -- 标签数组  
    status TEXT,  
    created_at TIMESTAMPTZ  
);  
```  
  
### 2. 创建包含标签的索引  
  
```sql  
CREATE INDEX ON documents USING diskann (embedding vector_cosine_ops, labels);  
```  
  
### 3. 执行过滤搜索  
  
```sql  
-- 查找具有特定标签的相似文档  
SELECT * FROM documents  
WHERE labels && ARRAY[1, 3]  -- 标签1或3  
ORDER BY embedding <=> query_vector  
LIMIT 10;  
```  
  
## 性能调优参数  
  
### 索引创建时参数  
  
```sql  
CREATE INDEX idx_custom ON table_name USING diskann (embedding)  
WITH (  
    num_neighbors = 50,        -- 每个节点的最大邻居数  
    search_list_size = 100,    -- 构建时的搜索列表大小  
    max_alpha = 1.2,          -- 图质量控制参数  
    storage_layout = 'memory_optimized'  -- 存储布局  
);  
```  
  
### 查询时参数  
  
```sql  
-- 设置查询时的搜索列表大小（影响速度和准确性）  
SET diskann.query_search_list_size = 100;  
  
-- 设置重排序元素数量（提高准确性）  
SET diskann.query_rescore = 50;  
```  
  
## Python 使用示例  
  
```python  
import psycopg2  
import numpy as np  
  
# 连接数据库  
conn = psycopg2.connect("postgresql://user:pass@host/db")  
cur = conn.cursor()  
  
# 创建表和索引  
cur.execute("""  
    CREATE TABLE test_embeddings (  
        id SERIAL PRIMARY KEY,  
        embedding vector(4)  
    )  
""")  
  
cur.execute("""  
    CREATE INDEX test_diskann_idx  
    ON test_embeddings  
    USING diskann (embedding vector_cosine_ops)  
""")  
  
# 插入向量数据  
vectors = []  
for i in range(50):  
    vector = np.random.rand(4)  
    vector_str = f"[{','.join(map(str, vector))}]"  
    vectors.append((i, vector_str))  
  
cur.executemany(  
    "INSERT INTO test_embeddings (id, embedding) VALUES (%s, %s)",  
    vectors  
)  
  
# 执行相似性搜索  
query_vector = np.random.rand(4)  
query_str = f"[{','.join(map(str, query_vector))}]"  
  
cur.execute("""  
    SELECT id, embedding <=> %s::vector as distance  
    FROM test_embeddings  
    ORDER BY embedding <=> %s::vector  
    LIMIT 5  
""", (query_str, query_str))  
  
results = cur.fetchall()  
print(f"找到 {len(results)} 个最近邻")  
```  
  
## 实际应用建议  
  
### 1. 内存设置  
构建大型索引时，建议增加维护内存：  
```sql  
SET maintenance_work_mem = '2GB';  
```  
  
### 2. 标签范围  
标签值必须在 PostgreSQL `smallint` 范围内（-32768 到 32767）  
  
### 3. 严格排序  
如果需要严格的距离排序，可以使用物化 CTE：  
```sql  
WITH relaxed_results AS MATERIALIZED (  
    SELECT * FROM table_name ORDER BY embedding <=> query_vector LIMIT 20  
)  
SELECT * FROM relaxed_results ORDER BY embedding <=> query_vector LIMIT 10;  
```  
  
## Notes  
  
- DiskANN 索引支持动态插入新数据，无需重建整个索引  
- 使用 `memory_optimized` 存储布局可以显著减少内存使用  
- 查询结果使用"宽松排序"，距离值可能不是完全按序排列，但近似程度很高  
- 对于生产环境，建议根据数据规模和查询模式调整 `num_neighbors` 和 `search_list_size` 参数  
  
  
  
-----  
  
# DiskANN 索引优化示例  
  
## 概述  
  
DiskANN 索引优化主要通过调整两类参数来实现：**构建时参数**（创建索引时设置）和**查询时参数**（执行查询时动态调整）。这些参数帮助你在速度和准确性之间找到最佳平衡。  
  
## 构建时优化参数  
  
### 1. 存储布局优化  
  
```sql  
-- 内存优化存储（推荐高维向量）  
CREATE INDEX idx_memory_optimized ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (storage_layout = 'memory_optimized');  
  
-- 普通存储（推荐低维向量或需要最高精度）  
CREATE INDEX idx_plain ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (storage_layout = 'plain');  
```  
  
`memory_optimized` 使用 SBQ 压缩技术，大幅减少内存使用，适合 768+ 维向量。  
  
### 2. 邻居数量调优  
  
```sql  
-- 高精度配置（更多邻居，更高召回率）  
CREATE INDEX idx_high_recall ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (num_neighbors = 75);  
  
-- 快速查询配置（较少邻居，更快查询）  
CREATE INDEX idx_fast ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (num_neighbors = 25);  
```  
  
`num_neighbors` 控制图中每个节点的最大连接数，值越高精度越高但查询越慢。  
  
### 3. 构建质量参数  
  
```sql  
-- 高质量图构建（较慢构建时间）  
CREATE INDEX idx_quality ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (  
    search_list_size = 150,  -- 构建时搜索更多候选  
    max_alpha = 1.4          -- 更激进的剪枝策略  
);  
  
-- 快速构建配置  
CREATE INDEX idx_fast_build ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (  
    search_list_size = 50,  
    max_alpha = 1.2  
);  
```  
  
`search_list_size` 影响构建时的图质量，`max_alpha` 控制邻居剪枝的激进程度。  
  
## 查询时优化参数  
  
### 1. 动态调整搜索精度  
  
```sql  
-- 会话级设置（影响所有后续查询）  
SET diskann.query_search_list_size = 200;  -- 探索更多候选  
SET diskann.query_rescore = 100;           -- 重排序更多结果  
  
-- 事务级设置（只影响当前事务）  
BEGIN;  
SET LOCAL diskann.query_search_list_size = 50;   -- 快速查询  
SET LOCAL diskann.query_rescore = 0;             -- 禁用重排序  
SELECT * FROM documents ORDER BY embedding <=> $1 LIMIT 10;  
COMMIT;  
```  
  
查询时参数可以动态调整，无需重建索引。  
  
### 2. 性能基准测试示例  
  
```python  
# 测试不同参数组合的性能  
import psycopg2  
import time  
  
def test_performance(conn, search_list_size, rescore):  
    with conn.cursor() as cur:  
        # 设置查询参数  
        cur.execute(f"SET diskann.query_search_list_size = {search_list_size}")  
        cur.execute(f"SET diskann.query_rescore = {rescore}")  
  
        # 执行查询并测量时间  
        start = time.time()  
        cur.execute("""  
            SELECT id FROM documents  
            ORDER BY embedding <=> '[0.1,0.2,0.3,...]'  
            LIMIT 100  
        """)  
        results = cur.fetchall()  
        end = time.time()  
  
        return len(results), end - start  
  
# 测试多种配置  
configs = [  
    (50, 0),    # 最快  
    (100, 50),  # 默认  
    (200, 100), # 高精度  
    (500, 400)  # 最高精度  
]  
  
for search_size, rescore in configs:  
    count, duration = test_performance(conn, search_size, rescore)  
    print(f"搜索列表={search_size}, 重排序={rescore}: "  
          f"返回{count}条结果, 耗时{duration:.3f}秒")  
```  
  
## 内存优化策略  
  
### 1. 构建时内存设置  
  
```sql  
-- 为大型索引构建分配更多内存  
SET maintenance_work_mem = '4GB';  
  
-- 创建索引  
CREATE INDEX large_vector_idx ON huge_table  
USING diskann (embedding vector_cosine_ops);  
```  
  
构建索引时默认 64MB 内存可能不足，建议根据数据规模调整。  
  
### 2. SBQ 压缩优化  
  
```sql  
-- 自定义压缩精度（1-32位）  
CREATE INDEX idx_custom_compression ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (  
    storage_layout = 'memory_optimized',  
    num_bits_per_dimension = 1  -- 最大压缩  
);  
  
-- 自动选择（推荐）  
CREATE INDEX idx_auto_compression ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (  
    storage_layout = 'memory_optimized',  
    num_bits_per_dimension = 0  -- 自动选择  
);  
```  
  
`num_bits_per_dimension` 控制压缩精度，0 表示自动选择（<900维用2位，否则1位）。  
  
## 实际优化案例  
  
### 案例1：高并发搜索优化  
  
```sql  
-- 针对高并发场景的索引配置  
CREATE INDEX idx_concurrent ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (  
    num_neighbors = 30,        -- 平衡精度和速度  
    search_list_size = 75,     -- 中等构建质量  
    storage_layout = 'memory_optimized'  
);  
  
-- 查询时优化  
SET diskann.query_search_list_size = 75;  
SET diskann.query_rescore = 25;  
```  
  
### 案例2：大规模数据集优化  
  
```sql  
-- 5000万向量数据集优化  
SET maintenance_work_mem = '8GB';  
  
CREATE INDEX idx_large_scale ON massive_table  
USING diskann (embedding vector_cosine_ops)  
WITH (  
    num_neighbors = 50,        -- 保证连通性  
    search_list_size = 150,    -- 高质量构建  
    max_alpha = 1.3,           -- 适度剪枝  
    storage_layout = 'memory_optimized',  
    num_bits_per_dimension = 1 -- 最大压缩节省空间  
);  
```  
  
## 性能监控与调优  
  
### 1. 查询计划分析  
  
```sql  
-- 检查索引是否被使用  
EXPLAIN (ANALYZE, BUFFERS)  
SELECT * FROM documents  
ORDER BY embedding <=> $1  
LIMIT 10;  
  
-- 比较不同参数的执行计划  
SET diskann.query_search_list_size = 50;  
EXPLAIN ANALYZE SELECT * FROM documents ORDER BY embedding <=> $1 LIMIT 10;  
  
SET diskann.query_search_list_size = 200;  
EXPLAIN ANALYZE SELECT * FROM documents ORDER BY embedding <=> $1 LIMIT 10;  
```  
  
### 2. 召回率测试  
  
```sql  
-- 计算召回率（与精确搜索对比）  
CREATE TEMP TABLE ground_truth AS  
SELECT id FROM documents  
ORDER BY embedding <=> $1  
LIMIT 100;  
  
SET diskann.query_search_list_size = 100;  
CREATE TEMP TABLE index_results AS  
SELECT id FROM documents  
ORDER BY embedding <=> $1  
LIMIT 100;  
  
-- 计算召回率  
SELECT  
    COUNT(*) * 100.0 / 100.0 AS recall_pct  
FROM index_results  
WHERE id IN (SELECT id FROM ground_truth);  
```  
  
## Notes  
  
- **构建时参数**需要重建索引才能更改，建议在创建索引时仔细选择  
- **查询时参数**可以动态调整，适合根据不同查询需求优化  
- `memory_optimized` 存储通常能提供最佳的性能/空间比  
- 生产环境建议先用代表性数据集进行基准测试  
- 召回率 95%+ 通常被认为是良好的近似搜索结果  
  
  
-----  
  
# max_alpha 参数通俗讲解  
  
## 核心概念  
  
`max_alpha` 是 DiskANN 索引构建时的一个质量控制参数，用于控制邻居剪枝的"宽松程度"。它的默认值是 1.2，取值范围是 1.0 到 5.0。  
  
## 工作原理  
  
### 1. 剪枝算法中的角色  
  
在构建图索引时，每个向量节点都需要选择哪些其他节点作为它的"邻居"。由于候选邻居可能很多，需要剪枝来限制数量。  
  
`max_alpha` 就像一个"门槛值"，决定了一个候选邻居能否通过考验：  
  
```rust  
// 算法逐步增加 alpha，从 1.0 开始  
let mut alpha = 1.0;  
while alpha <= max_alpha && results.len() < num_neighbors {  
    // 检查候选邻居是否能通过当前 alpha 门槛  
    if max_factors[i] > alpha {  
        continue; // 门槛太高，跳过这个候选  
    }  
    // 通过考验，加入邻居列表  
    results.push(neighbor.clone());  
    alpha *= 1.2 // 提高门槛，下一轮更严格  
}  
```  
  
### 2. 通俗理解  
  
想象你在组建一个学习小组：  
- **alpha = 1.0**：只找和你最聊得来的同学（标准严格）  
- **alpha = 1.2**：可以找聊得来，或者有共同兴趣的同学（标准适中）  
- **alpha = 2.0**：只要不太讨厌都可以加入（标准宽松）  
  
`max_alpha` 就是这个标准的"上限值"。  
  
## 实际影响  
  
### 构建时间和质量  
  
| max_alpha 值 | 构建速度 | 图质量 | 适用场景 |  
|-------------|---------|--------|---------|  
| 1.0 (最小) | 最快 | 一般 | 快速原型，测试环境 |  
| 1.2 (默认) | 中等 | 良好 | 大多数生产环境 |  
| 2.0+ | 较慢 | 很好 | 对准确性要求极高的场景 |  
  
### 使用示例  
  
```sql  
-- 快速构建，牺牲一些准确性  
CREATE INDEX idx_fast ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (max_alpha = 1.0);  
  
-- 默认设置，平衡速度和质量  
CREATE INDEX idx_default ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (max_alpha = 1.2);  
  
-- 高质量构建，花费更长时间  
CREATE INDEX idx_quality ON documents  
USING diskann (embedding vector_cosine_ops)  
WITH (max_alpha = 1.4);  
```  
  
## 技术细节  
  
### 剪枝因子计算  
  
算法会计算每个候选邻居的"遮挡因子"（factor），这个因子表示候选邻居与已选邻居的相似程度：  
  
- 如果一个候选邻居与很多已选邻居都很相似，它的因子就会很高  
- 当因子超过当前的 alpha 值时，这个候选就被"遮挡"了，不会被选为邻居  
- 通过逐步提高 alpha 值，算法可以在保证质量的同时找到足够的邻居  
  
## 调优建议  
  
1. **首次尝试**：使用默认值 1.2  
2. **构建太慢**：降低到 1.0-1.1  
3. **准确性不足**：提高到 1.4-1.8  
4. **极端情况**：最高可设为 5.0，但构建时间会显著增加  
  
## Notes  
  
- max_alpha 是构建时参数，修改后需要重建索引  
- 对于大多数应用场景，默认值 1.2 已经能提供良好的性能  
- 过高的 max_alpha 值可能导致图过于密集，反而影响查询性能  
- 建议在代表性数据集上测试不同值的效果后再做决定  
  
-----  
  
# 用虫洞概念理解 max_alpha  
  
## 虫洞类比  
  
是的，用虫洞的概念来理解 `max_alpha` 非常贴切！  
  
### 虫洞的稳定性阈值  
  
想象 DiskANN 的图结构是一个宇宙，每个向量节点是一个星球，虫洞连接着相似的星球：  
  
- **max_alpha = 1.0**：像**高度稳定的虫洞**，只有最直接、最安全的路径能通过。构建速度快，但连接有限。  
- **max_alpha = 1.2**（默认）：像**标准稳定的虫洞**，平衡了安全性和连通性，适合大多数情况。  
- **max_alpha = 2.0+**：像**不稳定的虫洞**，需要更多能量维持，但能连接更多偏远星球，构建慢但覆盖面广。  
  
### 能量消耗与连通性  
  
```rust  
// 算法逐步增加"能量阈值"来激活更多虫洞  
let mut alpha = 1.0;  // 从最低能量开始  
while alpha <= max_alpha && results.len() < num_neighbors {  
    // 检查这个虫洞是否稳定 enough  
    if max_factors[i] > alpha {  
        continue; // 能量不足，虫洞坍缩，跳过  
    }  
    // 能量足够，虫洞稳定，建立连接  
    results.push(neighbor.clone());  
    alpha *= 1.2 // 提高能量阈值，寻找更多连接  
}  
```  
  
### 实际应用场景  
  
| 虫洞类型 | max_alpha | 构建时间 | 图质量 | 适用场景 |  
|---------|-----------|---------|--------|---------|  
| 稳定虫洞 | 1.0 | 最快 | 基础连接 | 快速原型 |  
| 标准虫洞 | 1.2 | 中等 | 良好连接 | 生产环境 |  
| 探索虫洞 | 2.0+ | 慢 | 广泛连接 | 科研、高精度需求 |  
  
## Notes  
  
- 虫洞越不稳定（max_alpha 越高），需要的"能量"（计算时间）越多  
- 过于不稳定的虫洞可能导致宇宙混乱（图过于密集，反而影响查询）  
- 默认的 1.2 是经过测试的"最佳稳定点"，适合大多数宇宙航行需求  
  
-----  
  
# SBQ 设计原理通俗讲解  
  
## 核心思想：向量简笔画  
  
SBQ（Statistical Binary Quantization）是一种向量压缩技术，就像把高精度的彩色照片简化成黑白简笔画。    
  
原本每个向量维度需要 32 位存储，SBQ 将其压缩到 1-2 位，大幅减少内存使用，同时保持向量间的相对关系。  
  
## 两阶段工作流程  
  
### 1. 训练阶段：学习"平均特征"  
  
创建索引时，SBQ 首先分析数据集中的向量，计算每个维度的统计特征：    
  
```rust  
// 训练量化器  
let mut quantizer = SbqQuantizer::new(meta_page);  
quantizer.start_training(meta_page);  
// 扫描所有向量，收集统计信息  
quantizer.add_sample(vec.to_index_slice());  
quantizer.finish_training();  
```  
  
这个阶段就像老师批改大量作业，找出每个题目的"平均分"作为参考标准。  
  
### 2. 量化阶段：简化表示  
  
对每个向量，SBQ 根据训练得到的统计信息进行简化：    
  
- **1位量化**：维度值高于平均值记为 1，低于平均值记为 0  
- **多位量化**：将值域分成多个区间，用更多位表示精确位置  
  
## 存储结构优化  
  
### 压缩存储格式  
  
SBQ 将量化后的向量打包成紧凑的位数组：    
  
```rust  
pub struct SbqSpeedupStorage<'a> {  
    quantizer: SbqQuantizer,  // 共享的量化器  
    qv_cache: Option<RefCell<QuantizedVectorCache>>,  // 缓存  
    // ...  
}  
```  
  
原本需要 `4 × 维度数` 字节，现在只需 `维度数 ÷ 8` 字节（1位模式）。  
  
### 缓存机制  
  
为了提高查询效率，SBQ 实现了 LRU 缓存：    
  
```rust  
pub struct QuantizedVectorCache {  
    cache: LruCacheWithStats<ItemPointer, Vec<SbqVectorElement>>,  
}  
```  
  
就像把常用的简笔画放在手边，避免反复翻找。  
  
## 距离计算革命  
  
### XOR 快速比较  
  
SBQ 最大的优势是距离计算的加速。传统方法需要浮点运算，SBQ 使用位运算：    
  
```rust  
// 使用 XOR 操作计算汉明距离  
let dist = distance_xor_optimized(q, arch.get_bq_vector());  
```  
  
这就像比较两幅简笔画的不同之处，数一数有多少个像素点不一样，比精确计算颜色差异快得多。  
  
### 查询流程  
  
查询时，查询向量也被量化，然后通过位运算快速筛选候选：    
  
```rust  
StorageType::SbqCompression => {  
    let quantizer = SbqMeans::load(index, &meta_page, &mut stats);  
    let bq = SbqSpeedupStorage::load_for_search(index, heap, &quantizer, &meta_page);  
    // 使用量化后的存储进行搜索  
}  
```  
  
## 配置参数  
  
### 压缩精度控制  
  
通过 `num_bits_per_dimension` 参数控制压缩比：    
  
- **1位**：最大压缩（32:1），适合超高维向量  
- **2位**：平衡压缩（16:1），适合中等维度  
- **自动选择**：<900维用2位，否则用1位  
  
### 维度限制  
  
SBQ 支持最多 16000 维，而不压缩时只能支持 2000 维：    
  
## 性能优势总结  
  
| 指标 | 原始存储 | SBQ压缩 | 提升倍数 |  
|------|---------|---------|---------|  
| 内存占用 | 100% | 3-6% | 16-32倍减少 |  
| 距离计算 | 浮点运算 | 位运算 | 10-100倍加速 |  
| 支持维度 | ≤2000 | ≤16000 | 8倍提升 |  
  
## Notes  
  
- SBQ 是 Timescale 开发的改进版二进制量化，比标准方法更准确  
- 压缩是有损的，但通过精心设计的统计方法，保持了很高的搜索精度  
- 对于大多数应用，1位量化已经足够，2位提供更好的精度权衡  
- SBQ 使 pgvectorscale 能够处理 Pinecone 等商业服务的大规模向量工作负载  
  
-----  
  
# SBQ 1位模式映射过程通俗讲解  
  
## 训练阶段：寻找"分界线"  
  
### 1. 收集统计数据  
  
创建索引时，SBQ 首先扫描所有向量，为每个维度收集统计信息：    
  
```rust  
// 训练量化器  
let mut quantizer = SbqQuantizer::new(meta_page);  
quantizer.start_training(meta_page);  
// 扫描所有向量，收集统计信息  
quantizer.add_sample(vec.to_index_slice());  
quantizer.finish_training();  
```  
  
这就像老师统计全班同学的身高分布，找出每个维度的"平均分"。  
  
### 2. 计算阈值  
  
对于每个维度，SBQ 计算一个阈值（通常是均值或中位数）：    
  
- 阈值就像一条"分界线"  
- 高于阈值的值归为"正类"  
- 低于阈值的值归为"负类"  
  
## 映射阶段：二值化转换  
  
### 1. 简单判断规则  
  
1位模式的映射规则非常简单：  
  
```rust  
// 伪代码示例  
if original_value > threshold {  
    quantized_value = 1;  // 高于阈值，记为1  
} else {  
    quantized_value = 0;  // 低于阈值，记为0  
}  
```  
  
### 2. 实际量化过程  
  
在 `create_node` 方法中，新向量被量化：    
  
```rust  
let bq_vector = self.quantizer.vector_for_new_node(meta_page, full_vector);  
```  
  
每个维度都独立进行这个判断，整个向量就变成了一串0和1。  
  
## 通俗理解：成绩分级  
  
想象把学生的百分制成绩转换为及格/不及格：  
  
1. **训练阶段**：  
   - 统计全班成绩，发现平均分是75分  
   - 决定以75分作为及格线  
  
2. **映射阶段**：  
   - 小明85分 → 1（及格）  
   - 小红65分 → 0（不及格）  
   - 小刚75分 → 0（等于阈值，归为0）  
  
## 为什么这样有效？  
  
### 1. 保持相对关系  
  
虽然丢失了精确数值，但保留了重要的相对关系：  
- 原本：0.8 > 0.5 > 0.2  
- 量化后：1 > 0 > 0（仍然能区分高低）  
  
### 2. 快速比较  
  
量化后可以用 XOR 快速计算相似度：    
  
```rust  
// 使用 XOR 操作计算汉明距离  
let dist = distance_xor_optimized(q, arch.get_bq_vector());  
```  
  
就像比较两份答案的选择题，数一数有多少题答案不同。  
  
## 配置和控制  
  
### 自动选择阈值  
  
系统会根据数据特征自动选择最佳量化策略：    
  
- 1位模式：适合高维向量（>900维）  
- 2位模式：适合中等维度，提供更好精度  
  
### 压缩效果  
  
1位量化实现32:1的压缩比：  
- 原始：每个维度4字节（32位）  
- 压缩后：每个维度1位  
- 节省：96%的存储空间  
  
## Notes  
  
- SBQ的阈值选择基于统计学习，不是简单取平均值  
- 量化是有损压缩，但通过精心设计保持了搜索精度  
- 1位模式虽然粗糙，但在高维空间中仍然有效  
- 实际的量化算法比简单阈值更复杂，考虑了数据分布特征  
  
    
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
