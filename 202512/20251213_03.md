## AIè®ºæ–‡è§£è¯» | HongTu: Scalable Full-Graph GNN Training on Multiple GPUs
        
### ä½œè€…        
digoal        
        
### æ—¥æœŸ        
2025-12-13        
        
### æ ‡ç­¾        
PostgreSQL , PolarDB , DuckDB , AI , è®ºæ–‡è§£è¯»        
        
----        
        
## èƒŒæ™¯  
      
https://arxiv.org/pdf/2311.14898        
  
æç¤º:          
```          
è¯»æ‡‚ã€ŠHongTu: Scalable Full-Graph GNN Training on Multiple GPUsã€‹è¿™ç¯‡è®ºæ–‡éœ€è¦æå‰æŒæ¡å“ªäº›åŸºç¡€çŸ¥è¯†, è¯·ä½¿ç”¨ä¸­æ–‡é€šç†Ÿæ˜“æ‡‚çš„è®²è§£è¿™äº›åŸºç¡€çŸ¥è¯†, å¯ä»¥å¼•ç”¨è®ºæ–‡ä¸­çš„å›¾ã€è¡¨æˆ–ä½¿ç”¨Markdownæ”¯æŒçš„å›¾å½¢(text,mermaidç­‰)å¢åŠ è§£é‡Šæ€§. 
  
ä½¿ç”¨ä¸­æ–‡é€šç†Ÿæ˜“æ‡‚çš„è§£è¯»ã€ŠHongTu: Scalable Full-Graph GNN Training on Multiple GPUsã€‹è¿™ç¯‡è®ºæ–‡, å…¶ä¸­çš„å…³é”®å†…å®¹è¯·ç€é‡è®²è§£, å¯ä»¥å¼•ç”¨è®ºæ–‡ä¸­çš„å›¾ã€è¡¨æˆ–ä½¿ç”¨Markdownæ”¯æŒçš„å›¾å½¢(text,mermaidç­‰)å¢åŠ è§£é‡Šæ€§. 
  
æå–ã€ŠHongTu: Scalable Full-Graph GNN Training on Multiple GPUsã€‹è¿™ç¯‡è®ºæ–‡ä¸­çš„é‡è¦æœ¯è¯­, ä½¿ç”¨ä¸­æ–‡å¯¹è¿™äº›æœ¯è¯­è¿›è¡Œé€šç†Ÿæ˜“æ‡‚çš„è®²è§£, å¯ä»¥å¼•ç”¨è®ºæ–‡ä¸­çš„å›¾ã€è¡¨æˆ–ä½¿ç”¨Markdownæ”¯æŒçš„å›¾å½¢(text,mermaidç­‰)å¢åŠ è§£é‡Šæ€§. 
```     
  
## 1 å‰ç½®çŸ¥è¯† 
  
è¦è¯»æ‡‚è¿™ç¯‡åä¸ºã€ŠHongTu: Scalable Full-Graph GNN Training on Multiple GPUsã€‹çš„è®ºæ–‡ï¼Œä½ éœ€è¦æŒæ¡å››ä¸ªæ ¸å¿ƒé¢†åŸŸçš„é¢„å¤‡çŸ¥è¯†ã€‚è¿™ç¯‡è®ºæ–‡ä¸»è¦è§£å†³çš„æ˜¯ **â€œå›¾å¤ªå¤§ï¼Œæ˜¾å­˜æ”¾ä¸ä¸‹ï¼Œå¯¼è‡´è®­ç»ƒæ…¢â€** çš„é—®é¢˜ã€‚

ä»¥ä¸‹æˆ‘å°†ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€ï¼Œé…åˆå›¾ç¤ºä¸ºä½ è®²è§£è¿™äº›åŸºç¡€çŸ¥è¯†ã€‚

---

### 1. å›¾ç¥ç»ç½‘ç»œ (GNN) çš„â€œèšåˆ-æ›´æ–°â€æœºåˆ¶**æ ¸å¿ƒæ¦‚å¿µ**ï¼šGNN ç©¶ç«Ÿæ˜¯æ€ä¹ˆè¿ç®—çš„ï¼Ÿ
GNN ä¸ä¼ ç»Ÿç¥ç»ç½‘ç»œæœ€å¤§çš„ä¸åŒåœ¨äº**æ•°æ®ä¾èµ–æ€§**ã€‚åœ¨å¤„ç†ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆVertexï¼‰æ—¶ï¼Œä¸èƒ½åªçœ‹å®ƒè‡ªå·±ï¼Œå¿…é¡»æŠŠå®ƒé‚»å±…ï¼ˆNeighborsï¼‰çš„ä¿¡æ¯â€œæŠ“â€è¿‡æ¥ä¸€èµ·ç®—ã€‚

* **èšåˆ (Aggregate)** ï¼šæŠŠå‘¨å›´é‚»å±…çš„ä¿¡æ¯æ”¶é›†èµ·æ¥ï¼ˆä¾‹å¦‚æ±‚å’Œã€å–å¹³å‡ï¼‰ã€‚
* **æ›´æ–° (Update)** ï¼šç»“åˆé‚»å±…çš„ä¿¡æ¯å’Œè‡ªå·±çš„ä¿¡æ¯ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œå˜æ¢ï¼Œå¾—åˆ°æ–°çš„ç‰¹å¾ã€‚

**ä¸ºä»€ä¹ˆè¿™å¯¹è®ºæ–‡å¾ˆé‡è¦ï¼Ÿ**
è®ºæ–‡ä¸­åå¤æåˆ°çš„â€œFull-neighbor aggregationâ€ï¼ˆå…¨é‚»å±…èšåˆï¼‰å°±æ˜¯æŒ‡å¦‚æœä¸è¿›è¡Œé‡‡æ ·ï¼Œè¿™å°±éœ€è¦è®¿é—®å¤§é‡å†…å­˜ã€‚å¦‚æœå›¾è¢«åˆ‡åˆ†åˆ°äº†ä¸åŒçš„ GPU ä¸Šï¼Œè¿™ç§â€œæŠ“å–é‚»å±…ä¿¡æ¯â€çš„æ“ä½œå°±ä¼šå˜æˆè·¨è®¾å¤‡çš„é€šä¿¡å™©æ¢¦ã€‚

```mermaid
graph LR
    A((é‚»å±… A)) -->|å‘é€ç‰¹å¾| T((ç›®æ ‡èŠ‚ç‚¹ T))
    B((é‚»å±… B)) -->|å‘é€ç‰¹å¾| T
    C((é‚»å±… C)) -->|å‘é€ç‰¹å¾| T
    T -->|èšåˆ & æ›´æ–°| T_new((æ–°ç‰¹å¾ T'))
    style T fill:#f9f,stroke:#333,stroke-width:2px
    style T_new fill:#bbf,stroke:#333,stroke-width:2px

```

> 
> **è®ºæ–‡å…³è”**ï¼šè®ºæ–‡å…¬å¼ (1) h_{v}^{l}=UPDATE(AGGREGATE(\{h_{u}^{l-1}|u\in N(v)\}),h_{v}^{l-1}) è®²çš„å°±æ˜¯è¿™ä¸ªè¿‡ç¨‹ ã€‚
> 
> 

![pic](20251213_03_pic_001.jpg)  

---

### 2. å…¨å›¾è®­ç»ƒ vs. Mini-batch è®­ç»ƒ**æ ¸å¿ƒæ¦‚å¿µ**ï¼šæ€ä¹ˆæŠŠå¤§è±¡è£…è¿›å†°ç®±ï¼ˆæ€ä¹ˆè®­ç»ƒå¤§å›¾ï¼‰ï¼Ÿ

é€šå¸¸æœ‰ä¸¤ç§æ–¹æ³•å¤„ç†å¤§å›¾ï¼š

1. **Mini-batch (é‡‡æ ·)** ï¼šæ¯æ¬¡åªéšæœºé€‰ä¸€å°éƒ¨åˆ†èŠ‚ç‚¹å’Œå®ƒä»¬çš„**éƒ¨åˆ†**é‚»å±…æ¥è®­ç»ƒã€‚
* *ä¼˜ç‚¹*ï¼šçœå†…å­˜ã€‚
* *ç¼ºç‚¹*ï¼šä¸¢æ•°æ®ï¼Œå‡†ç¡®ç‡å¯èƒ½ä¸‹é™ï¼ˆInformation lossï¼‰ã€‚


2. **Full-graph (å…¨å›¾)** ï¼šæ¯ä¸€å±‚éƒ½ç”¨æ‰€æœ‰é‚»å±…çš„å®Œæ•´æ•°æ®ã€‚
* *ä¼˜ç‚¹*ï¼šå‡†ç¡®ç‡é«˜ï¼Œæ¨¡å‹æ•ˆæœå¥½ã€‚
* *ç¼ºç‚¹*ï¼šå†…å­˜çˆ†ç‚¸ï¼Œè®¡ç®—é‡å·¨å¤§ã€‚



**ä¸ºä»€ä¹ˆè¿™å¯¹è®ºæ–‡å¾ˆé‡è¦ï¼Ÿ**
HongTu åšæŒåš **Full-graph Training** ï¼Œå› ä¸ºå®ƒæ•ˆæœå¥½ã€‚ä½†å› ä¸ºæ˜¾å­˜ä¸å¤Ÿï¼Œå®ƒå¿…é¡»æŠŠæ•°æ®æ”¾åœ¨ CPU ä¸Šï¼Œè¿™å°±å¼•å‡ºäº†å®ƒçš„æ ¸å¿ƒç—›ç‚¹ï¼š **CPU å’Œ GPU ä¹‹é—´çš„æ•°æ®ä¼ è¾“å¤ªæ…¢äº†**ã€‚

---

### 3. ç¡¬ä»¶æ¶æ„ä¸é€šä¿¡ç“¶é¢ˆ (The Memory Wall) **æ ¸å¿ƒæ¦‚å¿µ**ï¼šä¸ºä»€ä¹ˆè¦æŠŠæ•°æ®æ¬æ¥æ¬å»ï¼Ÿ

åœ¨å¤š GPU æœåŠ¡å™¨ä¸Šï¼Œå­˜åœ¨ä¸‰ç§é€Ÿåº¦æˆªç„¶ä¸åŒçš„â€œè·¯â€ï¼š

1. **GPU æ˜¾å­˜ (HBM)** ï¼šé€Ÿåº¦æå¿« (2000 GB/s+)ï¼Œä½†å®¹é‡å° (å¦‚ A100 åªæœ‰ 80GB)ã€‚
2. **GPU äº’è” (NVLink)** ï¼šGPU ä¹‹é—´é€šä¿¡ï¼Œé€Ÿåº¦å¿« (200-600 GB/s)ï¼Œåƒé«˜é€Ÿå…¬è·¯ã€‚
3. **CPU-GPU äº’è” (PCIe)** ï¼šCPU ä¼ ç»™ GPUï¼Œé€Ÿåº¦æ…¢ (32 GB/s)ï¼Œåƒä¹¡æ‘åœŸè·¯ã€‚

**å¯è§†åŒ–è§£é‡Š (åŸºäºè®ºæ–‡ Figure 1)** ï¼š

> **å›¾è§£è¯´æ˜**ï¼š
> * è®ºæ–‡å›¾ 1 å±•ç¤ºäº† 4 ä¸ª GPU é€šè¿‡è“è‰²çš„ **NVLink** äº’è”ï¼ˆå¿«ï¼‰ï¼Œä½†å®ƒä»¬éƒ½è¦é€šè¿‡é»‘è‰²çš„è™šçº¿ **PCIe** è¿æ¥åˆ° CPUï¼ˆæ…¢ï¼‰ã€‚
> 
> 
> * **HongTu çš„ç­–ç•¥**ï¼šå› ä¸ºå›¾å¤ªå¤§ï¼ˆTB çº§åˆ«ï¼‰ï¼ŒGPU æ”¾ä¸ä¸‹ï¼Œåªèƒ½æŠŠæ•°æ®å­˜ CPUï¼ˆæ…¢å†…å­˜ï¼‰ã€‚
> * **æŒ‘æˆ˜**ï¼šå¦‚ä½•å°½é‡å°‘èµ° PCIe è¿™æ¡â€œæ…¢è·¯â€ï¼Œå¤šèµ° NVLink è¿™æ¡â€œå¿«è·¯â€ï¼Ÿè¿™æ˜¯ HongTu çš„æ ¸å¿ƒè´¡çŒ®ä¹‹ä¸€ã€‚
> 
> 
  
![pic](20251213_03_pic_002.jpg)  

---

### 4. å›¾åˆ‡åˆ†ä¸â€œå…‰ç¯èŠ‚ç‚¹â€ (Halo Nodes) **æ ¸å¿ƒæ¦‚å¿µ**ï¼šåˆ‡è›‹ç³•æ—¶ï¼Œè¾¹ç¼˜çš„å¥¶æ²¹å½’è°ï¼Ÿ

å½“ä¸€å¼ å¤§å›¾è¢«åˆ‡åˆ†æˆå‡ å—ï¼ˆPartitionsï¼‰åˆ†ç»™ä¸åŒçš„ GPU å¤„ç†æ—¶ï¼Œè¾¹ç•Œä¸Šçš„èŠ‚ç‚¹ä¼šå¾ˆéº»çƒ¦ã€‚
å¦‚æœ **GPU-0** è´Ÿè´£èŠ‚ç‚¹ Aï¼Œä½† A çš„é‚»å±… B åœ¨ **GPU-1** ä¸Šï¼Œä¸ºäº†è®¡ç®— Aï¼ŒGPU-0 å¿…é¡»å»è¦æŠŠ B çš„æ•°æ®å¤åˆ¶è¿‡æ¥ã€‚è¿™ä¸ª B å°±è¢«ç§°ä¸ºâ€œHalo Nodeâ€æˆ–å¤åˆ¶èŠ‚ç‚¹ã€‚

**ä¸ºä»€ä¹ˆè¿™å¯¹è®ºæ–‡å¾ˆé‡è¦ï¼Ÿ**
è¿™ç§è·¨åˆ‡åˆ†çš„ä¾èµ–ä¼šå¯¼è‡´**æ•°æ®é‡å¤ä¼ è¾“**ã€‚

* å¦‚æœèŠ‚ç‚¹ B æ˜¯å¾ˆå¤šäººçš„é‚»å±…ï¼Œå®ƒå¯èƒ½è¢« GPU-0 è¦ä¸€æ¬¡ï¼Œè¢« GPU-2 è¦ä¸€æ¬¡ï¼Œè¢« GPU-3 è¦ä¸€æ¬¡ã€‚
* å¦‚æœä¸ä¼˜åŒ–ï¼Œè¿™äº›é‡å¤çš„è¯·æ±‚éƒ½ä¼šèµ°é‚£æ¡æ…¢é€Ÿçš„ PCIe æ€»çº¿ã€‚
* HongTu çš„ **"Deduplicated Communication" (å»é‡é€šä¿¡)** å°±æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ ã€‚



**å¯è§†åŒ–è§£é‡Š (åŸºäºè®ºæ–‡ Figure 6a)** ï¼š

> **å›¾è§£è¯´æ˜**ï¼š
> * åœ¨å›¾ 6(a) ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°çº¢æ¡†é‡Œçš„èŠ‚ç‚¹ï¼ˆå¦‚èŠ‚ç‚¹ 0, 1ï¼‰åœ¨ä¸åŒçš„ GPU ä¸Šè¢«é‡å¤ä¼ è¾“äº†å¤šæ¬¡ ã€‚
> 
> 
> * HongTu çš„åšæ³•æ˜¯åªä¼ ä¸€æ¬¡åˆ°æŸä¸€ä¸ª GPUï¼Œç„¶åè®© GPU ä¹‹é—´äº’ç›¸ä¼ ï¼ˆèµ° NVLink é«˜é€Ÿè·¯ï¼‰ï¼Œä»è€Œç»™ PCIe å‡è´Ÿã€‚
> 
> 

![pic](20251213_03_pic_003.jpg)  

---

### 5. é‡è®¡ç®— (Recomputation / Gradient Checkpointing) **æ ¸å¿ƒæ¦‚å¿µ**ï¼šç”¨â€œæ—¶é—´â€æ¢â€œç©ºé—´â€ã€‚

åœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­ï¼Œä¸ºäº†ç®—å‡ºæ¢¯åº¦ï¼ˆåå‘ä¼ æ’­ï¼‰ï¼Œé€šå¸¸éœ€è¦ä¿å­˜å‰å‘ä¼ æ’­æ—¶çš„â€œä¸­é—´ç»“æœâ€ï¼ˆIntermediate Dataï¼‰ã€‚

* **å¸¸è§„åšæ³•**ï¼šç®—å®Œå‰å‘å­˜èµ·æ¥ -> æ˜¾å­˜ä¸å¤Ÿç”¨ã€‚
* **é‡è®¡ç®—**ï¼šç®—å®Œå‰å‘å°±æ‰”æ‰ -> åå‘ä¼ æ’­éœ€è¦æ—¶ï¼Œå†é‡æ–°ç®—ä¸€é -> æ˜¾å­˜çœä¸‹æ¥äº†ï¼Œä½†é€Ÿåº¦æ…¢äº†ã€‚

**ä¸ºä»€ä¹ˆè¿™å¯¹è®ºæ–‡å¾ˆé‡è¦ï¼Ÿ**
GNN çš„ä¸­é—´æ•°æ®éå¸¸å¤§ã€‚HongTu æå‡ºäº†ä¸€ç§ **"Recomputation-Caching-Hybrid"** ç­–ç•¥ ã€‚

* ç®€å•çš„è¿ç®—ï¼ˆå¦‚ GCN çš„èšåˆï¼‰ï¼Œå­˜åœ¨ CPU é‡Œï¼ˆCacheï¼‰ã€‚
* å¤æ‚çš„è¿ç®—ï¼Œæ‰”æ‰é‡ç®—ï¼ˆRecomputationï¼‰ã€‚
* è¿™æ ·æ—¢çœäº†æ˜¾å­˜ï¼Œåˆä¸ä¼šè®©è®¡ç®—æ—¶é—´å¢åŠ å¤ªå¤šã€‚

---

### æ€»ç»“ï¼šé˜…è¯»è·¯çº¿å›¾å¸¦ç€è¿™äº›çŸ¥è¯†å»è¯»è®ºæ–‡ï¼Œä½ çš„é€»è¾‘é“¾åº”è¯¥æ˜¯è¿™æ ·çš„ï¼š

1. **ç›®æ ‡**ï¼šæˆ‘æƒ³è·‘å…¨å›¾ GNN (Full-graph)ï¼Œå› ä¸ºæ•ˆæœå¥½ã€‚
2. **é˜»ç¢**ï¼šæ˜¾å­˜å¤ªå°ï¼Œæ”¾ä¸ä¸‹åäº¿çº§å¤§å›¾ã€‚
3. **å¦¥å**ï¼šåªèƒ½æŠŠæ•°æ®æ”¾ CPUï¼Œéœ€è¦ç”¨çš„æ—¶å€™é€šè¿‡ PCIe ä¼ ç»™ GPUã€‚
4. **æ–°é—®é¢˜**ï¼šPCIe å¤ªæ…¢äº†ï¼Œå˜æˆäº†ç“¶é¢ˆã€‚
5. **HongTu çš„è§£æ³• A (å‡å°‘å­˜é‡)** ï¼šåˆ©ç”¨**é‡è®¡ç®—**ç­–ç•¥ï¼Œå°‘å­˜ç‚¹ä¸­é—´æ•°æ®åœ¨æ˜¾å­˜é‡Œ ã€‚
6. **HongTu çš„è§£æ³• B (å‡å°‘ä¼ è¾“)** ï¼šå‘ç°é‚»å±…æ•°æ®è¢«é‡å¤ä¼ è¾“äº†ï¼Œè®¾è®¡ç®—æ³•è®©å®ƒä»¬åªä¼ ä¸€æ¬¡ï¼ˆ**å»é‡**ï¼‰ï¼Œå‰©ä¸‹çš„é€šè¿‡ GPU ä¹‹é—´äº’ä¼  ã€‚

## 2 è§£è¯»è®ºæ–‡ 
  
è¿™ç¯‡è®ºæ–‡ **ã€ŠHongTu: Scalable Full-Graph GNN Training on Multiple GPUsã€‹** ä»‹ç»äº†ä¸€ä¸ªåä¸º **HongTu (å®å›¾)** çš„ç³»ç»Ÿã€‚

**ä¸€å¥è¯æ€»ç»“ï¼š** HongTu æ˜¯ä¸€ä¸ªèƒ½è®©ä½ ç”¨å‡ å—æ™®é€š GPUï¼ˆæ˜¾å­˜æœ‰é™ï¼‰å°±èƒ½è®­ç»ƒ**åäº¿çº§èŠ‚ç‚¹**è¶…å¤§å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰çš„ç³»ç»Ÿï¼Œè€Œä¸”é€Ÿåº¦æ¯”å•çº¯ç”¨æ˜‚è´µçš„ CPU é›†ç¾¤å¿«å¾—å¤š ã€‚

å®ƒæ ¸å¿ƒè§£å†³çš„æ˜¯ **â€œæ˜¾å­˜æ”¾ä¸ä¸‹â€** å’Œ **â€œæ•°æ®ä¼ è¾“æ…¢â€** è¿™ä¸¤ä¸ªçŸ›ç›¾ã€‚ä¸‹é¢æˆ‘å°†ä¸ºä½ è¯¦ç»†è§£è¯»å®ƒçš„å…³é”®è®¾è®¡ã€‚

---

### 1. æ ¸å¿ƒèƒŒæ™¯ä¸æŒ‘æˆ˜åœ¨è®­ç»ƒè¶…å¤§å›¾ï¼ˆå¦‚ç¤¾äº¤ç½‘ç»œã€å¼•æ–‡ç½‘ç»œï¼‰æ—¶ï¼Œæœ€å¥½æ˜¯è¿›è¡Œ**å…¨å›¾è®­ç»ƒ (Full-Graph Training)** ï¼Œå› ä¸ºè¿™æ ·å‡†ç¡®ç‡æœ€é«˜ ã€‚

ä½†è¿™é‡Œæœ‰ä¸ªå·¨å¤§çš„**ç¡¬ä»¶ç“¶é¢ˆ**ï¼š

* **æ˜¾å­˜å¤ªå°**ï¼šå¤§å›¾çš„èŠ‚ç‚¹ç‰¹å¾å’Œè®­ç»ƒä¸­é—´æ•°æ®ï¼ˆIntermediate Dataï¼‰åŠ¨è¾„å‡ ç™¾ GB ç”šè‡³ TB çº§ï¼Œæ¯”å¦‚ *ogbn-paper* æ•°æ®é›†éœ€è¦ 6TB å†…å­˜ï¼Œè€Œä¸€å— A100 GPU åªæœ‰ 80GB ã€‚


* **ä¼ è¾“å¤ªæ…¢**ï¼šæ—¢ç„¶æ˜¾å­˜æ”¾ä¸ä¸‹ï¼Œåªèƒ½æŠŠæ•°æ®å­˜ CPU å†…å­˜é‡Œï¼Œè®­ç»ƒæ—¶å†ä¼ ç»™ GPUã€‚ä½† CPU å’Œ GPU ä¹‹é—´çš„é€šé“ï¼ˆPCIeï¼‰å¾ˆçª„ï¼ˆæ…¢ï¼‰ï¼Œä¼ è¾“æ•°æ®ä¼šå¡ä½æ•´ä¸ªè®­ç»ƒæµç¨‹ ã€‚



**HongTu çš„ä½¿å‘½**ï¼šæ—¢è¦æŠŠæ•°æ®æ”¾åœ¨ CPU ä¸Šä»¥èŠ‚çœæ˜¾å­˜ï¼Œåˆè¦æƒ³åŠæ³•æŠŠ CPU-GPU ä¹‹é—´çš„ä¼ è¾“é‡é™åˆ°æœ€ä½ï¼Œä¸è®©å®ƒæˆä¸ºç“¶é¢ˆ ã€‚

---

### 2. å…³é”®åˆ›æ–°ä¸€ï¼šåƒæ‹¼å›¾ä¸€æ ·åˆ‡åˆ†ä¸ç®¡ç†å†…å­˜ (Memory-Efficient Framework)ä¸ºäº†æŠŠå¤§å›¾å¡è¿›å°æ˜¾å­˜ï¼ŒHongTu åšäº†ä¸¤ä»¶äº‹ï¼š

#### A. äºŒçº§å›¾åˆ‡åˆ† (2-Level Graph Partitioning)HongTu ä¸æ˜¯ä¸€è‚¡è„‘æŠŠå›¾å¡ç»™ GPUï¼Œè€Œæ˜¯æŠŠå›¾åˆ‡å¾—å¾ˆç¢ ï¼š

1. **Level 1 (Partition)** ï¼šå…ˆæŠŠå¤§å›¾æŒ‰ GPU æ•°é‡åˆ‡æˆå‡ å¤§å—ï¼ˆPartitionï¼‰ï¼Œæ¯ä¸ª GPU è´Ÿè´£ä¸€å—ã€‚
2. **Level 2 (Chunk)** ï¼šåœ¨æ¯ä¸ª GPU å†…éƒ¨ï¼Œå†æŠŠå¤§å—åˆ‡æˆæ— æ•°ä¸ªå°å—ï¼ˆChunkï¼‰ã€‚
* *å¥½å¤„*ï¼šæ¯æ¬¡è®­ç»ƒåªéœ€è¦æŠŠè¿™ä¸€ä¸ªå° Chunk çš„æ•°æ®æ¬è¿›æ˜¾å­˜ï¼Œç®—å®Œå°±è…¾åœ°å„¿ï¼Œæ˜¾å­˜å ç”¨å¤§å¤§é™ä½ ã€‚





#### B. â€œæ··åˆâ€ä¸­é—´æ•°æ®ç®¡ç† (Recomputation-Caching-Hybrid)è®­ç»ƒç¥ç»ç½‘ç»œé€šå¸¸éœ€è¦ä¿å­˜å‰å‘ä¼ æ’­ï¼ˆForwardï¼‰çš„ä¸­é—´ç»“æœç”¨äºåå‘ä¼ æ’­ï¼ˆBackwardï¼‰ã€‚è¿™éå¸¸å å†…å­˜ã€‚
HongTu å‘ç° GNN æœ‰ä¸ªç‰¹ç‚¹ï¼šæœ‰äº›æ“ä½œï¼ˆå¦‚ GCN çš„èšåˆï¼‰è®¡ç®—ç®€å•ä½†ç»“æœå åœ°å¤§ï¼›æœ‰äº›æ“ä½œï¼ˆå¦‚ GAT çš„è¾¹è®¡ç®—ï¼‰è®¡ç®—å¤æ‚ã€‚

äºæ˜¯å®ƒè®¾è®¡äº†ä¸€å¥—**æ··åˆç­–ç•¥** ï¼š

* **å¯¹äºç®€å•æ“ä½œï¼ˆå¦‚ GCNï¼‰** ï¼š **ç¼“å­˜ (Caching)** ã€‚ç®—å®Œçš„ç»“æœç›´æ¥å­˜å› CPU å†…å­˜ï¼Œåå‘ä¼ æ’­æ—¶å†è¯»å›æ¥ã€‚è™½ç„¶æœ‰ä¼ è¾“å¼€é”€ï¼Œä½†æ¯”é‡ç®—åˆ’ç®— ã€‚


* **å¯¹äºå¤æ‚æ“ä½œï¼ˆå¦‚ GATï¼‰** ï¼š **é‡è®¡ç®— (Recomputation)** ã€‚ç®—å®Œå°±æ‰”ï¼Œåå‘ä¼ æ’­æ—¶å†é‡æ–°ç®—ä¸€éã€‚è™½ç„¶å¤šèŠ±äº†è®¡ç®—æ—¶é—´ï¼Œä½†çœä¸‹äº†å®è´µçš„æ˜¾å­˜ ã€‚



```mermaid
graph LR
    subgraph ä¼ ç»Ÿæ–¹æ³•
    A[å‰å‘è®¡ç®—] --> B{ä¿å­˜æ‰€æœ‰ä¸­é—´ç»“æœ}
    B --> C[æ˜¾å­˜çˆ†ç‚¸ ğŸ’¥]
    end
    
    subgraph HongTuæ··åˆç­–ç•¥
    D[å‰å‘è®¡ç®—] --> E{åˆ¤æ–­æ“ä½œç±»å‹}
    E -->|"ç®€å•èšåˆ (GCN)"| F[å­˜å…¥ CPU ç¼“å­˜]
    E -->|"å¤æ‚è®¡ç®— (GAT)"| G[æ‰”æ‰ç»“æœ, ç¨åé‡ç®—]
    F --> H[æ˜¾å­˜å ç”¨ä½ âœ…]
    G --> H
    end
```

---

### 3. å…³é”®åˆ›æ–°äºŒï¼šå»é‡é€šä¿¡æ¡†æ¶ (Deduplicated Communication) â€”â€” **è¿™æ˜¯æœ€æ ¸å¿ƒçš„äº®ç‚¹**åœ¨å¤š GPU è®­ç»ƒå›¾ç¥ç»ç½‘ç»œæ—¶ï¼Œå­˜åœ¨ä¸€ä¸ªä¸¥é‡çš„ **â€œæ•°æ®é‡å¤æ¬è¿â€** é—®é¢˜ã€‚
å› ä¸ºå›¾æ˜¯è¿é€šçš„ï¼Œåˆ‡åˆ†åï¼Œä¸åŒ GPU ä¸Šçš„èŠ‚ç‚¹å¯èƒ½å…±äº«åŒä¸€ä¸ªé‚»å±…ï¼ˆç§°ä¸ºâ€œHalo Nodesâ€ï¼‰ã€‚å¦‚æœæ¯ä¸ª GPU éƒ½å•ç‹¬å» CPU è¯·æ±‚è¿™ä¸ªé‚»å±…çš„æ•°æ®ï¼ŒPCIe æ€»çº¿å°±ä¼šå µæ­» ã€‚

HongTu æå‡ºäº†**å»é‡é€šä¿¡ (Deduplicated Communication)** ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š **â€œèƒ½è¹­è½¦å°±è¹­è½¦ï¼Œåˆ«æ¯ä¸ªäººéƒ½è‡ªå·±å¼€è½¦â€** ã€‚

#### A. è·¨ GPU å»é‡ (Inter-GPU Deduplication)åˆ©ç”¨ GPU ä¹‹é—´çš„é«˜é€Ÿé€šé“ï¼ˆå¦‚ NVLinkï¼Œé€Ÿåº¦æ˜¯ PCIe çš„ 6 å€ä»¥ä¸Šï¼‰ã€‚

* **ä»¥å‰**ï¼šGPU 0, 1, 2 éƒ½éœ€è¦â€œèŠ‚ç‚¹ Aâ€çš„æ•°æ®ã€‚å®ƒä»¬åˆ†åˆ«å‘ CPU è¯·æ±‚ 3 æ¬¡ã€‚
* **HongTu**ï¼šCPU åªæŠŠâ€œèŠ‚ç‚¹ Aâ€å‘ç»™ GPU 0ã€‚ç„¶å GPU 1 å’Œ 2 ç›´æ¥æ‰¾ GPU 0 è¦æ•°æ®ï¼ˆèµ° NVLink é«˜é€Ÿè·¯ï¼‰ã€‚
* **æ•ˆæœ**ï¼šåŸæœ¬æ‹¥å µçš„ CPU-GPU é€šè·¯ï¼ˆPCIeï¼‰çš„å‹åŠ›ç¬é—´å‡è½» ã€‚



#### B. GPU å†…å»é‡ (Intra-GPU Deduplication)åˆ©ç”¨æ—¶é—´çš„å±€éƒ¨æ€§ã€‚

* **ä»¥å‰**ï¼šGPU å¤„ç†å®Œ Chunk 1ï¼Œæ¸…ç©ºæ˜¾å­˜ï¼›æ¥ç€å¤„ç† Chunk 2ã€‚å¦‚æœè¿™ä¸¤ä¸ª Chunk éƒ½éœ€è¦â€œèŠ‚ç‚¹ Bâ€ï¼Œå°±è¦ä» CPU æ¬è¿ä¸¤æ¬¡ã€‚
* **HongTu**ï¼šåœ¨è°ƒåº¦ä»»åŠ¡æ—¶ï¼Œçœ‹çœ‹ä¸‹ä¸€æ‰¹ä»»åŠ¡éœ€è¦è°ã€‚å¦‚æœâ€œèŠ‚ç‚¹ Bâ€å·²ç»åœ¨æ˜¾å­˜é‡Œäº†ï¼Œå°±ç•™ç€ç»™ä¸‹ä¸€ä¸ªä»»åŠ¡ç”¨ï¼Œä¸ç”¨é‡æ–°æ¬ ã€‚



#### C. èªæ˜çš„ä»»åŠ¡é‡æ’ (Subgraph Reorganization)ä¸ºäº†è®©ä¸Šè¿°ä¸¤ç§â€œè¹­è½¦â€æ•ˆæœæœ€å¤§åŒ–ï¼ŒHongTu ä¼šåœ¨é¢„å¤„ç†é˜¶æ®µé‡æ–°æ’åˆ—ä»»åŠ¡é¡ºåº ã€‚

* å®ƒæŠŠå…±äº«é‚»å±…å¤šçš„ Chunk æ’åœ¨ä¸€èµ·æ‰§è¡Œï¼Œæœ€å¤§åŒ–æ•°æ®å¤ç”¨ç‡ï¼Œå°±åƒæŠŠé¡ºè·¯çš„ä¹˜å®¢å®‰æ’åœ¨åŒä¸€è¾†è½¦ä¸Š ã€‚



**(åŸºäºè®ºæ–‡ Fig 6 çš„ç®€åŒ–ç¤ºæ„å›¾)**

```mermaid
sequenceDiagram
    participant CPU
    participant GPU_A
    participant GPU_B
    
    Note over CPU, GPU_B: ä¼ ç»Ÿæ–¹æ³• (é‡å¤ä¼ è¾“)
    CPU->>GPU_A: å‘é€æ•°æ® X (æ…¢é€Ÿ PCIe)
    CPU->>GPU_B: å‘é€æ•°æ® X (æ…¢é€Ÿ PCIe)
    
    Note over CPU, GPU_B: HongTu æ–¹æ³• (å»é‡)
    CPU->>GPU_A: å‘é€æ•°æ® X (1æ¬¡æ…¢é€Ÿä¼ è¾“)
    GPU_A->>GPU_B: è½¬å‘æ•°æ® X (é«˜é€Ÿ NVLink ğŸš€)
    Note right of GPU_B: èŠ‚çœäº† 50% çš„ CPU é€šä¿¡!
```

![pic](20251213_03_pic_003.jpg)  

---

### 4. å®éªŒæ•ˆæœ (Results)è®ºæ–‡åœ¨ 4 å— NVIDIA A100 GPU ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œå¯¹æ¯”äº† DistGNNï¼ˆCPU é›†ç¾¤æ–¹æ¡ˆï¼‰å’Œå…¶ä»– GPU æ–¹æ¡ˆ ã€‚

* **é€šä¿¡é‡å¤§å¹…å‡å°‘**ï¼šç›¸æ¯”äºç›´æ¥ä¼ è¾“ï¼ŒHongTu å°† CPU-GPU çš„é€šä¿¡é‡å‡å°‘äº† **25% åˆ° 71%** ã€‚


* **é€Ÿåº¦ç¢¾å‹ CPU é›†ç¾¤**ï¼šç›¸æ¯”äºä½¿ç”¨äº† 16 ä¸ª CPU èŠ‚ç‚¹çš„ DistGNN ç³»ç»Ÿï¼ŒHongTu ä»…ç”¨ 4 å— GPU å°±å®ç°äº† **7.8å€ åˆ° 20.2å€** çš„åŠ é€Ÿ ã€‚


* **æ€§ä»·æ¯”æé«˜**ï¼šå› ä¸º GPU æ•°é‡å°‘ï¼Œç¡¬ä»¶æˆæœ¬æ˜¾è‘—ä½äºå¤§è§„æ¨¡ CPU é›†ç¾¤ ã€‚


* **å¯æ‰©å±•æ€§ (Scalability)** ï¼šéšç€ GPU æ•°é‡ä» 1 å¢åŠ åˆ° 4ï¼Œæ€§èƒ½æå‡æ¥è¿‘çº¿æ€§ï¼ˆ3.3x - 3.8xï¼‰ï¼Œè¯æ˜äº†è¯¥ç³»ç»Ÿèƒ½å¾ˆå¥½åœ°åˆ©ç”¨å¤šå¡èµ„æº ã€‚



### æ€»ç»“**HongTu** çš„æˆåŠŸåœ¨äºå®ƒèªæ˜åœ°â€œå‹æ¦¨â€äº†ç°ä»£ç¡¬ä»¶çš„ç‰¹æ€§ï¼š

1. æ—¢ç„¶æ˜¾å­˜å°ï¼Œå°±ç”¨ç²¾ç»†çš„åˆ‡åˆ†å’Œæ··åˆç¼“å­˜ç­–ç•¥æ¥çœç€ç”¨ã€‚
2. æ—¢ç„¶ CPU-GPU ä¼ è¾“æ…¢ï¼Œå°±åˆ©ç”¨ GPU ä¹‹é—´è¶…å¿«çš„ NVLink æ¥äº’ç›¸åˆ†äº«æ•°æ®ï¼Œå‡å°‘æ‰¾ CPU è¦æ•°æ®çš„æ¬¡æ•°ã€‚

è¿™ä½¿å¾—åœ¨å•å°å¤šå¡æœåŠ¡å™¨ä¸Šè®­ç»ƒè¶…å¤§è§„æ¨¡å›¾ç¥ç»ç½‘ç»œæˆä¸ºå¯èƒ½ï¼Œè€Œä¸”æ¯”å † CPU æœºå™¨æ›´ä¾¿å®œã€æ›´å¿«ã€‚
  
## 3 æœ¯è¯­ 
  
è¿™ç¯‡è®ºæ–‡ã€ŠHongTu: Scalable Full-Graph GNN Training on Multiple GPUsã€‹æå‡ºäº†ä¸€ç§åœ¨æ˜¾å­˜æœ‰é™çš„ GPU ä¸Šè®­ç»ƒè¶…å¤§å›¾ç¥ç»ç½‘ç»œçš„ç³»ç»Ÿã€‚ä¸ºäº†è¯»æ‡‚è¿™ç¯‡è®ºæ–‡ï¼Œæˆ‘ä¸ºä½ æå–å¹¶é€šä¿—è®²è§£äº†ä»¥ä¸‹ 6 ä¸ªæœ€æ ¸å¿ƒçš„æœ¯è¯­ã€‚

### 1. CPU æ•°æ®å¸è½½ (CPU Data Offloading)* **é€šä¿—è§£é‡Š**ï¼š
è¿™å°±å¥½æ¯”**å¨æˆ¿ï¼ˆGPU æ˜¾å­˜ï¼‰å¤ªå°ï¼Œæ”¾ä¸ä¸‹æ‰€æœ‰çš„é£Ÿæï¼ˆæµ·é‡å›¾æ•°æ®ï¼‰** ã€‚
æ‰€ä»¥ï¼Œæˆ‘ä»¬å°†é£Ÿæå…¨éƒ¨å­˜æ”¾åœ¨ç©ºé—´å·¨å¤§çš„**ä»“åº“ï¼ˆCPU å†…å­˜ï¼‰** é‡Œã€‚åªæœ‰å½“å¨å¸ˆï¼ˆGPU è®¡ç®—æ ¸å¿ƒï¼‰éœ€è¦ç‚’æŸé“èœæ—¶ï¼Œæ‰æ´¾äººå»ä»“åº“æŠŠé‚£éƒ¨åˆ†é£Ÿææ¬åˆ°å¨æˆ¿æ¥ ã€‚


* **è®ºæ–‡ä¸­çš„ä½œç”¨**ï¼š
è¿™æ˜¯ HongTu çš„åŸºç¡€æ¶æ„ã€‚å› ä¸ºå…¨å›¾è®­ç»ƒçš„æ•°æ®é‡ï¼ˆå¦‚ *ogbn-paper* æ•°æ®é›†éœ€è¦ 6TB å†…å­˜ï¼‰è¿œè¶… GPU æ˜¾å­˜ï¼ˆé€šå¸¸ä»… 80GBï¼‰ï¼Œå¿…é¡»æŠŠé¡¶ç‚¹ç‰¹å¾å­˜å‚¨åœ¨ CPU å†…å­˜ä¸­ï¼Œè®¡ç®—æ—¶å†ä¼ ç»™ GPU ã€‚



### 2. ä¸¤çº§å›¾åˆ‡åˆ† (Edge-Cut 2-Level Graph Partitioning)* **é€šä¿—è§£é‡Š**ï¼š
ä¸ºäº†æ–¹ä¾¿â€œåƒâ€ä¸‹å·¨å¤§çš„å›¾ï¼ŒHongTu é‡‡ç”¨äº†â€œåˆ‡ä¸¤åˆ€â€çš„ç­–ç•¥ ï¼š


1. **ç¬¬ä¸€åˆ€ (Partition)** ï¼šæŠŠå¤§è›‹ç³•åˆ‡æˆå‡ å¤§å—ï¼Œåˆ†ç»™ä¸åŒçš„ GPUï¼ˆæ¯”å¦‚ GPU 0, GPU 1ï¼‰ã€‚è¿™ä¿è¯äº†å¤šå¡å¹¶è¡Œå·¥ä½œã€‚
2. **ç¬¬äºŒåˆ€ (Chunk)** ï¼šåœ¨æ¯ä¸ª GPU æ‹¿åˆ°çš„å¤§å—é‡Œï¼Œå†åˆ‡æˆæ— æ•°ä¸ªâ€œä¸€å£å¤§å°â€çš„å°å—ï¼ˆChunkï¼‰ã€‚


* **ä¸ºä»€ä¹ˆè¿™ä¹ˆåšï¼Ÿ** å› ä¸ºå³ä½¿åˆ†ç»™äº† GPUï¼Œé‚£ä¸€æ•´å—å¯èƒ½è¿˜æ˜¯å¤ªå¤§å¡ä¸è¿›æ˜¾å­˜ã€‚åˆ‡æˆ Chunk åï¼ŒGPU æ¯æ¬¡åªç”¨åŠ è½½è¿™ä¸€å°å£æ•°æ®ï¼Œç®—å®Œå°±è…¾åœ°å„¿ï¼Œä»è€Œæå¤§åœ°èŠ‚çœäº†æ˜¾å­˜ ã€‚




> **å›¾ç¤ºå‚è€ƒ (åŸºäºå›¾ 2 å’Œå›¾ 5)** ï¼š
> å›¾ä¸­å±•ç¤ºäº† Partitionï¼ˆå¤§åˆ†åŒºï¼‰è¢«è¿›ä¸€æ­¥åˆ‡åˆ†ä¸º Chunk 0, Chunk 1... æ¯æ¬¡åªå¤„ç†ä¸€ä¸ªé¢œè‰²çš„æ¡† ã€‚
> 
> 

![pic](20251213_03_pic_004.jpg)  

![pic](20251213_03_pic_005.jpg)  

### 3. å…¨å›¾è®­ç»ƒ (Full-Graph Training)* **é€šä¿—è§£é‡Š**ï¼š
åœ¨å­¦ä¹ æ—¶ï¼Œä½ æ˜¯æŠŠæ•´æœ¬æ•™ç§‘ä¹¦çš„æ‰€æœ‰çŸ¥è¯†ç‚¹å…³è”èµ·æ¥å­¦ï¼ˆå…¨å›¾ï¼‰ï¼Œè¿˜æ˜¯æ¯æ¬¡åªéšæœºæŠ½å‡ é¡µå¤å°ä»¶æ¥å­¦ï¼ˆMini-batch é‡‡æ ·ï¼‰ï¼Ÿ
* **Mini-batch**ï¼šçœè„‘å­ï¼ˆçœå†…å­˜ï¼‰ï¼Œä½†å¯èƒ½æ¼æ‰çŸ¥è¯†ç‚¹ä¹‹é—´çš„è”ç³»ï¼Œå¯¼è‡´è€ƒåˆ†ä¸é«˜ï¼ˆç²¾åº¦æŸå¤±ï¼‰ã€‚
* **Full-graph**ï¼šè™½ç„¶è´¹è„‘å­ï¼ˆè€—å†…å­˜ã€ç®—åŠ›å¤§ï¼‰ï¼Œä½†èƒ½æŒæ¡æ‰€æœ‰ç»†èŠ‚ï¼Œæ¨¡å‹æ•ˆæœæœ€å¥½ ã€‚




* **æ ¸å¿ƒéš¾ç‚¹**ï¼šHongTu åšæŒåšå…¨å›¾è®­ç»ƒä»¥ä¿è¯é«˜ç²¾åº¦ï¼Œä½†å¿…é¡»è§£å†³è¿™å°±å¸¦æ¥çš„å†…å­˜çˆ†ç‚¸é—®é¢˜ ã€‚



### 4. é‡è®¡ç®—ä¸ç¼“å­˜æ··åˆç®¡ç† (Recomputation-Caching-Hybrid)* **é€šä¿—è§£é‡Š**ï¼š
åœ¨è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¿å­˜å‰å‘è®¡ç®—çš„â€œè‰ç¨¿â€ï¼ˆä¸­é—´æ•°æ®ï¼‰ä»¥ä¾¿åå‘æ£€æŸ¥ï¼ˆè®¡ç®—æ¢¯åº¦ï¼‰ã€‚ç”±äºè‰ç¨¿å¤ªå¤šï¼ŒHongTu é‡‡ç”¨äº†ä¸€ç§ **â€œçœ‹æƒ…å†µâ€** çš„ç­–ç•¥ ï¼š


* **ç®€å•é¢˜ï¼ˆå¦‚ GCNï¼‰** ï¼šè‰ç¨¿å¾ˆå°ï¼Œç®—è¿™é“é¢˜å´å¾ˆè´¹äº‹ã€‚ç­–ç•¥æ˜¯ **â€œç¼“å­˜â€** â€”â€” æŠŠè‰ç¨¿å­˜å› CPU ä»“åº“ï¼Œä¸‹æ¬¡ç›´æ¥æ‹¿æ¥ç”¨ ã€‚


* **å¤æ‚é¢˜ï¼ˆå¦‚ GATï¼‰** ï¼šè‰ç¨¿ç‰¹åˆ«å¤§ï¼ˆå å‡ ç™¾ GBï¼‰ï¼Œå­˜ä¸ä¸‹ã€‚ç­–ç•¥æ˜¯ **â€œé‡è®¡ç®—â€** â€”â€” ç®—å®Œå°±æŠŠè‰ç¨¿æ‰”äº†ï¼Œç­‰éœ€è¦æ£€æŸ¥æ—¶ï¼Œå†é‡æ–°ç®—ä¸€éã€‚è™½ç„¶å¤šèŠ±äº†ç‚¹æ—¶é—´ï¼Œä½†çœä¸‹äº†å®è´µçš„ç©ºé—´ ã€‚




```mermaid
graph LR
A[äº§ç”Ÿä¸­é—´æ•°æ®] --> B{è®¡ç®—ç±»å‹å¤æ‚å—?}
B -- ç®€å•(GCN) --> C["å­˜å…¥CPUç¼“å­˜ (Caching)"]
B -- å¤æ‚(GAT) --> D["ç›´æ¥ä¸¢å¼ƒ, éœ€è¦æ—¶é‡ç®— (Recomputation)"]
```



### 5. é‡å¤é‚»å±… (Duplicated Neighbors / Halo Nodes)* **é€šä¿—è§£é‡Š**ï¼š
è®¾æƒ³å›¾æ˜¯ä¸€ä¸ªç¤¾äº¤ç½‘ç»œã€‚å¦‚æœæŠŠäººç¾¤åˆ‡åˆ†å¼€ï¼Œ **â€œå¤§æ˜æ˜Ÿâ€ï¼ˆçƒ­é—¨èŠ‚ç‚¹ï¼‰** å¯èƒ½æ˜¯å¾ˆå¤šäººçš„æœ‹å‹ã€‚
* GPU 1 è´Ÿè´£çš„äººç¾¤è®¤è¯†å¤§æ˜æ˜Ÿã€‚
* GPU 2 è´Ÿè´£çš„äººç¾¤ä¹Ÿè®¤è¯†å¤§æ˜æ˜Ÿã€‚
* ç»“æœï¼šè¿™ä¸ªâ€œå¤§æ˜æ˜Ÿâ€çš„æ•°æ®è¢«å¤åˆ¶äº†å¾ˆå¤šä»½ï¼Œè¿™å°±å«é‡å¤é‚»å±… ã€‚




* **åæœ**ï¼šå¦‚æœä¸å¤„ç†ï¼Œç”±äºæ¯ä¸ªåˆ†åŒºéƒ½è¦æŠŠå¤§æ˜æ˜Ÿä» CPU æ¬è¿ä¸€æ¬¡ï¼Œä¼šå¯¼è‡´ CPU åˆ° GPU çš„é‚£æ¡å°è·¯ï¼ˆPCIeï¼‰ä¸¥é‡å µè½¦ ã€‚



### 6. å»é‡é€šä¿¡ (Deduplicated Communication)* **é€šä¿—è§£é‡Š**ï¼š
è¿™æ˜¯ HongTu è§£å†³â€œå µè½¦â€çš„ç‹¬é—¨ç»æŠ€ ã€‚ç­–ç•¥å« **â€œåªè¿ä¸€æ¬¡ï¼Œå†…éƒ¨å…±äº«â€** ï¼š


* **è·¨ GPU å»é‡**ï¼šæ—¢ç„¶ GPU 1 å’Œ GPU 2 éƒ½éœ€è¦â€œå¤§æ˜æ˜Ÿâ€çš„æ•°æ®ï¼ŒCPU å°±ä¸å‘ä¸¤éäº†ã€‚CPU åªå‘ç»™ GPU 1ï¼Œç„¶å GPU 1 é€šè¿‡å®ƒä»¬ä¹‹é—´çš„é«˜é€Ÿä¸“çº¿ï¼ˆNVLinkï¼Œæ¯” CPU çº¿å¿«å¾—å¤šï¼‰ä¼ ç»™ GPU 2 ã€‚


* **GPU å†…å»é‡**ï¼šå¦‚æœ GPU 1 ç°åœ¨å¤„ç†çš„ä»»åŠ¡éœ€è¦â€œå¤§æ˜æ˜Ÿâ€ï¼Œä¸‹ä¸€ä¸ªä»»åŠ¡ä¹Ÿéœ€è¦ã€‚é‚£å°±æŠŠâ€œå¤§æ˜æ˜Ÿâ€ç•™åœ¨æ˜¾å­˜é‡Œåˆ«åˆ ï¼Œä¸‹ä¸€ä¸ªä»»åŠ¡ç›´æ¥ç”¨ï¼ˆReuseï¼‰ï¼Œä¸ç”¨å†æ‰¾ CPU è¦ ã€‚




> **æ•°æ®ä½è¯**ï¼š
> è¿™ç§â€œæ‹¼è½¦â€ç­–ç•¥èƒ½å‡å°‘ **25% åˆ° 71%** çš„ CPU-GPU æ•°æ®ä¼ è¾“é‡ï¼Œå¤§å¹…æå‡é€Ÿåº¦ ã€‚
> 
> 


**(å‚è€ƒè®ºæ–‡ Fig. 6 çš„é€»è¾‘)**

```mermaid
sequenceDiagram
    participant CPU
    participant GPU_A
    participant GPU_B
    Note over CPU, GPU_B: ä¼ ç»Ÿæ¨¡å¼ (æ‹¥å µ)
    CPU->>GPU_A: å‘é€èŠ‚ç‚¹X (æ…¢)
    CPU->>GPU_B: å‘é€èŠ‚ç‚¹X (æ…¢)

    Note over CPU, GPU_B: HongTu å»é‡æ¨¡å¼ (é«˜é€Ÿ)
    CPU->>GPU_A: å‘é€èŠ‚ç‚¹X (1æ¬¡æ…¢é€Ÿ)
    GPU_A->>GPU_B: è½¬å‘èŠ‚ç‚¹X (NVLink é«˜é€Ÿäº’è”)
```

![pic](20251213_03_pic_003.jpg)  
  
## å‚è€ƒ        
         
https://arxiv.org/pdf/2311.14898    
        
<b> ä»¥ä¸Šå†…å®¹åŸºäºDeepSeekã€Qwenã€GeminiåŠè¯¸å¤šAIç”Ÿæˆ, è½»å¾®äººå·¥è°ƒæ•´, æ„Ÿè°¢æ­å·æ·±åº¦æ±‚ç´¢äººå·¥æ™ºèƒ½ã€é˜¿é‡Œäº‘ã€Googleç­‰å…¬å¸. </b>        
        
<b> AI ç”Ÿæˆçš„å†…å®¹è¯·è‡ªè¡Œè¾¨åˆ«æ­£ç¡®æ€§, å½“ç„¶ä¹Ÿå¤šäº†äº›è®¸è¸©å‘çš„ä¹è¶£, æ¯•ç«Ÿå†’é™©æ˜¯æ¯ä¸ªç”·äººçš„å¤©æ€§.  </b>        
    
#### [PolarDB å­¦ä¹ å›¾è°±](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL è§£å†³æ–¹æ¡ˆé›†åˆ](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [å¾·å“¥ / digoal's Github - å…¬ç›Šæ˜¯ä¸€è¾ˆå­çš„äº‹.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About å¾·å“¥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
