## 用 AI 分析谷歌财报 6 AI超算杀手锏  
            
### 作者            
digoal            
            
### 日期            
2026-01-23            
            
### 标签            
财报分析 , AI            
            
----            
            
## 背景            
接上一篇, 本篇分析“谷歌最新的 AI Hypercomputer（AI超级计算机）是如何整合这些硬件和软件的?”           
            
-----            
            
谷歌的 **AI Hypercomputer（AI超级计算机）** 并不是一个简单的硬件堆叠，而是一个**全栈系统架构**。它的核心逻辑是： **“将数据中心视为一台计算机”** 。  
  
在 2025 年的财报和技术白皮书中，谷歌强调了这种“系统级”整合如何帮助其在保持高性能的同时，大幅降低运行万亿参数模型（如 Gemini）的单位成本。以下是其硬件与软件整合的四个关键层级：  
  
### 1. 硬件层：异构算力的“池化”  
  
AI Hypercomputer 允许在同一套系统内混合使用 **TPU** 和 **NVIDIA GPU**。  
* **液冷技术（Liquid Cooling）：** 随着 Trillium (TPU v6) 和 NVIDIA Blackwell 的部署，能耗极高。谷歌通过在数据中心大规模部署液冷基础设施，将芯片产生的热量直接通过水循环排走，这使得芯片可以长时间满频率运行而不降频。  
* **自研高性能存储（Hyperdisk）：** AI训练需要极快的数据吞吐。Hyperdisk 允许动态分配存储吞吐量，确保芯片在训练时不会因为“等数据”而闲置。  
  
### 2. 互联层：光电路交换（OCS）的“神经系统”  
  
这是谷歌区别于所有友商的“杀手锏”。  
* **OCS (Optical Circuit Switching)：** 传统的超级计算机使用电信号交换机，成本高且延迟大。谷歌自研了光交换机，通过微小的镜片反射光束来建立连接。  
* **动态拓扑：** 软件可以实时更改芯片之间的连接方式（拓扑结构）。如果你今天训练一个超大模型，OCS 可以把几万颗 TPU 连成一个巨大的环形；明天如果你做小模型推理，它可以秒级切换成数千个独立的小集群。这种**灵活性**极大地提高了设备利用率。  
  
### 3. 软件编排层：从集群到“单一算力池”  
  
谷歌通过自研的系统软件，让开发者感觉是在一台巨大的电脑上编程，而不是在几万台服务器上分发任务：  
* **Dynamic Workload Scheduler：** 这是大脑。它会根据任务优先级自动分配资源。例如，它能预测哪部分计算最费钱，并自动将其调度到能效比更高的 TPU 上运行。  
* **Multislice 训练技术：** 传统的训练受限于单个机架，而 Multislice 允许模型跨越数个物理集群进行无缝训练。这意味着谷歌可以训练比对手大 10 倍的模型，而不会因为网络延迟导致训练中断。  
  
### 4. 编译器层：XLA 与 JAX 的深度优化  
  
硬件再强，如果没有好的翻译官（编译器）也是徒劳。  
* **XLA (Accelerated Linear Algebra)：** 这是一个专门为张量运算设计的编译器。它可以扫描 AI 代码，并将其转化为最适合 TPU 或 GPU 执行的机器语言。  
* **全栈优化：** 谷歌的软件工程师在开发 Gemini 时，会直接向硬件工程师反馈：*“我们需要一种新的数据格式（如 FP4）来加速推理”*。硬件团队随后会在下一代 TPU（如 Ironwood）中直接加入这个指令集。这种**软硬件协同进化（Co-design）** 是微软或亚马逊短期内难以企及的。  
  
### 总结：这种整合对投资者的意义  
  
对于投资者来说，AI Hypercomputer 的真正价值在于 **“效率带来的毛利率提升”** 。  
* **避开英伟达税：** 通过整合自研的 OCS 互联和 TPU，谷歌在提供相同 AI 算力时，资本支出（CapEx）的效率远高于完全依赖英伟达的友商。  
* **云业务的护城河：** 谷歌云不再只是卖 CPU 空间，而是卖这套“AI 超级计算机系统”。由于这套系统高度复杂（涉及光物理、液冷基础设施、编译器底层），竞争对手很难通过简单的购买硬件来复制这种性能。  
  
正如财报所反映的，**Google Cloud 的利润率从去年同期的 17% 跃升至今年的近 24%** ，很大程度上归功于这种全栈整合带来的运营效率提升。  
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
