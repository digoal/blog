## 解密顶级AI应用的系统提示词   
    
### 作者    
digoal    
    
### 日期    
2026-02-25    
    
### 标签    
system prompt , 提示词注入   
    
----    
    
## 背景    
一个收集了大量市面上流行的开源及商业AI应用的系统提示词项目, 居然有 123k star !  
  
凭什么?  
  
https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools  
  
这个 GitHub 项目 **`x1xhlol/system-prompts-and-models-of-ai-tools`** 是目前 AI 社区中非常硬核且备受关注的一个资源库。简单来说，它是一个**全球知名 AI 工具“系统提示词（System Prompts）”的地下博物馆或档案馆**。  
  
以下是对该项目的深度解读：  
  
### 1. 项目核心内容  
  
该项目收集了大量主流 AI 产品（如 Cursor, Manus, v0, Devin, Windsurf, Trae 等）的 **内部系统提示词（System Prompts）** 和**工具/插件配置**。  
  
* **系统提示词是什么？** 它是 AI 模型的“出厂设置”或“思维钢印”。例如，当你使用 Cursor 编写代码时，Cursor 背后的模型之所以表现得像一个资深程序员，是因为有一段长达数千行的指令（System Prompt）在告诉它：“你是一个世界级的开发助手，你需要遵循以下代码规范，你可以调用这些本地文件工具……”  
* **规模庞大：** 项目包含超过 30,000 行的提示词内容，揭示了这些顶尖 AI 工具是如何通过复杂的指令工程（Prompt Engineering）来实现其强大功能的。  
  
### 2. 涵盖的知名工具  
  
这个库更新频率极高，几乎涵盖了目前市面上所有热门的 AI 代理（AI Agents）和开发工具：  
  
* **编程类：** Cursor (最新版), Windsurf, Trae, GitHub Copilot, Replit Agent, Devin。  
* **代码生成/前端类：** v0.dev, Lovable, Bolt.new, Lovable.ai。  
* **搜索与通用类：** Perplexity, Search1API, 以及最近爆火的自动智能体 **Manus**。  
  
### 3. 项目的价值（为什么这么多人看？）  
  
* **揭秘“魔法”背后的逻辑：** 很多人好奇为什么某些 AI 产品比原生的 GPT-4 或 Claude 3.5 好用。通过查看这些提示词，你可以看到这些公司是如何通过 **思维链（CoT）** 、**工具调用（Function Calling）规范**以及**异常处理流程**来调教模型的。  
* **学习提示词工程：** 对于开发者来说，这是学习如何编写“高质量、逻辑严密、多轮对话稳定”提示词的教科书级参考。你可以学习它们如何定义 Agent 的身份、限制、工作流和报错机制。  
* **复刻或开发类似产品：** 许多创业者参考这些提示词, 再结合开源大模型或微调过的模型来构建自己的垂直领域 AI 助手。  
  
### 4. 敏感性与争议  
  
* **泄露与反编译：** 这些提示词通常不是官方主动公开的，而是通过“提示词注入（Prompt Injection）”等手段从模型中“套”出来的。因此，该项目处于一个法律和道德的模糊地带。  
* **安全警示：** 作者在 README 中也提醒 AI 初创公司，如果系统提示词被轻易泄露，可能会面临被逆向工程或竞争对手抄袭的风险（建议关注其提到的 ZeroLeaks 等安全服务）。  
  
### 5. 总结  
  
如果你是一个 **AI 开发者**、**提示词工程师**，或者单纯好奇 **AI 是如何被“洗脑”执行特定任务的**，这个项目是目前全网最全的参考资料库。  
  
**访问建议：**  
你可以直接在文件夹中搜索你感兴趣的工具名称（如 `Cursor`），查看里面的 `.txt` 或 `.md` 文件，你会发现这些“大牛”产品的内部指令往往非常精细，甚至连“不要在回复中啰嗦”、“输出代码前先思考”这种细节都有极严格的规定。  
  
