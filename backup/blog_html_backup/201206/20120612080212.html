<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=gbk">
<title>PostgreSQL research</title>
<style type="text/css">
.blogcnt{line-height:160%;font-size:14px;text-align:left;word-wrap:break-word;}
.blogcnt *{line-height:160%;}
.blogcnt p{margin:0 0 10px;}
.blogcnt ul,.nbw-blog ol{margin:5px 0 5px 40px;padding:0}
.blogcnt em{font-style:italic;}
.blogcnt blockquote{font-size:1em;margin:auto 0 auto 35px;}
.blogcnt img{border:0;max-width:100%;}
</style>
</head>
<body style="color:#444444;">
<h1 id="blog-Title"><a href="index.html">PostgreSQL research</a></h1>
<div id="" style="padding:0 20px;">
	<h2 id="">tmpfs</h2>
	<h5 id="">2012-06-12 8:02:12&nbsp;&nbsp;&nbsp;<a href="http://blog.163.com/digoal@126/blog/static/16387704020125128212880/" target="_blank">查看原文&gt;&gt;</a></h5>
	<div class="" id="" style="padding:0 20px;">
		<div class="blogcnt" style="width:800px;"><div>Tmpfs is a file system which keeps all files in virtual memory.</div><div><br></div><div><br></div><div>Everything in tmpfs is temporary in the sense that no files will be</div><div>created on your hard drive. If you unmount a tmpfs instance,</div><div>everything stored therein is lost.</div><div><br></div><div>tmpfs puts everything into the kernel internal caches and grows and</div><div>shrinks to accommodate the files it contains and is able to swap</div><div>unneeded pages out to swap space. It has maximum size limits which can</div><div>be adjusted on the fly via 'mount -o remount ...'</div><div><br></div><div>If you compare it to ramfs (which was the template to create tmpfs)</div><div>you gain swapping and limit checking. Another similar thing is the RAM</div><div>disk (/dev/ram*), which simulates a fixed size hard disk in physical</div><div>RAM, where you have to create an ordinary filesystem on top. Ramdisks</div><div>cannot swap and you do not have the possibility to resize them.&nbsp;</div><div><br></div><div>Since tmpfs lives completely in the page cache and on swap, all tmpfs</div><div>pages currently in memory will show up as cached. It will not show up</div><div>as shared or something like that. Further on you can check the actual</div><div>RAM+swap use of a tmpfs instance with df(1) and du(1).</div><div><br></div><div><br></div><div>tmpfs has the following uses:</div><div><br></div><div>1) There is always a kernel internal mount which you will not see at</div><div>&nbsp; &nbsp;all. This is used for shared anonymous mappings and SYSV shared</div><div>&nbsp; &nbsp;memory.&nbsp;</div><div><br></div><div>&nbsp; &nbsp;This mount does not depend on CONFIG_TMPFS. If CONFIG_TMPFS is not</div><div>&nbsp; &nbsp;set, the user visible part of tmpfs is not build. But the internal</div><div>&nbsp; &nbsp;mechanisms are always present.</div><div><br></div><div>2) glibc 2.2 and above expects tmpfs to be mounted at /dev/shm for</div><div>&nbsp; &nbsp;POSIX shared memory (shm_open, shm_unlink). Adding the following</div><div>&nbsp; &nbsp;line to /etc/fstab should take care of this:</div><div><br></div><div>&nbsp; &nbsp; &nbsp; &nbsp; tmpfs &nbsp; /dev/shm &nbsp; &nbsp; &nbsp; &nbsp;tmpfs &nbsp; defaults &nbsp; &nbsp; &nbsp; &nbsp;0 0</div><div><br></div><div>&nbsp; &nbsp;Remember to create the directory that you intend to mount tmpfs on</div><div>&nbsp; &nbsp;if necessary (/dev/shm is automagically created if you use devfs).</div><div><br></div><div>&nbsp; &nbsp;This mount is _not_ needed for SYSV shared memory. The internal</div><div>&nbsp; &nbsp;mount is used for that. (In the 2.3 kernel versions it was</div><div>&nbsp; &nbsp;necessary to mount the predecessor of tmpfs (shm fs) to use SYSV</div><div>&nbsp; &nbsp;shared memory)</div><div><br></div><div>3) Some people (including me) find it very convenient to mount it</div><div>&nbsp; &nbsp;e.g. on /tmp and /var/tmp and have a big swap partition. And now</div><div>&nbsp; &nbsp;loop mounts of tmpfs files do work, so mkinitrd shipped by most</div><div>&nbsp; &nbsp;distributions should succeed with a tmpfs /tmp.</div><div><br></div><div>4) And probably a lot more I do not know about :-)</div><div><br></div><div><br></div><div>tmpfs has three mount options for sizing:</div><div><br></div><div>size: &nbsp; &nbsp; &nbsp;The limit of allocated bytes for this tmpfs instance. The&nbsp;</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;default is half of your physical RAM without swap. If you</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;oversize your tmpfs instances the machine will deadlock</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;since the OOM handler will not be able to free that memory.</div><div>nr_blocks: The same as size, but in blocks of PAGE_CACHE_SIZE.</div><div>nr_inodes: The maximum number of inodes for this instance. The default</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;is half of the number of your physical RAM pages, or (on a</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;a machine with highmem) the number of lowmem RAM pages,</div><div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;whichever is the lower.</div><div><br></div><div>These parameters accept a suffix k, m or g for kilo, mega and giga and</div><div>can be changed on remount. &nbsp;The size parameter also accepts a suffix %</div><div>to limit this tmpfs instance to that percentage of your physical RAM:</div><div>the default, when neither size nor nr_blocks is specified, is size=50%</div><div><br></div><div>If nr_blocks=0 (or size=0), blocks will not be limited in that instance;</div><div>if nr_inodes=0, inodes will not be limited. &nbsp;It is generally unwise to</div><div>mount with such options, since it allows any user with write access to</div><div>use up all the memory on the machine; but enhances the scalability of</div><div>that instance in a system with many cpus making intensive use of it.</div><div><br></div><div><br></div><div>tmpfs has a mount option to set the NUMA memory allocation policy for</div><div>all files in that instance (if CONFIG_NUMA is enabled) - which can be</div><div>adjusted on the fly via 'mount -o remount ...'</div><div><br></div><div>mpol=default &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; prefers to allocate memory from the local node</div><div>mpol=prefer:Node &nbsp; &nbsp; &nbsp; &nbsp; prefers to allocate memory from the given Node</div><div>mpol=bind:NodeList &nbsp; &nbsp; &nbsp; allocates memory only from nodes in NodeList</div><div>mpol=interleave &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;prefers to allocate from each node in turn</div><div>mpol=interleave:NodeList allocates from each node of NodeList in turn</div><div><br></div><div>NodeList format is a comma-separated list of decimal numbers and ranges,</div><div>a range being two hyphen-separated decimal numbers, the smallest and</div><div>largest node numbers in the range. &nbsp;For example, mpol=bind:0-3,5,7,9-15</div><div><br></div><div>Note that trying to mount a tmpfs with an mpol option will fail if the</div><div>running kernel does not support NUMA; and will fail if its nodelist</div><div>specifies a node &gt;= MAX_NUMNODES. &nbsp;If your system relies on that tmpfs</div><div>being mounted, but from time to time runs a kernel built without NUMA</div><div>capability (perhaps a safe recovery kernel), or configured to support</div><div>fewer nodes, then it is advisable to omit the mpol option from automatic</div><div>mount options. &nbsp;It can be added later, when the tmpfs is already mounted</div><div>on MountPoint, by 'mount -o remount,mpol=Policy:NodeList MountPoint'.</div><div><br></div><div><br></div><div>To specify the initial root directory you can use the following mount</div><div>options:</div><div><br></div><div>mode: &nbsp; The permissions as an octal number</div><div>uid: &nbsp; &nbsp;The user id&nbsp;</div><div>gid: &nbsp; &nbsp;The group id</div><div><br></div><div>These options do not have any effect on remount. You can change these</div><div>parameters with chmod(1), chown(1) and chgrp(1) on a mounted filesystem.</div><div><br></div><div><br></div><div>So 'mount -t tmpfs -o size=10G,nr_inodes=10k,mode=700 tmpfs /mytmpfs'</div><div>will give you tmpfs instance on /mytmpfs which can allocate 10GB</div><div>RAM/SWAP in 10240 inodes and it is only accessible by root.</div><div><br></div><div><br></div><div>Author:</div><div>&nbsp; &nbsp;Christoph Rohland &lt;cr@sap.com&gt;, 1.12.01</div><div>Updated:</div><div>&nbsp; &nbsp;Hugh Dickins &lt;hugh@veritas.com&gt;, 19 February 2006</div><div><br></div><div><br></div><div>【参考】</div><div>kernel-doc/Documentation/filesystems/tmpfs.txt</div><div><br></div><div>【其他】</div><div>The following names are reserved for mounting special filesystems</div><div><div>under /dev. &nbsp;These special filesystems provide kernel interfaces that</div><div>cannot be provided with standard device nodes.</div><div><br></div><div>/dev/pts &nbsp; &nbsp; &nbsp; &nbsp;devpts &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;PTY slave filesystem</div><div>/dev/shm &nbsp; &nbsp; &nbsp; &nbsp;tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; POSIX shared memory maintenance access</div></div><div><br></div><div>【摘录1】</div><div><div>一、/dev/shm理论</div><div>/dev/shm/是linux下一个非常有用的目录，因为这个目录不在硬盘上，而是在内存里。因此在linux下，就不需要大费周折去建ramdisk，直接使用/dev/shm/就可达到很好的优化效果。 /dev /shm/需要注意的一个是容量问题，在linux下，它默认最大为内存的一半大小，使用df -h命令可以看到。但它并不会真正的占用这块内存，如果/dev/shm/下没有任何文件，它占用的内存实际上就是0字节；如果它最大为1G，里头放有 100M文件，那剩余的900M仍然可为其它应用程序所使用，但它所占用的100M内存，是绝不会被系统回收重新划分的，否则谁还敢往里头存文件呢？</div><div>默认系统就会加载/dev/shm ，它就是所谓的tmpfs，有人说跟ramdisk（虚拟磁盘），但不一样。象虚拟磁盘一样，tmpfs 可以使用您的 RAM，但它也可以使用您的交换分区来存储。而且传统的虚拟磁盘是个块设备，并需要一个 mkfs 之类的命令才能真正地使用它，tmpfs 是一个文件系统，而不是块设备；您只是安装它，它就可以使用了。</div><div>　　tmpfs有以下优势：</div><div>　　1，动态文件系统的大小。</div><div>　　2，tmpfs 的另一个主要的好处是它闪电般的速度。因为典型的 tmpfs 文件系统会完全驻留在 RAM 中，读写几乎可以是瞬间的。</div><div>　　3，tmpfs 数据在重新启动之后不会保留，因为虚拟内存本质上就是易失的。所以有必要做一些脚本做诸如加载，绑定的操作。</div><div>二、修改/dev/shm大小</div><div>默认的最大一半内存大小在某些场合可能不够用，并且默认的inode数量很低一般都要调高些，这时可以用mount命令来管理它。</div><div>#mount -o size=1500M -o nr_inodes=1000000 -o noatime,nodiratime -o remount /dev/shm</div><div>在2G的机器上，将最大容量调到1.5G，并且inode数量调到1000000，这意味着大致可存入最多一百万个小文件。</div><div>如果需要永久修改/dev/shm的值，需要修改/etc/fstab</div><div>tmpfs /dev/shm tmpfs defaults,size=1.5G 0 0</div><div>#mount -o remount /dev/shm</div><div>三、/dev/shm应用</div><div>　　首先在/dev/shm建个tmp文件夹，然后与实际/tmp绑定</div><div>　　#mkdir /dev/shm/tmp</div><div>　　#chmod 1777 /dev/shm/tmp</div><div>　　#mount Cbind /dev/shm/tmp /tmp（Cbind ）</div><div>　　在使用mount Cbind olderdir newerdir命令来挂载一个目录到另一个目录后，newerdir的权限和所有者等所有信息会发生变化。挂载后的目录继承了被挂载目录的所有属性，除了名称。Oracle 11g的amm内存管理模式就是使用/dev/shm，所以有时候修改MEMORY_TARGET或者MEMORY_MAX_TARGET会出现ORA-00845的错误.</div></div><wbr><br><div>【摘录2】</div><div><div>什么是tmpfs?</div><div>tmpfs是Linux/Unix系统上的一种基于内存的文件系统。tmpfs可以使用您的内存或swap分区来存储文件。由此可见，temfs主要存储暂存的文件。</div><div>linux内核中的VM子系统负责在后台管理虚拟内存资源Virtual Memory，即RAM和swap资源，透明地将RAM页移动到交换分区或从交换分区到RAM页，tmpfs文件系统需要VM子系统的页面来存储文件。tmpfs自己并不知道这些页面是在交换分区还是在RAM中；做这种决定是VM子系统的工作。tmpfs文件系统所知道的就是它正在使用某种形式的虚拟内存。</div><div>tmpfs基于内存，因而速度是相当的，另外tmpfs使用的VM资源是动态的，当删除tmpfs中文件，tmpfs 文件系统驱动程序会动态地减小文件系统并释放 VM 资源，当然在其中创建文件时也会动态的分配VM资源。另外，tmpfs不具备持久性，重启后数据不保留，原因很明显，它是基于内存的。</div><div>编译内核时，启用“Virtual memory file system support”就可以使用tmpfs,linux kernel从2.4以后都开始支持tmpfs。目前主流的linux系统默认已启用tmpfs，如Redhat。</div><div><br></div><div>什么是/dev/shm?</div><div>看到dev大家都使知道它是一个设备文件。使用tmpfs文件系统，在Redhat/CentOS等linux发行版中默认大小为物理内存的一半。如我的虚拟机装的是CentOS6.0,分配内存为1G，所以/dev/shm为500M左右。</div><div>[root@GoGo tmp]# df -h</div><div>Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</div><div>/dev/sda3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 8.8G &nbsp;4.0G &nbsp;4.5G &nbsp;48% /</div><div>tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 499M &nbsp; 88K &nbsp;499M &nbsp; 1% /dev/shm</div><div>/dev/sda1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;97M &nbsp; 43M &nbsp; 50M &nbsp;47% /boot</div><div><br></div><div>tmpfs是基于内存的文件系统，创建时不需要使用mkfs等初始化。如我想把/dev/shm tmpfs大小改为512M.</div><div>#vi /etc/fstab</div><div>tmpfs &nbsp; &nbsp; &nbsp; /dev/shm &nbsp; &nbsp;tmpfs &nbsp;defaults &nbsp; 0 &nbsp; 0</div><div>更改为</div><div>tmpfs &nbsp; &nbsp; &nbsp; /dev/shm &nbsp; &nbsp;tmpfs &nbsp;defaults,size=512m &nbsp; 0 &nbsp; &nbsp;0</div><div><br></div><div>[root@GoGo tmp]# mount -o remount /dev/shm</div><div>[root@GoGo tmp]# df -h</div><div>Filesystem &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Size &nbsp;Used Avail Use% Mounted on</div><div>/dev/sda3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 8.8G &nbsp;4.0G &nbsp;4.5G &nbsp;48% /</div><div>tmpfs &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 512M &nbsp; 88K &nbsp;512M &nbsp; 1% /dev/shm</div><div>/dev/sda1 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;97M &nbsp; 43M &nbsp; 50M &nbsp;47% /boot</div><div><br></div><div>怎么样，变成512M啦，使用很方便吧，哈哈。</div><div>当然在生产环境中你可以把内存加大些，反正现在内存很便宜啦，为了提高性能也需要将/dev/shm加大。如：</div><div>mount -o size=1500M -o nr_inodes=1000000 -o noatime,nodiratime -o remount /dev/shm</div><div>nr_innodes指定索引节点数，nodiratime &nbsp;man中解释如下：</div><div>nodiratime &nbsp;Do &nbsp;not &nbsp;update directory inode access times on this filesystem.</div><div>不更新目录被访问时inode中的记录信息，noatime同理，好处你懂的。</div><div>tmpfs应用</div><div>tmpfs是基于内存的，速度是不用说的，硬盘和它没法比。</div><div>Oracle 中的Automatic Memory Management特性就使用了/dev/shm。</div><div><br></div><div>另外如果在网站运维中好好利用tmpfs，将有意想不到的收获。</div><div>我们先在/dev/shm建一个tmp目前，并与/tmp绑定。</div><div><br></div><div>[root@GoGo shm]# mkdir /dev/shm/tmp</div><div>[root@GoGo shm]# chmod 1777 /dev/shm/tmp &nbsp;//注意一下权限</div><div>[root@GoGo shm]# mount Cbind /dev/shm/tmp /tmp</div><div>[root@GoGo tmp]# ls -ld /tmp</div><div>drwxrwxrwt 2 root root 40 Aug 29 23:58 /tmp</div><div><br></div><div>当然您也可以不绑定，直接mount在现有的安装点上使用tmpfs,如：</div><div>#umount &nbsp; /tmp</div><div>#mount &nbsp;tmpfs &nbsp;/tmp &nbsp; -t tmpfs &nbsp; -o size=512M</div><div><br></div><div>也很方便吧，不需要使用mkfs等命令创建。</div><div>以下/tmp使用tmpfs文件系统。</div><div>(1)将squid的缓存目录cache_dir放到/tmp下</div><div>cache_dir ufs /tmp 256 16 256</div><div>重启一下squid服务，这样缓存目录都放在了tmpfs文件中了，速度不用说吧。</div><div>(2)将php的session文件放在/tmp下</div><div>通过phpinfo测试文件查看你的php session存储位置，如果不在/tmp下，修改php.ini文件，修改如下：</div><div>session.save_path = “/tmp”</div><div>当然如果您的网站访问量比较大，可/tmp下设置分层目录存储session,语法如下：</div><div>session.save_path=”N;/save_path”，N 为分级的级数，save_path 为开始目录。</div><div>(3)将服务的socket文件放在/tmp下</div><div>如nginx.socket和mysql.sock</div></div></div>
	</div>
</div>
</body>
</html>