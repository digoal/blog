## 数据库metascan - 存储级、块级、batch级过滤与数据编排
                   
### 作者                    
digoal                   
                     
### 日期                     
2017-08-09               
                              
### 标签              
PostgreSQL , metascan , 块级过滤 , 块级统计信息 , BATCH级统计信息 , brin , 区间索引 , 块级索引 , batch级索引 , 数据编排 , 存储计算分离 , 混合编排 , 分段编排       
              
----              
               
## 背景   
为了加速数据的检索效率，我们通常需要对数据创建索引，提高数据定位的精准性。例如查询某人某个月的通话流水数据，没有索引的话，我们需要搜索所有的数据，逐条匹配。通过索引，可以直接定位到需要查询的记录。

特别是在存储和计算分离时，如果搜索量越大，网络中传输的数据量就越大。瓶颈很明显。

另外，在OLAP领域，需要对大量的数据进行处理，如果都建索引，索引引入的开销还是蛮大的。

那么有没有其他方法，不建索引降低扫描量呢？

## 存储层统计和过滤下推
相信大家一定已经想到了，统计信息，没错我们可以对存储的数据，按块进行数据统计，例如每个块内的数据范围。

有几个非常常见的技术实现：

1、PostgreSQL BRIN索引。

[《PostgreSQL 物联网黑科技 - 瘦身几百倍的索引(BRIN index)》](../201604/20160414_01.md)  

https://www.postgresql.org/docs/10/static/brin-intro.html

PostgreSQL brin索引就是块级索引，记录的是每个块、或者每一批连续的块的统计信息。

在按这个列搜索时，通过元数据，过滤不相干的块。

2、cstore_fdw列存储插件。实际上它也是按BATCH编排的列存储，每个BATCH的元数据（最大值、最小值）可以用于扫描时的过滤。

https://github.com/citusdata/cstore_fdw

Skip indexes: Stores min/max statistics for row groups, and uses them to skip over unrelated rows.

Using Skip Indexes

cstore_fdw partitions each column into multiple blocks. Skip indexes store minimum and maximum values for each of these blocks. While scanning the table, if min/max values of the block contradict the WHERE clause, then the block is completely skipped. This way, the query processes less data and hence finishes faster.

To use skip indexes more efficiently, you should load the data after sorting it on a column that is commonly used in the WHERE clause. This ensures that there is a minimum overlap between blocks and the chance of them being skipped is higher.

In practice, the data generally has an inherent dimension (for example a time field) on which it is naturally sorted. Usually, the queries also have a filter clause on that column (for example you want to query only the last week's data), and hence you don't need to sort the data in such cases.

在按这个列搜索时，通过元数据，过滤不相干的块。

例子

```
某个300GB的外部表，采样skip index扫描，加速扫描。耗时103毫秒。

explain (analyze,verbose,timing,costs,buffers) select c400,sum(c2) from ft_tbl1 where c400=1 group by c400;

         Filter: (ft_tbl1.c400 = 1)
         Rows Removed by Filter: 89996  
         CStore File: /data01/digoal/pg_root1921/cstore_fdw/13146/41038
         CStore File Size: 325166400400
         Buffers: shared hit=8004
 Planning time: 52.524 ms
 Execution time: 103.555 ms
(13 rows)

不使用where c400=1，耗时89秒
explain (analyze,verbose,timing,costs,buffers) select c400,sum(c2) from ft_tbl1  group by c400;

         CStore File: /data01/digoal/pg_root1921/cstore_fdw/13146/41038
         CStore File Size: 325166400400
         Buffers: shared hit=8004
 Planning time: 52.691 ms
 Execution time: 89428.721 ms
```

## 过滤效率与线性相关性
注意，由于数据存储的关系，并不是所有列的统计信息过滤性都很好。举个例子：

某列的写入很随机，导致值的分布很随机，那么在一个数据块里面包含的数据范围可能比较大，这种列的存储元信息过滤性就很差。

```
create table a(id int, c1 int);
insert into a select generate_series(1,1000000), random()*1000000;
```

数据的分布如下

```
postgres=# select substring(ctid::text, '(\d+),')::int8 blkid, min(c1) min_c1, max(c1) max_c1, min(id) min_id, max(id) max_id from a group by 1 order by 1;
 blkid | min_c1 | max_c1 | min_id | max_id  
-------+--------+--------+--------+---------
     0 |   2697 | 998322 |      1 |     909
     1 |   1065 | 998817 |    910 |    1818
     2 |    250 | 998025 |   1819 |    2727
     3 |     62 | 997316 |   2728 |    3636
     4 |   1556 | 998640 |   3637 |    4545
     5 |    999 | 999536 |   4546 |    5454
     6 |   1385 | 999196 |   5455 |    6363
     7 |   1809 | 999042 |   6364 |    7272
     8 |   3044 | 999606 |   7273 |    8181
     9 |   1719 | 999186 |   8182 |    9090
    10 |    618 | 997031 |   9091 |    9999
    11 |     80 | 997581 |  10000 |   10908
    12 |    781 | 997710 |  10909 |   11817
    13 |   1539 | 998857 |  11818 |   12726
    14 |   2097 | 999932 |  12727 |   13635
    15 |    114 | 999913 |  13636 |   14544
    16 |    136 | 999746 |  14545 |   15453
    17 |   2047 | 997439 |  15454 |   16362
    18 |   1955 | 996937 |  16363 |   17271
    19 |   1487 | 999705 |  17272 |   18180
    20 |     97 | 999549 |  18181 |   19089
    21 |    375 | 999161 |  19090 |   19998
    22 |    645 | 994457 |  19999 |   20907
    23 |   4468 | 998612 |  20908 |   21816
    24 |    865 | 996342 |  21817 |   22725
    25 |    402 | 998151 |  22726 |   23634
    26 |    429 | 998823 |  23635 |   24543
    27 |   1305 | 999521 |  24544 |   25452
    28 |    974 | 998874 |  25453 |   26361
    29 |   1056 | 999271 |  26362 |   27270
。。。。。。
```

对于ID列，分布非常清晰（线性相关性好），而C1列，分布非常散，导致存储元数据的过滤性差。

例如我要查id=10000的数据，直接查11号数据块，跳过其他数据块的扫描。

而如果我要查c1=10000的数据，那么要查很多个数据块，因为能跳过的数据块很少。

## 如何提升每一列的过滤性 - 存储编排
因为数据存储


## 

需要提一下，目前cstore_fdw这个插件没有支持并行计算，而实际上PostgreSQL的fdw接口已经支持了并行计算，cstore_fdw只需要改造一下，即可支持并行计算。

如下

https://www.postgresql.org/docs/10/static/fdw-callbacks.html#fdw-callbacks-parallel




我记得以前写过一篇这样的文档：

[《一个简单算法可以帮助物联网,金融 用户 节约98%的数据存储成本 (PostgreSQL,Greenplum帮你做到)》](../201604/20160404_01.md)  












不能完全代替索引


## 相关技术

https://github.com/citusdata/cstore_fdw

https://www.postgresql.org/docs/10/static/fdw-callbacks.html#fdw-callbacks-parallel


[《一个简单算法可以帮助物联网,金融 用户 节约98%的数据存储成本 (PostgreSQL,Greenplum帮你做到)》](../201604/20160404_01.md)  

[《PostgreSQL 物联网黑科技 - 瘦身几百倍的索引(BRIN index)》](../201604/20160414_01.md)  

https://www.postgresql.org/docs/10/static/brin-intro.html




## 云端产品  
[阿里云 RDS PostgreSQL](https://www.aliyun.com/product/rds/postgresql)        
      
[阿里云 HybridDB for PostgreSQL](https://www.aliyun.com/product/gpdb)        

